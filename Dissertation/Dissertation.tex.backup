\documentclass[ % the name of the author
                    author={Nicholas Tutte},
                % the name of the supervisor
                supervisor={Prof. Nigel Smart},
                % the degree programme
                    degree={MEng},
                % the dissertation    title (which cannot be blank)
                     title={Secure Two Party Computation},
                % the dissertation subtitle (which can be blank)
                  subtitle={A practical comparison of recent protocols},
                % the dissertation     type
                      type={Research - GG1K},
                % the year of submission
                      year={2015} ]{dissertation}

\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{mdframed}
\usepackage{appendix}
\usepackage[section]{placeins}


\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

	\pagenumbering{roman}

	\maketitle
	\chapter*{Declaration}

		This thesis is submitted to the University of Bristol in accordance 
		with the requirements of the degree of \textbf{GG1K} in the Faculty 
		of Engineering.  It has not been submitted for any other degree or diploma 
		of any examining body.  Except where specifically acknowledged, it is all 
		the work of the Author. 

		\vspace{6cm}

		\noindent{Nicholas Tutte}, \today


	\chapter*{Prelude}
		\section*{Executive Summary}
			\subsubsection*{Abstract}
			  We present prototype implementations of several recently proposed Secure Two Party Computation protocols and perform experiments for the purpose of comparison. We also give and prototype a novel variant combining two of the aforementioned protocols.\\

			  For several of these protocols our implementation is, to the best of our knowledge, the first. As such until now we have had only theoretical comparisons of these protocols, making it difficult to know which approach is the most promising and deserving of further research.\\

			  In particular we have implemented the protocols described in \cite{LindellAndPinkas2011}, \cite{Lindell_CnC_2013} and \cite{Katz_Symm_CnC_2013} and additionally we experiment with modifying \cite{Lindell_CnC_2013} to use \cite{Katz_Symm_CnC_2013} instead of \cite{LindellAndPinkas2011} as a sub-protocol.\\

			  We had limited success with modifying the Lindell 2013 protocol's sub-computation on circuits with small input sizes. Whilst our modified protocol ran on the AES circuit in about $\frac{2}{3}$ of the time taken by Lindell 2013 we believe most of this is due another improvement, also inspired by the Huang et al. paper.\\

			  We found that the Huang-Katz-Evans protocol using Symmetric cut and choose was by far and away more efficient in terms of computational resources needed. The Lindell 2013 protocol, while considerably slower than that of Huang et al. had lower bandwidth usage and the computational costs were heavily skewed towards the Builder.\\

			  We also found the Cut and Choose Oblivious Transfer is of dubious value. Whilst it removes the need for a set of potentially expensive commitments it adds in a set of even more expensive Zero Knowledge Proofs. 


			\subsubsection*{Summary of Achievements}
				\begin{itemize}
					\item We implemented the protocols described in \cite{LindellAndPinkas2011, Lindell_CnC_2013}, to the best of our knowledge these are the first implementations of these protocols.
					\item We implemented the protocol described in \cite{Katz_Symm_CnC_2013}. Huang et al. have produced an implementation in Java this cannot be fairly compared to my C implementations of the other protocols. Furthermore they only performed preliminary experiments, we provide more extensive results.
					\item We experimented with modifying the sub-protocol used for the Secure computation to detect cheating in \cite{Lindell_CnC_2013}, exchanging the use of \cite{LindellAndPinkas2011} for \cite{Katz_Symm_CnC_2013} and making other changes as necessary for this approach to work.
					\item We have argued informally for the security of the modified protocol.
					\item We have run practical comparisons of all the implemented protocols on a variety of circuits/computations and provided some analysis of the results.
				\end{itemize}

		\section*{Supporting Technologies}
			\begin{itemize}
					\item Unless otherwise stated all tests have been run upon the Bristol Cryptography Group's Diffie and Hellman machines. These machines are identical and have dedicated network cards for communications between each other.
					\item All code is in either C or C++, using the OpenMP library for parallelism in the shared memory paradigm. Furthermore AES-NI support is enabled.
					\item Extensive use has been made of the GNU Multi Precision Arithmetic Library.
					\item The net code was provided by my supervisor Prof. Nigel Smart.
					\item The AES implementation I use was mostly provided by my supervisor Prof. Nigel Smart (coded by Dr. Dan Page). Though I have extended this as it did not provide non-AES-NI decryption.
					\item The SHA-256 implementation used was provided by Brad Conte with minor modifications, the original code can be found at \url{http://bradconte.com/files/projects/code/sha256.c}.
					\item For much of the random number generation we have used the implementation of ISAAC provided by \cite{ISAAC_Implementation}.
			\end{itemize}

		\section*{Notational Glossary}
			$\mathbb{G} = (G, g, q) \leftarrow \zeta(1^n)$ informally speaking this indicates choosing a group such that the `security' of the group is $n$ bits.\\

			We define the group as the tuple $(G, g, q)$ where $G$ is the set of all elements of the group, $g$ is a set that generates $G$ (we deal primarily in Cyclic groups so usually this will be a single element) and finally $q$ which is the order of the group.\\

			The group $G^n$ is taken to be the direct product of $G$ with itself $n$ times, elements take the form $(g_1, g_2, ..., g_n)$ where $g_i \in G$. The group operation is the natural extension of the group operation of $G$.\\

			$\Vert$ indicates concatenation. $\oplus$ denotes XOR.\\

			Throughout take $S$ to be a statistical security parameter.\\

			We abbreviate to the protocol put forward by Lindell and Pinkas in \cite{LindellAndPinkas2011} as LP-2010. Similarly we abbreviate Lindell's protocol from \cite{Lindell_CnC_2013} to L-2013 and abbreviate the protocol given by Huang, Katz and Evans in \cite{Katz_Symm_CnC_2013} to HKE.

		\section*{Disclaimer}
			Here we give a disclaimer. Our implementations are prototypes for the purposes of comparing the performance of the protocols. Whilst we have implemented the protocols faithfully we have not dealt with some non-protocol related issues such as establishing a secure authenticated communication channel between parties.\\

			As such we \emph{cannot} condone use of our implementation in `real-life' situations where actual security is required and in fact strongly advise against it.

	% \mainmatter
	% CONTENTS.
	\tableofcontents

	\chapter{Introduction}
		\setcounter{page}{1}
		\pagenumbering{arabic}

		Secure multi-party computation(SMC) is a long standing problem in Cryptography. We have a set of parties who wish to cooperate to compute some function on inputs distributed across the parties. However, these parties distrust one another and do not wish their inputs to reveal their inputs to the other parties. Using SMC we can perform the desired computation without any party ever knowing the other's inputs.\\

		A commonly used example is the Millionaires problem. A group of rich persons wish to find out who among them is the richest, but do not wish to tell each other how much they are worth. Here the parties are the rich individuals, each party's inputs is their net worth and the function will return the identifier of the individual with the greatest input. Additionally, at the end of the computation no party should be able to divine anything about another party's inputs, apart from what can be inferred from their own input and the output.\\

		For many years Yao's protocol \cite{YaoOriginal} has been the most attractive avenue of theoretical research, mainly due to its conceptual simplicity and constant round nature. In particular recent work has endeavoured to produce variants of Yao's protocol that can provide security in the presence of malicious adversaries (\cite{LindellAndPinkas2007}, \cite{LindellAndPinkas2011}, \cite{Lindell_CnC_2013}, \cite{Katz_Symm_CnC_2013}, \cite{OnCommittedInputs}, \cite{LEGO_Paper}, \cite{MiniLEGO}) and to improve the efficiency of the original protocol itself (\cite{SMC_Is_Practical}, \cite{FreeXOR}).\\

		We provide implementations for several of the more recent protocols, in order to run experiments to measure and compare their performance. For two of the three published protocols we provide the first ever implementation, the fourth protocol is of our own devising, so again we provide the first implementation.\\

		As important as theoretical comparisons are they can only tell us so much. For example in \cite{Lindell_CnC_2013} Lindell explicitly compares the Lindell 2013 protocol with the Lindell-Pinkas 2010 protocol. He notes how the L-2013 protocol trades off more exponentiations for fewer symmetric encryptions and less bandwidth usage. However this theoretical comparison does not tell us if this trade off is worth it. Answering questions like this is the primary purpose of this thesis.\\

		Our contributions are as follows,

		\begin{itemize}
			\item To the best of our knowledge we provide the first implementations of the protocols of \cite{LindellAndPinkas2011} and \cite{Lindell_CnC_2013}.
			\item We also provide an implementation of the protocol described in \cite{Katz_Symm_CnC_2013}. 
			\item We put forward and implement a modification of \cite{Lindell_CnC_2013} using our implementation of \cite{Katz_Symm_CnC_2013} for the sub-computation rather than \cite{LindellAndPinkas2011} as originally proposed. Further we informally argue this modification maintains security.
			\item We measure the performance of each protocol on several of the classic SMC benchmark computations and give analysis of the results.

		\end{itemize}

		% In this paper we shall be producing implementations of several recently proposed protocols based on Yao's protocol and, several of which are as yet unimplemented, producing a practical comparison of them. The purpose being to explore which protocol suggests the most potential, allowing future research to be directed in the most promising direction.

		% \section{Paper Structure} Section \ref{sec:BG_toSMC} provides a more detailed overview of the problem of Secure Multiparty Computation and consider some of its applications for the purposes of motivation. Section \ref{sec:Yao_Circuits} introduces the basic ideas underlying Yao's protocol that are the cornerstone of the protocols we are comparing. Section \ref{sec:Protocols} delves into the specifics of each of the protocols we have implemented, touching on the main ideas and challenges of each. Section \ref{sec:ImplementationDetails} 


	\chapter{Background to Secure Multiparty Computation} \label{sec:BG_toSMC}
		\section{Security Properties} \label{sub:SecurityProperties}
			There are three main properties that we wish to achieve with any SMC protocol,
			\begin{itemize}
				\item Privacy, the only knowledge parties gain from participating is the output.
				\item Correctness, the output is indeed that of the intended function.
				\item Independence of inputs, no party can choose its inputs as the function of other parties inputs.
			\end{itemize}

			In this sense we define the goal of an adversary to compromise one or more of these properties.\\

			We compare any protocol to the \emph{ideal} execution, in which the parties submit their inputs to a universally trusted and incorruptible external party via secure channels. This trusted party then computes the value of the function and returns the output to the relevant parties.\\

			Informally we say that the protocol is secure if no adversary can attack the protocol with more success than they can achieve against the ideal model. Formal security proofs are based upon the notion of simulation.

			Astute readers may have already noticed that some functions inherently leak information about the inputs of the other parties. For example in a two-party addition both parties can easily recover the other party's input after the computation has been run by subtracting their own input from the output. In these cases SMC is not at fault so we do not concern ourselves.\\

			% Alice-Bob-Trevor could go here.
			Occasionally a fourth property is proposed, namely \emph{fairness}, meaning if one party gets their output then all parties get their output. However, generally this is ignored due being thought to be impossible outside a synchronous communication model as any party can stop participating in the protocol at any time.

		\section{Security levels}\label{sub:SecurityLevels}
			Having established the goals of the adversary and how we can measure if said adversary has a valid attack, we next deal with the capabilities of the adversary. We use three main models to describe the capability of the adversary.

			\subsection{Semi-honest Adversary}
				The Semi-honest adversary is the weakest adversary, with very limited capabilities. The Semi-honest adversary has also been referred to as ``honest but curious'', because in this case the adversary is not allowed to deviate from the established protocol (i.e. they are honest), but at the same time they will do their best to compromise one of the aforementioned security properties by examining the data they have legitimate access to. This is in some ways analogous to the classic ``passive'' adversary.

				\subsubsection{Example}

					At first it can be difficult to think of applications where only Semi-Honest security is required, but such applications do exist. Semi-Honest security is of use when in situations where it is not in the interest of either party to cheat.\\

					So take the example of parties who wish to decide whether they should cooperate on a particular project. More concretely maybe two drug companies are considering cooperating in a particular area of research, but first need to establish that they have the combined expertises required. To do this without unnecessarily revealing information about their capabilities to the other company they might run a legally binding Secure Computation.\\
					
					In this case undetected cheating could lead to the parties committing to a project they do not have the expertises to complete, this is clearly not in the interests of the parties so it is reasonable to assume that both parties will act honestly.\\



			\subsection{Malicious Adversary}
				The Malicious adversary is allowed to employ any polynomial time strategy and is not bounded by the protocol (they can run arbitrary code instead), furthermore the Malicious adversary does not care if it is caught cheating so long as it achieves its goal in the process. This is in some ways analogous to the classic ``active'' adversary.

				\subsubsection{Example}
					Security in the presence of malicious adversaries is much sought after, and is useful in many more scenarios. Suppose a pair of persons wish to compute the intersection of sets they each hold but only wish to reveal those elements in both sets, keeping the rest secret.\\

					A malicious adversary might wish to reveal all of the elements in the other party's set. If the adversary can rig the condition in the computation checking whether an element is in both sets they can get all elements returned. Clearly in this case the adversary has something to gain and so we cannot count on the adversary being honest.\\


			\subsection{Covert Adversary}
				The Covert adversary model is very similar to the Malicious model, again bounded by polynomial time with freedom to ignore the protocol. However, in this case the adversary is adverse to being caught cheating and is therefore slightly weaker than the Malicious adversary. A Covert adversary will accept a certain probability of detection, this probability represents the point at which the expected benefit of cheating successfully outweighs the expected punishment for getting caught, effectively a game theory problem \cite{WhenGameTheoryMetSMC}.\\

				We call the probability that a Covert adversary will be caught the ``deterrent probability'', usually denoted using $\epsilon$. Often protocols providing security against Covert adversaries take a Security parameter which varies the probability of detecting cheating.

				\subsubsection{Example} 

					This model can be thought of as a compromise between practicality and malicious security and is usually appropriate when there are tangible consequences to a party being caught cheating. For example consider a consortium of companies who wish to cooperate in some way that benefits participants and that if one is caught cheating in the computations they are publicly expelled from the consortium.\\

					In this case a sufficiently high deterrent probability will mean the chance of being caught is so high that the risk of being caught outweighs the benefits to be gained by cheating.

			\subsection{Actively Secure}
				We refer to the second and third adversary as `Active', denoting the fact that they can take an active role in trying to subvert the security of the computation. We call protocols that are secure in the presence of such active adversaries `Actively Secure'.

		\section{Applications of SMC} \label{sub:Applications}
			Here we take time to motivate the study of SMC by giving several actual or proposed applications.

			\subsection{Secret Auctions - Danish Beets} \label{BeetsAuctionApplication}
				In Denmark a significant number of farmers are contracted to grow sugar beets for Danisco (a Danish bio-products company). Farmers can trade contracts amongst themselves (effectively sub-contracting the production of the beets), bidding for these sub-contracts is done via a ``double auction''.\\

				Farmers do not wish to expose their bids as this gives information about their financial state to Danisco and so refused to accept Danisco as a trusted auctioneer. Similarly all other parties (e.g. Farmer union) already involved are in some way disqualified from playing the role of a universally trusted party. Rather than rely on a completely uninvolved party like an external auction house (an expensive option) the farmers use an SMC-based approached described in \cite{SugarBeets}. Since 2008 this auction has been ran multiple times.\\

				As far as team behind this auction are aware this was the first large scale application of SMC to a real world problem, this application example in particular is important as it is a concrete practical example of SMC being used to solve a problem demonstrating this is not just a Cryptological gimmick.

			% SHOULD REALLY PROVIDE CITATION TO THEIR WEBSITE. AND TO RSA
			\subsection{Distributed secrets} \label{sub2:DistributedSecretApplication}
				Consider the growing use of physical tokens in user authentication, e.g. the RSA SecurID. When each SecurID token is activated the seed generated for that token is loaded to the relevant server (RSA Authentication Manager), then when authentication is needed both the server and the token compute `something' using the aforementioned seed. However, this means that in the event of the server being breached and the seed being compromised the physical tokens will need to be replaced. Clearly this is undesirable, being both expensive both in terms of up front clean up costs and reputation.\\

				In the above scenario we clearly need to store the secret(the seed) somewhere. If we can split the seed across multiple servers and have these servers perform the computation as an SMC problem we can remove the single point of failure and increase the cost to an attacker. As the secret is now distributed an attacker will now have to compromise multiple servers.\\

				Such a service is in development by Dyadic Security who provide a technical primer on applying SMC to this problem \cite{DYADIC_MPC_Primer} (full disclosure, my supervisor Prof. Nigel Smart is a co-founder of Dyadic).

			\subsection{PROCEED - Computation on encrypted data} \label{sub2:PROCEED_DARPA}
				Recently US Defence Advanced Research Projects Agency (DARPA) ended a programme called PROCEED. The eventual goal being the ability to efficiently perform computations on encrypted data without knowledge of the data. This could be used by companies such as Google to continue to provide services requiring computation on personal data without intruding on the privacy on their users.\\

				The PROCEED program is not restricted to SMC, it also considers Fully Homomorphic Encryption. At present DARPA claim that SMC slows the computation by at least 2 orders of magnitude whilst FHE slows it by nearly 10 orders of magnitude \cite{DARPAPROceed}. 


	\chapter{Technical Background}
		Here we detail two of the two main common components of a Yao Garbled Circuits based system. The Yao Garbled Circuits themselves and Oblivious transfer.

		\section{Oblivious Transfer} \label{sec:OT_Intro}
			Oblivious Transfers are vitally important for SMC and in particular Yao's Protocol that we shall be looking at later. Oblivious Transfers protocols allow for one party(the Receiver) to get one out-of two values from another party (the Sender). The Receiver is oblivious to the other value, and the Sender is oblivious to which value the Receiver received.\\

			We shall first talk abstractly about what functionality Oblivious Transfers should have before then giving two concrete examples of how to perform Oblivious Transfer.\\

			Oblivious Transfers were first suggested by Rabin in \cite{Rabin81}. We define the functionality of a 1-out-of-2 OT protocol in Figure \ref{fig:OTformalDef}. As we shall see later, Oblivious Transfers are vital to Yao Garbled Circuits. 

			\begin{figure}[!htb]
				\centering
				\begin{minipage}{0.45\textwidth}
					\centering
					\textbf{Receiver}\\
					Inputs : $b \in \{0, 1\}$\\
					Outputs : $x_b$\\
				\end{minipage}
				\begin{minipage}{0.45\textwidth}
					\centering
					\textbf{Sender}\\
					Inputs : $x_0, x_1 \in \{0, 1\}^l$\\
					Outputs : $\emptyset$\\
				\end{minipage}

				\caption{ Formal definition of the functionality of a one-out-of-two OT protocol.\label{fig:OTformalDef}}
			\end{figure}

			The security of Oblivious Transfers is defined in a similar way to that of SMC, the focus is on Semi-honest(passive) and Malicious(active) adversaries. Security against these adversaries is usually either computational or statistical.\\

			A protocol is considered secure with regards to Semi-honest adversaries if neither a Semi-honest adversary in the sender role cannot learn anything about which value the receiver requested, nor can a Semi-honest adversary in the role of the Receiver learn anything about values other than the one it requested. The protocol being secure against Malicious adversaries is defined by the obvious extension of the Semi-honest case.\\

			We primarily use OTs based on the Peikert-Vaikuntanathan-Waters OT (PVW-OT) from \cite{PVW_OT_2008} or more precisely the modifications of the PVW-OT suggested in \cite{LindellAndPinkas2011} and expanded on in \cite{Lindell_CnC_2013}. However, we also use the Naor-Pinkas (NP-OT) from \cite{NaorPinkasOT2001} for the protocol in \cite{Katz_Symm_CnC_2013}.


			\subsection{Naor-Pinkas Oblivious Transfer} \label{sub:NaorPinkasOT}

				Here we describe the Naor-Pinkas Oblivious Transfer as put forward in \cite{Katz_Symm_CnC_2013} that is used in the Huang, Katz and Evans protocol later implemented, for a full description including proofs of security see \cite{NaorPinkasOT2001}.\\

				We assume that we have the usual OT inputs and parties. That is a Sender $S$ who holds two input bit strings denoted $x_0, x_1 \in \{0, 1\}^*$ and a Receiver who has a $b \in \{0, 1\}$ representing the  input that the Receiver wishes to uncover.\\

				On top of these inputs the parties share a group $\mathbb{G}$ as an auxiliary input. We denote the group by $(\mathbb{G}, g, q)$ where $<g> = \mathbb{G}$ and $q$ is the order of the group.\\ %($g$ generates $\mathbb{G}$)

				See Figure \ref{fig:NPOT_Functionality} for the functionality of the Naor-Pinkas OT.\\


				\begin{figure}[!htb]
					\centering
					
					\textbf{Shared Auxiliary Input}\\
					$\mathbb{G}$ a group for which the CDH assumption is believed to hold. $C$, an element of $G$ generated by the Sender.\\
					\vspace{0.3cm}
					\begin{minipage}{0.45\textwidth}
						\centering
						\textbf{Receiver}\\
						Inputs : $b \in \{0, 1\}$\\
						Outputs : $x_b$\\
					\end{minipage}
					\begin{minipage}{0.45\textwidth}
						\centering
						\textbf{Sender}\\
						Inputs : $x_0, x_1 \in \{0, 1\}^l$\\
						Outputs : $\emptyset$\\
					\end{minipage}

					\caption{ Formal definition of the functionality of The Naor-Pinkas Oblivious Transfer.\label{fig:NPOT_Functionality}}
				\end{figure}

				The Naor-Pinkas OT is known to be simulatable against a malicious Sender assuming the CDH holds in the group. However, it is only known to provide \emph{privacy} against a malicious Receiver, the question of whether it is simulatable against such an adversary is as yet unanswered.

				\begin{figure}[!htb]
					\begin{mdframed}
						\centering
						\begin{tabular}{l c l}
							\textbf{Sender} & Group $\mathbb{G} = (G, g, q)$ & \textbf{Receiver}\\
							$x_0, x_1 \in \{0, 1\}^l$ & & $b \in \{0, 1\}$\\[0.6cm]

							$C \xleftarrow{\$} G$ & &\\

							& \commRightArrow{C} & \\

							& & $k \xleftarrow{\$} \mathbb{Z}_q$ \\
							& & $h_0 \leftarrow g^k$\\
							& & $h_1 \leftarrow C / g^k $\\

							& \commLeftArrow{h=h_b} & \\

							$r \xleftarrow{\$} \mathbb{Z}_q$ & &\\
							$a \leftarrow g ^ r$ & &\\
							$c_0 \leftarrow H(h^r) \oplus x_0$ & &\\
							$c_1 \leftarrow H( (C / h)^r) \oplus x_1$ & &\\

							& \commRightArrow{a, c_0, c_1} & \\

							& & $y \leftarrow a ^ k (= g^{r \cdot k})$ \\
							& & $x_b \leftarrow H( y ) \oplus c_b$ \\
							& & Output $x_b$\\
						\end{tabular}
					\end{mdframed}

					\caption{ The Naor-Pinkas Oblivious Transfer protocol. Note that the same $C$ can be used for multiple OTs.\label{fig:NPOT_Protocol}}
				\end{figure}



			% THIS NEED TIDYING UP
			\subsection{Peikert - Vaikuntanathan - Waters Oblivious Transfer} \label{sub:dualModeCryptoOT}
				The basis of the Oblivious transfer protocol we shall be using comes from \cite{PVW_OT_2008}, in particular we shall be using the realisation of the dual-mode cryptosystem based on Decisional Diffie-Hellman problem. Whilst I shall not go into depth on this protocol we shall give a broad overview of the dual-mode cryptosystem.

				\subsubsection{High level concepts}
					The Peikert-Vaikuntanathan-Waters (PVW) OT has at its core the concept of a messy key. This is a key such that under encryption by this key all information about the plaintext is lost, moreover messy keys are indistinguishable from normal valid (\emph{neat}) keys that do not obliterate the plaintext. It does not take much to see how these could be useful for an Oblivious Transfer scheme.\\

					The PVW OT is constructed in such a way we can ensure one of the keys will be a messy key, whilst the other will be a neat key. Furthermore the Receiving party can control which key will be messy and which will be neat, allowing the Receiving party to choose which input to uncover.

				\subsubsection{Dual-Mode Encryption}
					In \cite{PVW_OT_2008} Peikert-Vaikuntanathan and Water's describe a new abstraction, a Dual-mode cryptosystem. This system requires a setup phase in which the parties produce a public \emph{Common Reference String} and potentially a trapdoor. Peikert et al. state that this trapdoor information is only needed for the security proof as such we will mostly ignore these details.\\

					The setup also chooses one of two modes (\emph{messy} and \emph{decryption}).. Once this setup is complete this cryptosystem is very similar to a normal Public Key system, with one major difference, Peikert et al. introduce the concept of encryption branches.\\

					The key generation algorithm takes a parameter $\sigma \in \{0, 1\}$, and returns a public/secret key pair. Similarly when encrypting using the public key produced by the key generation one must also specify a $b \in \{0, 1\}$.\\

					Plaintexts can be decrypted if encrypted with $b = \sigma$ (the decryptable branch of $pk$), but plaintexts encrypted with $b \neq \sigma$ cannot be decrypted (we call this the messy branch of $pk$). Additionally when carrying out an encryption using a public key provided by the other party you cannot tell which branch is decryptable.\\

					Depending on which mode is selected during setup the trapdoor returned allows subversion of one of these properties. If the system is in messy mode the trapdoor allows the encrypting party to distinguish when the branch input to the key generation that produced a public key was. If the system is in decryptable mode the trapdoor allows the decryption of both branches.\\

					In Figure \ref{fig:PVW_Abstract_Functions} we more formally define the abstract system and in particular what functions are required.

					\begin{figure}[!htb]
						\begin{mdframed}
							\centering
							\begin{itemize}
								\item \textbf{Setup}($1^n$, $\mu$) - This function takes a security parameter $1^n$ and a bit $\mu \in \{0, 1\}$ which defines which mode (messy or decryptable). The function should output the CRS and trapdoor information (crs, t). All other functions take this crs as an implicit parameter.\\[0.25cm]

								In order to ease notation later we define two separate functions depending on $\mu$. \textbf{SetupMessy}$(1^n) :=$ \textbf{Setup}$(1^n, 0)$ and \textbf{SetupDec}$(1^n) :=$ \textbf{Setup}$(1^n, 1)$.\\[0.25cm]


								\item \textbf{KeyGen}($\sigma$) - This function takes a single input of a bit $\sigma \in \{0, 1\}$ and outputs ($pk$, $sk$) where $pk$ is a public key for encryption and $sk$ is a secret key that allows decryption of plaintexts encrypted using $pk$ on the branch $\sigma$.

								\item \textbf{Enc}($m$, $pk$, $b$) - This function takes a message $m \in \{0, 1\}^l$, a public key $pk$ and a bit $b \in \{0, 1\}$. It returns the encryption of $m$ under $pk$ on branch $b$.

								\item \textbf{Dec}($c$, $sk$) - This function takes a ciphertext $c$ and a secret key $sk$. It outputs a message $m' \in \{0, 1\}^l$.

								\item \textbf{FindMessy}($pk$, $t$) - This function takes a public key $pk$ and a messy mode trapdoor $t$. The function then outputs a bit $b \in \{0, 1\}$ indicating which branch of $pk$ is messy.

								\item \textbf{TrapKeyGen}($t$) - This function takes decryptable mode trapdoor $t$ and is an alternative key generation. The function outputs $(pk, sk_0, sk_1)$, note that it outputs two secret keys, one for each branch. These secret keys allow the decryption of both branches of $pk$.
							\end{itemize}
						\end{mdframed}

						\caption{The abstract functions defining a Dual-mode cryptosystem. \label{fig:PVW_Abstract_Functions}}
					\end{figure}

				\subsubsection{Dual-mode encryption using DDH}

					Having described the abstract form of a Dual-mode cryptosystem we now give a concrete realisation. This realisation requires a group, as usual we define this group as $\mathbb{G} = (G, g, q)$ where $g$ generates $G$ and $|g| = q$. Further we require that the the group is chosen such that we believe the Decisional Diffie-Hellman problem be hard for this group.\\

					Before giving concrete definitions of the functions we need a few primitives relating to DDH cryptosystems.
					
					\paragraph{Randomisation} Take $G$ to be an arbitrary group, we shall use multiplicative notation, such that the group is of order $p$ where $p$ is prime. We then define $DLOG_G(x) = \{ (g, g^x) : g \in G\}$. Put another way $DLOG_G(x)$ is the set of all pairs of elements in $G$ such that the discrete log of the second over the first is $x$.\\
					
					We define a probabilistic algorithm \emph{Randomise} that takes generators $g,h \in G$ and elements $g', h' \in G$. The algorithm then outputs $(u, v) \in G^2$ such that the following properties hold,
					
					\begin{itemize}
						\item If $(g, g'), (h, h') \in DLOG_G(x)$ for some $x \in \mathbb{Z}_p$ then $(u, v)$ is chosen from $DLOG_G(x)$ uniformly at random.

						\item If $(g, g')\in DLOG_G(x)$ and $(h, h') \in DLOG_G(y)$ for some distinct $x, y \in \mathbb{Z}_p$ then $(u, v)$ is chosen uniformly at random from $G^2$.
					\end{itemize}

					In particular we define $Randomise(g, h, g', h')$ as follows, choose $s, t \xleftarrow{\$} \mathbb{Z}_p$ independently of one another, then let $u = g^s \cdot h^t$ and $v = (g')^s \cdot (h')^t$.\\

					A full proof that this instantiation of \emph{Randomise} is given in \cite{PVW_OT_2008}, suffice to say the main idea of the proof is to re-write $h$ as a power of $g$ which we can do as $g$ generates $G$.\\

					Having defined the function \emph{Randomise} Peikert et al. next defined a simple asymmetric cryptosystem based on it.

					\paragraph{DDH-Randomise Cryptosystem} As with all asymmetric cryptosystems we need to define three algorithms namely key generation, encryption and decryption. Peikert et al. described a cryptosystem based on \emph{Randomise} which we give in Figure \ref{fig:DDH_Cryptosystem}.

					\begin{figure}[!htb]
						\begin{mdframed}
							\centering
							\begin{itemize}
								\item \textbf{DDH-KeyGen}($1^n$) - This function takes a security parameter and chooses a group $\mathbb{G} = (G, g, q) \leftarrow \gamma(1^n)$, this group $G$ is the message space. For our purposes this group will be an Elliptic curve group of size $\sim2^{2n}$.\\[0.25cm]

								Then choose another generator of the group $h \in G$ and an exponent $x \in \mathbb{Z}_p$. Then set $pk = (g, h, g^x, h^x)$ and $sk = x$. 

								\item \textbf{DDH-Enc}($pk$, $m$) - This function takes a message $m \in \{0, 1\}^l$, a public key $pk$. The public key should be parsed as $(g, h, g', h')$.\\[0.25cm]

								The function computes $(u, v) \leftarrow Randomise(g, h, g', h')$ and then outputs the ciphertext $(u, v \cdot m)$.

								\item \textbf{DDH-Dec}($sk$, $c$) - This function takes a ciphertext $c$ and a secret key $sk$, parse $c$ as $(c_0, c_1)$. Output a decryption $m' = c_1 / c_0^{sk}$.

							\end{itemize}
						\end{mdframed}

						\caption{A simple asymmetric cryptosystem based on \emph{Randomise} in a DDH group.   \label{fig:DDH_Cryptosystem}}
					\end{figure}


					\paragraph{Dual-mode Cryptosystem based on Randomise} Finally Peikert et al. give instantiations of the functions specified in \ref{fig:PVW_Abstract_Functions}, using the DDH cryptosystem just defined. These instantiations can be seen in Figure \ref{fig:PVW_DDH_Concrete_Functions}\\

					
					\begin{figure}[!htb]
						\begin{mdframed}
							\centering
							\begin{itemize}
								\item \textbf{Setup}$(1^n, \mu)$ - Recall that for notational purposes we split this function depending on the value of $\mu$. However, both branches of this function begin by choosing a group $\mathbb{G} = (G, g, p) \leftarrow \zeta(1^n)$. Then the Decryption and Messy Setup functions diverge.

								\textbf{SetupDec}$(1^n)$ - Choose a random generator $g_0 \in G$, a random \emph{non-zero} exponent $y \in \mathbb{Z}_p$ and let $g_1 = g_0^y$. Then take another random \emph{non-zero} exponent $x \in \mathbb{Z}_p$ and let $h_b = g_b^x$ for $b \in \{0, 1\}$. The outputs are then $(crs, t) = ( (g_0, h_0, g_1, h_1), y )$.

								\textbf{SetupMessy}$(1^n)$ - Choose a pair of random generators $g_0, g_1 \in G$ and a pair of random \emph{distinct and non-zero} exponents $x_0, x_1 \in \mathbb{Z}_p$. Let $h_b = g_b^{x_b}$ for $b \in \{0, 1\}$.  The outputs are then $(crs, t) = ( (g_0, h_0, g_1, h_1), (x_0, x_1) )$.

								\item \textbf{KeyGen}($\sigma$) - Firstly choose $r \xleftarrow{\$} \mathbb{Z}_p$. Then set $g = g_{\sigma}^r$ and  $h = h_{\sigma}^r$. Finally set $pk = (g, h)$ and $sk = r$ and output $(pk, sk)$.

								\item \textbf{Enc}($m$, $pk$, $b$) - Parse $pk$ as $(g, h)$. Let $pk_b = (g_b, h_b, g, h)$ where $g_b, h_b$ are taken from the crs. Then output \textbf{DDH-ENC}$(pk_b, m)$

								\item \textbf{Dec}($sk$, $c$) - This function just outputs \textbf{DDH-Dec}$(sk, c)$.

								\item \textbf{FindMessy}($pk$, $t$) - Parse $pk$ as $(g, h)$ and a messy mode trapdoor $t$ as $x_0, x_1$. If $h \neq g^{x_0}$ then output 0 (as the $pk$ provided is for branch 1, so branch 0 is the messy branch). Else output 1.

								\item \textbf{TrapKeyGen}($t$) - Parse $t$ as $y \in \mathbb{Z}_p$, check that $y$ is indeed non-zero and a member of $\mathbb{Z}_p$. Pick a random $r \xleftarrow{\$} \mathbb{Z}_p$, compute $pk = (g_0^r, h_0^r)$ and output $(pk, r, r / y)$
							\end{itemize}
						\end{mdframed}

						\caption{The realisation of the Dual-mode cryptosystem based on the DDH cryptosystem defined. \label{fig:PVW_DDH_Concrete_Functions}}
					\end{figure}


	\section{Yao's Protocol} \label{sec:Yao_Circuits}

		\subsection{Overview} \label{sub:Yao_Overview}
			Yao garbled circuits are one of the primary avenues of research into Secure multi-party computation. Yao first proposed garbled circuits in \cite{YaoOriginal}. The two parties are designated the Builder and the Executor. The Builder then constructs a circuit representing the function the parties wish to compute, this circuit is ``garbled'' in such a way that it can still be executed.\\

			This garbled circuit, hardcoded with the Builder's input data, is sent to the Executing party who then obtains the data representing its input from the Builder via Oblivious Transfer (for details on OT see Section  \ref{sec:OT_Intro}). The Executor then evaluates the circuit and obtains the output of the function.


		\subsection{Yao Garbled Circuits} \label{sub:Yao_Details}
			As noted above we first represent the function to compute as a binary circuit. Denote the two parties as $P_1$ and $P_2$, we will denote the party building the circuit by $P_1$ and the executing party by $P_2$.\\
			
			Take a single gate of this circuit with two input wires and a single output wire. Denote the gate a $G_1$ and the input wires as $w_1$ and $w_2$ and let $w_3$ be the output wire. Let $b_i \in \{0, 1\}$ be the value of $w_i$. Here we will take the case where $w_i$ is an input wire for which $P_i$ provides the value. Define the output value of the gate to be $G(b_1, b_2) \in \{0, 1\}$. We now garble this gate in order to obscure the inputs and outputs.\\

			$P_1$ garbles each wire by selecting two random keys of length $l$, for the wire $w_i$ call these keys $k_i^0$ and $k_i^1$. The length of these keys ($l$) can be considered a security parameter, and should correspond to the length of the key needed for the symmetric encryption scheme we'll be using later.\\

			$P_1$ also generates a random permutation $\pi_i \in \{0, 1\}$ for each $w_i$. Note that this can be represented by XORing the bit to be permuted and the permutation. We define $c_i = \pi_i(b_i)$. The garbled value of the $i^{th}$ wire is then $k_i^{b_i} \Vert c_i$, we then represent our garbled truth table for the gate with the table indexed by the values for the $c_1$ and $c_2$.

			$$ c_1, c_2 : E_{k_1^{b_1}, k_2^{b_2}} (k_3^{ G(b_1, b_2) } \Vert c_3) $$

			This table is referred to as the \emph{encrypted truth table}.\\

			Where $E_{k_i, k_j}(m)$ is some encryption function taking the keys $k_i$ and $k_j$ and the plaintext $m$. Since the advent of AES-NI and the cheapness of using AES we will use AES with 128 bit keys to make this function. This is particularly convenient since AES-128 takes in inputs of size $128$ bits and produces an output of size $128$ bits.\\

			Suppose that $AES_k(m)$ denotes the AES encryption of the plaintext $m$ under the 128 bit key $k$ and $AES^{-1}_k(c)$ denotes the decryption of ciphertext $c$ under key $k$. We define $E_K$ (and its inverse $D_K$) as follows,

			$$ E_K(m) = AES_{k_1}( AES_{k_2}(m)) \textnormal{, where } K = \{k_1, k_2\}$$ 
			$$ D_K(m) = AES^{-1}_{k_2}( AES^{-1}_{k_{1}}(m)) \textnormal{, where } K = \{k_1, k_2\}$$ 

			This is the intuitive extension of AES to multiple keys, chaining the encryption under all of the keys in a set order.\\

			Then $P_1$ sends this garbled version of the circuit to $P_2$. $P_1$ should send the garbling key for its input bit ($k_1^{b_1}$), the full encrypted truth table and $c_1 = \pi(b_1)$. $P_1$ should also send the permutations for each input wire owned by the Executor and for every output wire owned by $P_2$.\\

			Then $P_2$ needs to get $k_2^{b_2} \Vert c_2$ from $P_2$ without revealing the value of $b_2$. This is done by an Oblivious Transfer (see Section\ref{sec:OT_Intro}) where $P_1$ inputs $k_2^0$ and $k_2^1$ and $P_2$ inputs $b_2$. $P_2$ receives the output $k_2^{b_2} \Vert c_2$ from the OT and learns nothing about $k_2^{(1 - b_2)} $, $P_1$ gets no output and learns nothing about the value of $b_2$.\\

			$P_2$ can then look up the entry in the encrypted truth table indexed by $c_1$ and $c_2$ and decrypt it using $D_{k_1^{b_1}, k_2^{b_2}}(\cdot)$. This will give $P_2$ a value for $k_3^{G(b_1, b_2)} \Vert c_3$. If this is an output gate then $P_2$ can extract a value for $G(b_1, b_2)$ by using $\pi_3^{-1}$.\\

			This can be extended to a full circuit, the input wires belonging to the circuits builder are hard coded and their garble keys and permuted values are sent to the executor. The values for the input wires belonging to the executor are obtained by the executor via Oblivious transfer with the builder. The executor is only given the permutations for the output wires, and therefore the intermediate wire bit values are protected.

			\subsubsection{Free XOR Improvement}

				Over the years many improvements have been made to the original Yao Garbled Circuits to make them quicker to evaluate. One of these improvements is called the Free XOR technique and at its most simple level it reduces the cost of evaluating an XOR gate in the garbled circuit to virtually nil. This is why one of the key measures of a binary circuits optimisation for Yao Garbling is the number of non-XOR gates.\\

				The Free XOR method works by introducing a relationship between the 0-key($k_0$) and 1-key($k_1$) for each wire. In particular an $R$ is chosen at random for each Yao Garbled Circuit and whilst $k_0$ is generated randomly as usual we take $k_1 := k_0 \oplus R$.\\

				Then if we have an XOR gate that takes two input gates. Suppose the output keys of the input wires to be $\{X_0, X_1 = X_0 \oplus R\}$ and $\{Y_0, Y_1 = Y_0 \oplus R\}$. Then we take the output keys of the XOR gate to be $Z_0 := X_0 \oplus Y_0$ and $Z_1 := Z_0 \oplus R$.\\

				Then to evaluate a 2-to-1 XOR gate one only need to XOR the input keys. This removes any need for symmetric decryption when evaluating a gate.\\

				To understand why this works it may be helpful to think of the $R$ factor as being the indicator of a $1$. Therefore if both inputs are lacking the $R$ factor or both have it then the XOR eliminates it and the output also lacks the $R$ factor.\\

				However, if the input bits are different then only one of input key contains the $R$ factor, as such the XOR preserves it in the output. This can be seen in Figure \ref{table:FREE_XOR_Demonstration}.
% 
				\begin{figure}[!ht]
					\begin{center}
						\begin{tabular}{c c | l }
							$X$ & $Y$ & $X \oplus Y$\\
							\hline
							$X_0$ & $Y_0$ & $X_0 \oplus Y_0 = Z_0$ \\
							$X_0$ & $Y_1$ & $X_0 \oplus (Y_0 \oplus R) = Z_1$ \\
							$X_1$ & $Y_0$ & $(X_0 \oplus R) \oplus Y_0 = Z_1$ \\
							$X_1$ & $Y_1$ & $(X_0 \oplus R) \oplus (Y_0 \oplus R) = Z_0$ \\
						\end{tabular}
					\end{center}
					\caption{A tabulation of an XOR gate demonstrating that if all keys are of the Free-XOR form then an XOR gate can be evaluated by simply XORing the input keys. \label{table:FREE_XOR_Demonstration}}
				\end{figure}

				This does not only improve evaluation time for circuits though, it also removes the need to send the encrypted truth table for any gate for which Free-XOR can be used to evaluate. These encrypted truth tables are the main contributor to bandwidth for sending circuits and so this would yield significant improvements. However, we have not implemented this addition optimisation, on the evaluation optimisation.

		\subsection{Security of Yao Garbled Circuits} \label{sub:YaoSecurity}
			A naive implementation of a protocol using Yao Garbled Circuits provides only Semi-honest security. For a formal proof of Semi-honest security see \cite{ProofOfYaoSecurity}, we shall briefly give an intuitive explanation of why naive Yao Garbled Circuits are not secure in the presence of Malicious or Covert adversaries.\\

			Consider the case where $P_1$ is Malicious, at no point does a naive $P_2$ verify that the garbled circuit provided by the Builder actually computes the function the builder claims it does.\\

			Whilst the Executor can check that the garbled circuit has the correct ``shape'' (number of gates, wires between gates etc.) the Executor cannot verified that each gate has the correct output. This clearly breaks the Correctness requirement and depending on the function being computed and the structure of the circuit corresponding to it, the Builder can craft a garbled circuit to undermine the Privacy or Independence of Input properties.\\

			Additionally, the Executor has no way to check that the key it received from the OTs actually corresponds to the request key in the circuit, the Builder could use the same key for both $X_0$ and $X_1$ and thus alter the key used by the Executor for a given input wire.


		\subsection{Cut and Choose - Security against Malicious and Covert Adversaries} \label{sub:YaoMalicious}
			\subsubsection{Concept}
				Several extensions of Yao's original protocol have been proposed in order to achieve security against Malicious and Covert adversaries. Many depend on an approach dubbed ``cut and choose'' which provides statistical security (detects cheating with a certain probability).\\

				This relates to the old solution to dividing a cake fairly between two parties. Neither trusts the other so neither is willing to let the other cut a piece for themselves first as they will cut an unfairly large slice. The solution is to have one party cut the cake, then the other party chooses a slice. As the cutting party goes second it is in their interest to ensure the two available slices are of equal size else the chooser will pick the bigger slice and leave the cutter with the smaller.\\

				In our case the Builder builds $S$ many garbled circuits and sends them to the Executor. A subset of these circuits are chosen to be opened for the purpose of checking if they are correct. The remaining circuits are then referred to as Evaluation circuits.\\

				If all check-circuits pass then the Executor evaluates the remaining circuits as usual. If the Executor receives differing outputs from the Evaluation Circuits this indicates cheating, furthermore if any check circuits fail during correctness testing this is also taken to indicate cheating.\\

				As the check-set is unknown to the Builder till they have already committed to the circuits the Builder must guess at which circuit will be in the check-set before the Executor has chosen the check-set.\\

				The number of garbled circuits built ($S$) acts as a security parameter and the probability of detecting cheating is expressed in terms of $S$. For example cheating in the protocol proposed in \cite{Lindell_CnC_2013} goes undetected with probability $2^{-s}$.

			\subsubsection{Issues}
				Cut and Choose seems very simple conceptually, but it creates several subtle new problems to be solved.\\

				\noindent \textbf{Input consistency} Whilst evaluating the many circuits we must now also ensure that both parties provide the same inputs to each evaluation  circuit, else they might be able learn many outputs. Aggregating these results might then reveal something about the input of the Building party.\\

				In \cite{LindellAndPinkas2007} the example is given of computing the inner product of two binary strings, in this situation the Executing party could give many different inputs each with a single bit set to $1$. The output of the circuit would then give the Executor the value of the Builder's input bit corresponding to the high bit in the Executor's input.\\

				\noindent \textbf{Revealing circuit secrets}In order to open the check circuits the Executor needs obtain both keys for each of its input wires for the check circuits without revealing its input. To this end after the Oblivious Transfers have taken place the Executor reveals the check-set and requests all input keys for these circuits.\\

				Note that as the OT has already taken place the Executor can now check that the Builder provided the correct inputs to the OT by comparing its output from the OT with the keys it now receives.\\

				\noindent \textbf{Checking Circuit Correctness} Given all keys for the inputs wires how does one go about check the correctness of a circuit? The simplest method is for the Builder to seed the randomness used for each circuit differently and then send the seed for each circuit to be opened. The Executor can then fully re-build each check circuit using this seed and the full inputs sets and check that the resulting circuit is equal to the check circuit.\\

				At this point we should mention a bandwidth/memory optimisation first put forward in \cite{HashCheckOpt}. Goyal et al. observed that instead of sending the full set of circuits the Builder could instead send a hash of each circuit.\\

				Then when checking correctness, the Executor could construct the circuit as use, hash it and compare this to the hash given by the Builder. This means that then the Builder only needs to send the evaluation circuits in full, reducing bandwidth usage significantly. This is not an optimisation we have implemented.\\

				\noindent \textbf{Output Determination} How should the Executor react to differing outputs from the evaluation circuits? Whilst it is tempting to simply abort immediately this opens the Executor up to an attack referred to as a \emph{selective failure} attack. This is where the Builder crafts one (or more) of the circuits to fail in some way if the input from the Executor fulfils some condition (e.g. if the first bit is 1). Then the Executor aborting due to differing outputs from Evaluation Circuits leaks information about whether the Executor input satisfies the condition or not.\\

				This leaves the Executor needing to determine what output to give in this situation? The answer to this question affects how many circuits are needed to achieve a certain level of statistical security. One approach to this has the Executor return the majority output on each output wire.\\
				
				Then if we have $S$ many circuits, $t$ of which are selected as check circuits the Builder will need to submit at least $\frac{S - t}{2}$ many corrupted circuits else the bad circuits will certainly be outvoted when it comes to decided the majority output. However, the Builder also requires that none of the corrupted circuits are selected as Check circuits, else their cheating will be detected.\\

				\noindent \textbf{An aside} The Builder cannot hardcode its input anymore. Whilst assessing the correctness of the check circuits the Executor is given both keys for each input wire, including those belonging to the Builder. So if the Builder has hardcoded the keys the Executor can tell which key it was given hardcoded and know the Builder's input. Instead the Builder must wait until after the check-set is revealed to send its inputs for only the evaluation circuits.

	\chapter{Summary of Actively Secure Protocols to be implemented} \label{sec:Protocols}
		We now give an overview of each of the protocols we have implemented. This is not intended to be a full blow-by-blow explanation of the protocols, instead we intend on giving the reader a high-level intuition of the key points of each protocol. We will dig a little deeper into a few points of each protocol, particularly where we feel the original papers were not as clear as they could be.

		\section{Lindell and Pinkas 2011}
			\subsection{Overview}
				The protocol proposed in \cite{LindellAndPinkas2011} is a significant improvement on their previous proposal \cite{LindellAndPinkas2007} both in terms of performance and conceptual simplicity.\\

				This protocol gives an improved deterrent probability of $\epsilon = 1 - 2^{-0.311 S}$, further the work in \cite{ShelatAndShen} showed how to achieve a slightly improve deterrent probability of $\epsilon = 1 - 2^{-0.32 S}$.\\

				A key improvement is the removal of the very large number of commitments entailed in \cite{LindellAndPinkas2007}. These commitments formed one of the main costs in the Lindell-Pinkas-Smart\cite{LindellPinkasSmart2008} implementation of the previous protocol. Indeed Lindell and Pinkas comment in their introduction to \cite{LindellAndPinkas2011} that the previous protocol, when running on a circuit with input size $128$, required $6,553,600$ commitments.\\

				Another big improvement is this protocol does not require the preprocessing of the circuit that vastly inflates the number of input wires for the Executor and thus the number of Oblivious transfers needed.

			\subsection{Cut and Choose Oblivious Transfer}
				The main new idea in this protocol is a modification of the PVW-OT from \cite{PVW_OT_2008}. We refer to this new OT as the ``Cut and Choose OT''(CnC OT). The Receiver generates a random $J \subset [1, ..., S]$ during the setup such that $\vert J \vert = \frac{S}{2}$,  this set is kept secret from the Sender till later). The represents a subset of the $S$ circuits to be opened in order to check for correctness, we call this the \emph{J-set}.\\

				This set $J$ is then used to generate $S$ many CRSs, each CRS to be used for the OTs to obtain inputs for a different circuit that the Builder sent. For the $j^{th}$ CRS if $j \in J$ then an OT using this CRS will reveal \emph{both} values input by the sender rather than the usual 1-out-of-2 values, otherwise the usual OT functionality holds.\\

				The Executor can then reveal for which circuits it received both values for each input wire, in doing so proves those circuits at least belong to the J-set. The Builder can then reveal all information required to fully decrypt these check circuits, allowing the Executor to test the correctness. The keys representing the Builder's input for each wire for the evaluation circuits are then sent, allowing the Executor to evaluate all the non-check circuits.\\

				A subtle detail that may have passed the reader by is that we require the Executing party be able to prove that at most $\frac{S}{2}$ many of the CRSs allow the recovery of both inputs.\\ 

				This is achieved via a Zero Knowledge Proof detailed in Appendix B of \cite{LindellAndPinkas2011}, we will not dwell upon it other than to say it uses a secret sharing scheme to modify the classic Sigma-protocol for proving a Diffie-Hellman tuple to prove that at most $\frac{S}{2}$ of the CRSs allow recovery of both inputs.

			\subsection{Consistency of Builder's inputs}
				Lindell and Pinkas present a conceptually elegant method for ensuring the consistency of the builder's inputs. Before building the circuits the builder takes a group $\mathbb{G}$ in which the Discrete Log problem is hard. It then generates $\{a_i^0, a_i^1\}_{i = 1}^{l}$ where $l$ is the number of builder's input wires and $\{r_j\}_{j = 1}^{S}$ where $S$ is the number of circuits.\\

				The Builder then computes $\{g^{a_i^0}, g^{a_i^1}\}_{i = 1}^{l}$ and $\{g^{r_j}\}_{j = 1}^{S}$ which are sent to the Executor as commitments to the secret keys. Then $K_0 = H(g^{r_j^{a_i^0}})$ is used as the $0$-key on the $i^th$ Builder input wire in the $j^{th}$ circuit. Similarly the Builder uses $K_1 = H(g^{r_j^{a_i^1}})$ as the $1$-key on the same wire.\\

				Then inputs for circuit $j$ can be revealed to the Executor by sending $r_j$, with which the Executor can compute the keys using the commitments to the $a$ values. This reduces the bandwidth needed for revealing the check-circuit keys significantly.\\

				Lindell and Pinkas note this means the keys are \emph{Pseudo-Random Synthesizers} \cite{PseudoRandomSynth}, so if some of the keys are revealed (a necessity for checking correctness of circuits) the rest remain pseudo random.\\

				Now note that $(g, g^{r_j}, g^{a_i^0}, g^{r_j^{a_i^0}})$ and $(g, g^{r_j}, g^{a_i^1}, g^{r_j^{a_i^1}})$ are both Diffie-Hellman tuples. Further note that if we take $K$ to be the Builder's input key (either $K_0, K_1$  then only one of $(g, g^{r_j}, g^{a_i^0}, K)$ and $(g, g^{r_j}, g^{a_i^1}, K)$ is a Diffie-Hellman tuple.\\

				This property is the basis for proving the consistency of the Builder's inputs using the Zero Knowledge Proof for an Extended Diffie-Hellman tuple put forwards in Appendix B of \cite{LindellAndPinkas2011}.

				\subsubsection{Extended Diffie-Hellman Tuples}
					The last detail we shall touch upon for the Lindel-Pinkas 2010 protocol is the Zero Knowledge proof of an Extended Diffie-Hellman(DH) tuple. As already mentioned this is used to prove the consistency of the Builder's inputs to the evaluation circuits.\\

					An Extended DH tuple is a tuple of elements $(g, h, u_1, ..., u_l, v_1, ..., v_l)$ such that each $\{(g, h, u_i, v_i)\}_{i = 1}^{l}$ is a DH Tuple. When proving the consistency of the $i^{th}$ Builder input the parties input $(g, g^{a_i^0}, g^{a_i^1}, U, V)$ where $U = \{g^{r_j}\}_{j \notin J}$ and $V$ is the Builder's inputs in Group element form.\\

					The Parties then engage in a Zero Knowledge Proof that either $(g, g^{a_i^0}, U, V)$ is an Extended DH tuple or $(g, g^{a_i^1}, U, V)$ is.\\

					Lindell and Pinkas provide a pre-processing step that reduces the Extended DH tuple problem to a standard DH tuple problem. The pre-processing is as follows,

					The Verifying party(V) generates $\{\delta_i\}_{i = 1}^{l}$ random exponents and sends them to the Proving party(P). P then computes,
					
					$$\tilde u = \prod^{l}_{i = 1} u_i^{\delta_i}, \tilde v = \prod^{l}_{i = 1} v_i^{\delta_i}$$

					Then note that if $(g, h, U, V)$ is an Extended DH tuple then $(g, h, \tilde u, \tilde v)$ will be a standard DH tuple. Thus we reduce the number of Zero Knowledge proofs from $l$ to 1.

		\section{Lindell 2013}
			\subsection{Overview}

				In \cite{Lindell_CnC_2013} Lindell proposed further improvements on his work with Pinkas in \cite{LindellAndPinkas2011}.\\

				Lindell uses a Secure Computation to determine the output that will produce the correct output if even only one of the evaluation circuits produces the correct output.\\

				This means that to successfully cheat a malicious builder will need to corrupt every evaluation circuit guessing \emph{exactly} which circuits will be selected as check circuits. If the guess made by the malicious builder is wrong on even one circuit the cheating will either be detected (if it corrupts a check circuit) or ignored (if it fails to corrupt every evaluation circuit).\\

				Lindell suggest this Secure Computation be carried out using the protocol he authored with Pinkas in \cite{LindellAndPinkas2011} using a small circuit he provides. The hope is that, especially for large circuits, this small secure computation will be relatively cheap.\\

				In order to take full advantage of this improved output determination Lindell modifies the Cut and Choose Oblivious Transfer in \cite{LindellAndPinkas2011}. The modification removes the requirement that exactly half the circuits are selected as check circuits. Instead each circuit is selected with probability $\frac{1}{2}$.\\

				This modification of the OT requires a series of Zero knowledge proofs. However, as we shall see it also allows a significant reduction in the number of circuits needed and so the number of OTs needed. One of the purposes of our implementation is to find out if this exchange is worth it.\\

				As each circuit is chosen to be a check-circuit with probability $\frac{1}{2}$ this is effectively requiring a malicious adversary to guess at a random element in the set $\{0, 1\}^s$ in order to cheat successfully. Therefore such a builder can only successfully cheat with probability $2^{-S}$. (It is a worth noting here that as at least one circuit needs to be checked and at least one needs to be evaluated that there are really $2^{-S+1}$ sets).

			\subsection{Secure Computation to detect cheating}
				The Builder constructs all the circuits so that the keys for output wires are the same across all circuits, call these consistent output keys $\{b_i^0, b_i^1\}_{i = 1}^{h}$ (where there are $h$ many output wires). Further we denote the input of the Builder to the circuit as $x$.\\

				Then if any of the circuits evaluated by the Executor give different outputs on any output wire (say output wire $i$) the executor will obtain both $b_i^0$ and $b_i^1$, these will then be used as input to the cheating detection. If all circuits produce the same output then the Executor randomly generates this input to the cheating detection.\\
					
				The parties then perform a Secure Computation to detect cheating (here on in, the Sub-computation) where the Builder inputs $x$ (its original input to the main computation) and  we call the Executor's inputs $b$. The Secure Computation returns $x$ to the Executor if its input $b$ indicates it knows both $b_i^0$ and $b_i^1$ for some $i$, otherwise it returns garbage.\\

				This can be achieved with a circuit that takes each $b_i^0 \Vert b_i^1$ as hardcoded inputs, the Executor then inputs some $b$ as above. The circuit then checks $b$ against each $b_i^0 \Vert b_i^1$ using NXOR gates, ANDs the results for each $i$ before ORing all the results. This will yield a $1$ if $b$ is equal to some $b_i^0 \Vert b_i^1$ and $0$ otherwise. This circuit will work, but it is very large and as such impractical, we will see optimisations later.\\

				We need to be sure the Builder inputs the same $x$ to the sub-computation as the main computation. This can be done by using the same consistent input style as in the Lindell-Pinkas 2010 protocol.\\

				Lindell suggests using the Lindell-Pinkas protocol for this secure computation and gives several iterations of optimisations for the circuit to compute the function. We skip some of these optimisations, particularly those rendered obsolete by later optimisation. For the full history of optimisation see Lindell's paper.\\

				First let the builder choose $\{b_i^0, b_i^1\}$ and some $\delta \in \{0, 1\}^{128}$ such that $b_i^0 \oplus b_i^1 = \delta$ for all $i$. We can then check if they Executor knows $\delta$ in rather than checking to see if they know $b_i^0$ and $b_i^1$ for each pair, reducing the size of hte circuit (and bandwidth for sending it) significantly. Given only one of the pair the Executor gains no knowledge of $\delta$ so security is maintained. The Executor's input to the sub-computation is then $\delta'$.\\

				This optimisation requires an extra check, after the Executor has committed to his guess at $\delta$ the Builder must then revealed $\delta$ to prove that the $\{b_i^0, b_i^1\}$ set is consistent with a single $\delta$.\\

				Secondly, as we are aiming for statistical security of $2^{-S}$ we only need to check $S$ many bits of the $\delta$, reducing the number of inputs and so the number of OTs required.

				\subsubsection{The Oblivious Transfer Optimisation}
					Lindell finally describes a method to eliminate completely the gates for comparison between $\delta$ and $\delta'$ with an elegant use of the OTs we were already going to have to perform. Suppose that the Builder construct the check circuit with the Executor's input as a single bit, indicating knowledge of $\delta$.\\

					Then take the keys for the single Executor input wire for the $j^{th}$ circuit to be $\{k_0^j, k_1^j\}$. All the $k_0^j$ can be simply sent to the Executor. Then for each circuit $j$ construct the set $\{Y_i^j\}_{i = 1}^{S}$ such that $Y_1^j \oplus ... \oplus Y_S^j = k_1^j$.\\

					The parties then run a CnC OT over $S$ many pairs where for the $j^th$ circuit in the $i^th$ pair $P_{\delta_i} = Y_i^j$ while $_{\delta_i}P$ is random (where $\delta_i$ is the $i^{th}$ bit of $\delta$). For each input $i$ the Executor asks for the $\delta'_i$ member of the pair.\\

					If $\delta = \delta'$ then the Executor will be able to use the outputs of the OT to compute $k_1^j$ for every $j$. If, however, the Executor gets even one bit wrong then the value of $k_1^j$ will be completely hidden. The Cut and Choose nature of the OT allows the Executor to recover $k_1^j$ for every check circuit once $\delta$ is revealed.

				

		\section{Huang, Katz and Evans 2013}
			\subsection*{Overview}

				Concurrently to Lindell's work in \cite{Lindell_CnC_2013} Huang, Katz and Evans produced a protocol also based along the same cut and choose paradigm. However, in their protocols the parties symmetrically generate a set of circuits and then evaluate each others circuits.\\

				Output determination for each output wire is such that the value for an output wire is only taken if the partner obtained the same value for that output wire in at least one of their evaluation circuits.\\

				The observant reader might question what one does if a party gets both $0$ and $1$ on some output wire in different circuits, and likewise for the other party. We claim this situation is only possible if both parties cheated, in which case we care little for either party's plight.\\

				If at least one party is honest then this party will provide honest circuits and will only provide the keys required to get one output from these circuits. As such at least one party will have the correct value for every output wire in all their evaluation circuit.\\

				The probability of a malicious adversary successfully cheating is stated as $2^{-S + log(s)}$ where $S$ is the number of circuits created by \emph{each} party. Note this means that we actually need to create $\sim 2S$ many circuit so this protocol requires a factor of about $3/2$ less circuits for the same security level as \cite{LindellAndPinkas2011} (we ignore the log factor here but include it in our implementation).
				
			\subsection{Consistency of party's inputs} \label{sub:HKE_Consistency}
				The Lindell-Pinkas approach for ensuring inputs from parties are consistent involves expensive zero knowledge proofs. Furthermore, in the symmetric paradigm this approach is problematic as $P_1$ (resp. $P_2$) needs to know that $P_2$ ($P_1$) gave consistent inputs both to the circuits $P_2$ ($P_1$) created and to the circuits $P_1$ ($P_2$) created. Furthermore, this must be accomplished without leaking any knowledge of the either party's input bits to the other.\\

				The solution to this problem presented by Huang et al. is an elegant one, based on the form of the queries sent by the receiver in the Naor-Pinkas OT and the `hardness' of the Discrete Logarithm problem.\\

				Clearly $P_2$ will need to engage in an OT with $P_1$ to get its inputs for the circuits $P_1$ has sent to it. Recall in a Naor-Pinkas OT both parties generate a $C$ in the group at random, and send this to their partner. Each party then refers to the $C$ received from its partner as $\tilde C$. Then the query sent by $P_2$ for its $i^{th}$ input bit will be of the form,

				$$
				h_i = \bigg\{
					\begin{matrix}
						g^{k_i}, & x_i = 0\\
						\tilde C / g^{k_i}, & x_i = 1
					\end{matrix}
					\textnormal{,  where } k_i \textnormal{ is the key for } P_1 \textnormal{'s } i^{th} \textnormal{ input bit.}
				$$

				These queries are used for Naor-Pinkas OTs for all the circuit built by $P_1$ and as such $P_2$ obtains consistent input keys from the OT stage. Effectively the queries commit a party to its input bit string.\\

				This deals with ensuring each party uses consistent keys for the circuits it executes, next we ensure those keys are further consistent with the ones given to the party's partner for executing the circuits it built. Huang et al. propose that when building their circuits each party make their input keys be of the form
				
				$$
				\begin{matrix}
					k_{i,j}^0 = g^{a_0^i}\\
					k_{i,j}^1 = \tilde C / g^{a_1^i}
				\end{matrix}
				$$

				Now consider the value of $A = h_i / k_{i,j}^{b}$ for any $j$ and some $b \in \{0, 1\}$. If $b = x_i$ when $x_i$ is the input bit used to generate $h_i$ then the $\tilde C$s cancel and using the laws of exponentiation the querying party can compute the discrete logarithm of $A$ over $g$.\\

				However, $b \neq x_i$ if there will be some factor of $\tilde C$ in $A$. As $\tilde C$ was generated by the other party the querying party does not know the discrete log of $\tilde C$ and so cannot compute the discrete log of $A$ over $g$. Therefore if the querying party can demonstrate knowledge of the discrete logarithm of $A$ over $g$ its partner can take this as proof of the consistency of the querying party's inputs to both sets of circuits.

			\subsection{Output determination}
				Huang et al. use a verifiable secret sharing scheme for the output determination. For each output wire in the circuit representing the function the parties each randomly generate two secrets. One secret represents a $0$ output on that wire, the other represents a $1$ output. For $P_1$ label these $(S_i^0, S_i^1)$ where $i$ is the output wire. In the case of $P_2$ label them $(T_i^0, T_i^1)$.\\

				From here on in we look from one party's perspective, the other party mirrors the behaviour we specify.\\

				$P_1$ creates a secret sharing scheme for each $S_i^b$ with $S$ many shares and a threshold such that $\frac{S}{2} + 1$ many shares are needed to reconstruct the secret. Label these shares $W_{i, j}^b$, $b$ being the output bit value on the $i^{th}$ output wire for the $j^{th}$ circuit.\\

				Then when sending the secrets required to assess the correctness of the check circuits $P_2$ also sends $\{W_{i, j}^0, W_{i, j}^0\}, \forall j \in J, \forall i$. This means $P_1$ is now in possession of $\frac{S}{2}$ many shares for $S_i^b$, as such $P_1$ only needs one more share to uncover the secret.\\

				$P_2$ evaluates the remaining circuits and for each output wire $i$ if any evaluation circuit outputs $0$ on that wire the $P_2$ can recover the secret $\tilde S_i^0$, similarly for $\tilde S_i^1$. If there is no circuit that outputs $b$ on output wire $i$ then $P_2$ sets $\tilde S_i^b$ to be random. Symmetrically $P_1$ obtains $\tilde T_i^0$ and $\tilde T_i^1$.\\

				Finally the parties run \emph{weak} secure equality tests (weak in the sense the inputs are revealed at the end) for each natural pair of secrets. $P_1$ inputs $X_i^b = S_i^b \oplus \tilde T_i^b$ whilst $P_2$ inputs $Y_i^b = \tilde S_i^b \oplus T_i^b$. If equality holds then the parties know that each party evaluated output wire $i$ to $b$ in at least one evaluation circuit.\\

				If for some output wire $i$ neither $X_i^0 = Y_i^0$ nor $X_i^1 = Y_i^1$ then both parties abort as they have no valid output for the $i^{th}$ output wire. Huang et al. suggest that by convention the parties should test the $0$-value secrets first, and if equality holds there skip the equality test on the $1$-value secrets.\\


			\subsection{Advantages of symmetrical cut-and-choose}
				As the protocol is symmetrical, both parties will be working symmetrically reducing wall clock delays caused by one party having more work to do leaving the other party idle, so depending on how this works out in practise this could mean an improvement in wall clock time of around $3$ times quicker.\\

				Once again it is difficult to estimate how much of an improvement this will provide when implemented, but given two parties of similar capabilities we would expect high CPU/Wall time ratio, due to the lack of idling.


		\section{Merging Lindell 2013 and HKE 2013}
			In the Lindell 2013 protocol the Sub-computation is carried out using the Lindell-Pinkas 2010 protocol. The natural question, given the HKE protocol requires fewer circuits to achieve the same level of statistical security as Lindell-Pinkas, is can we alter the sub-computation to use HKE?\\

			This is very simple conceptually, but we must be careful of a few subtle problems, indeed the solutions to these require us to modify the behaviour of the protocol outside the sub-computation.\\

			At this point it should be noted that while I will argue \emph{informally} that my merging of Lindell 2013 and HKE is secure I give no formal proof, as such this should not be used seriously till such a formal proof exists.

			\subsection{Problems to address}
				At first this seems like a trivial matter, merely change the sub-computation implementation to use HKE instead of Lindell-Pinkas. However, consider the following questions, all of which arise due to the symmetrical nature of HKE.

				\begin{enumerate}
					\item The consistency of the Builder's input to the main computation and the sub-computation must be assured, but now it must also be assured in the sub-computation circuit built by the Executor.

					\item In the final optimisation of the sub-computation the Executor's input to the sub-computation circuit is a single bit, indicating if it knows $\delta$. When the Executor is building some of the circuits what happens if the Executor giving its input bit as $1$?

					We shall in fact give an attack that could be used here that would leak the value of one bit of the Builder's input. As such we are forced to `roll back' to the previous level of optimisation.

					\item The output of the sub-computation must be concealed from the Builder, else the Builder might be able to tell whether the Executor received inconsistent results from the main computation circuits. This would open the door to what is effectively a selective failure attack.

				\end{enumerate}


			\subsection{Consistency of Builder's inputs}
				Recall in the Lindell-Pinkas / Lindell protocols consistency of the builder's inputs can be assured by the use of a `base key' for each bit value on each input wire. By using a common starting point and then adding in some randomness for each circuit the Builder creates keys that are still indistinguishable to the Executor. They can then run a Zero Knowledge proof that the keys used by the Builder are an Extended Diffie-Hellman Tuple derived on the same `base key'.\\

				Clearly we could extend this to be used for the Builder's inputs to the Builder's sub-computation circuits. However, I see no way for this to be extended to the builder's inputs to the Executor's sub-computation circuits. Fundamentally the Zero Knowledge Proof proves that,
				
				$$\forall j (g, g^{r_j}, g^{a_i^0}, k_{i,j}) \in DH \textnormal{ OR } \forall j (g, g^{r_j}, g^{a_i^1}, k_{i,j}) \in DH$$

				This causes serious problems because both parties need to know $k_{i,j}$, and as the Executor generated $k_{i,j}$ if the Builder tells the Executor which one to use for the proof then the Executor learns the Builder's input bit. Whilst there are probably ways to alter the Zero Knowledge Proof to account for this I propose a simpler and more efficient solution by using the HKE approach to consistency.\\

				Suppose the Builder's inputs to the main circuit are produced so to be in the same form as given in Subsection \ref{sub:HKE_Consistency}. Furthermore the Builder's inputs to the sub-computation circuits it builds are also of this form. Both sets of inputs use the same $\tilde C$.\\

				The Builder obtains his inputs for the sub-computation circuits sent by the Executor by Naor-Pinkas Oblivious Transfer as is usual in the HKE protocol. Then the Builder can prove the consistency of his input to all three sets of circuits using knowledge of logarithm trick used in the HKE protocol.\\

				Whilst changing the consistency checks is a side-effect of the other changes it also gives significant performance improvements. Two main reasons for these appear to be the HKE approach using many more fixed-base point multiplications which are significantly faster, and the removal of the expensive Zero Knowledge Proofs.\\

			\subsection{Ensuring consistency of Executor's inputs}
				\subsubsection{An attack on the OT optimisation}
					In the final optimisation suggested in \cite{Lindell_CnC_2013} the sub-circuit is reduced so that the Executor only inputs a single bit, indicating knowledge of $\delta$. The 0-value key for this wire is given freely to the Executor. The Executor then obtains the 1-value in a series of cut-and-choose OTs where the Executor only learns the value by.\\

					This approach cannot be used when we are using a symmetric paradigm for the sub-computation because the Builder cannot verify that the consistency of the Executor's inputs beyond each circuit set. Suppose then that the Builder is honest the Executor therefore has not obtained $\delta$. Then his input to the circuits created by the Builder will have to be $0$. However, no such restriction exists on his input to the circuit it created.\\

					Therefore the circuits evaluated by the Builder will output $X$ (where $X$ is his input to the main computation). The circuits evaluated by the Executor will output $00...0$. So when it comes to the Secure Equality testing the parties will abort on the first bit where $X$ is $1$, leaking information about the Builder's input to the computation.\\

				\subsubsection{Rolling Back}
					The reason the aforementioned attack exists is the fact that the Executor can simply set its input to $1$ and the Builder has no way to tell if this is consistent with the Executor's input to the other circuits.\\

					We therefore take a step back and return to the Builder inputting the first $S$ many bits of $\delta$ and the Executor inputting the first $S$ bits of $\delta'$. This does not cost us as much as one might think, while it increases the size of the circuit it does so only a little and by a factor that is unaffected by the size of the main computation inputs. This current round of modification to the sub-computation leaves us requiring $|X| \cdot S + 2 \cdot S^2$ many OTs with a circuit size of about $S + 2 \cdot |X|$.

			\subsection{Hiding output from Builder}
				We need to ensure that the Builder gains no knowledge from the sub-computation about whether the Executor input $\delta' = \delta$. If the Builder can tell if the sub-computation output all zeroes or $X$ then it knows if the Executor received inconsistent outputs from the main computation circuits. This gives rise to an indirect selective failure attack whereby the Builder crafts the main computation circuits so the Executor will get inconsistent outputs if some condition is met by the Executor's inputs. Thus if the Builder can discern that the Sub-computation output $X$ it knows the Executor's input satisfies this condition.\\

				This is not an issue in the original Lindell 2013 protocol as the Builder does not evaluate any circuits relating to the sub-computation. However, when we perform the sub-computation with the Huang-Katz-Evans protocol the Builder will be evaluating circuits and takes part in the output determination. To ensure the Builder does not learn anything about the output we further modify the sub-computation circuits to take an extra input from the Executor. This input should be same length as the output and is XORed with the old output.\\

				This would mean the Builder only learns the XORed result of the circuit but the Executor could use his auxiliary input to recover the true output. As in the scenario where we care about the output being hidden from the Builder we can assume the Executor is honest. In this case the outputs from the Executor's circuits will be consistent and the Builder will only see one output and so gains no depth for the key.\\

			\subsection{Performance expectations}

				We expect our modified sub-computation to outperform the version given in Lindell 2013, mainly due to the reduction in the number of circuits needed to achieve the same statistical security.\\

				This said we do not think the margin of superiority will be nearly as great as it could be due to the rolling back of some of the Lindell Optimisations. In particular the hiding of the output determination adds not only to the size of the circuit but also increases the number of inputs requiring OTs etc.\\

				Further we think our modified sub-computation's performance will degrade more quickly than the Lindell version when the input size of the Builder increases as this leads to more Oblivious Transfers while the Lindell version requires a constant number of Oblivious Transfers.\\

				On the other hand our modified protocol reduces the cost of the proof of the Builder's consistency, so it could be that this reduction cancels out the cost of the additional Oblivious Transfer. This is a question we will have to consider when breaking down the measurements for the sub-computations.

	\chapter{Experiments} \label{sec:Results}
		We shall be using the circuits provided in \cite{NigelCircuits} for our experiments with varying randomised inputs, in particular we shall consider
		
		\begin{itemize}
			\setlength\itemsep{0.2em}
			\item 32-bit Addition,
			\item 32-bit Multiplication,
			\item AES encryption.
		\end{itemize} \vspace{-0.9cm}

		\section{Measurement metrics}
			We shall be focusing on three main metrics for measuring performance of the protocols for both parties, namely CPU time used, Wall clock time (both in seconds) used and data sent (in terms of bytes).\\

			We shall break these metrics down further so that we can see measure the performance of each part of the protocol for the purpose of identifying the bottlenecks for each protocol.

		\section{Testing Environment}
			All tests were carried out between two test machines each with an i7-3770S CPU clocked at $3.10$ GHz with $8096$ KB of cache and $32$ GB of RAM. These machines both possess dedicated network cards for communications with the other member of the pair. Compilation was performed with g$++$ version 4.4.7. 


		\section{Notes on the form of Experiments}
			All tests are configured to given a deterrent probability of $1 - 2^{40}$, or put in other terms, a statistical security parameter of $40$.\\

			For each protocol we ran a 100 evaluations on each test circuit, the figures given below are taken from the average of these experiments. As already noted we measure performance in terms or Wall/CPU time (in seconds) and in terms of data sent/received (in Bytes).\\

			We further took sub-measurements for the important parts of the protocol, allowing us to identify which part of a protocol is the most expensive. We refer to check circuits as the \emph{J-Set}.\\

			The HKE protocol is symmetric and therefore given the circuits all have equal divisions of input sizes there is no purpose is giving measurements for both parties when they are running in identical environments. As such for each measurement we simply give the measurements for Party 1, 


		\section{Expectations}
			Before giving the results of our experiments we shall first give some expectations we had for each circuit and some thoughts on the circuits themselves.

			\subsection{32-bit addition}
				The 32-bit addition circuit is the smallest circuit we consider, consisting of only 349 gates. Each party inputs 32-bits and the circuit outputs the addition of the inputs considered as a 33-bit integers.\\

				We expected to see a poor showing from the Lindell 2013 protocol due to the circuits small size increasing the relative cost of the sub-computation. For the Lindell 2013 and the L-HKE 2015 protocols the small size of the circuit lead us to expect the Sub-computation will dominate running time on this circuit.\\

				For other protocols due to the relatively high input wire to gate ratio we expect the cost of Oblivious Transfers (and other input size dependant part of the protocol) to be the main cost in terms of running time.

			\subsection{32-bit multiplication}

				The 32-bit multiplication circuit is significantly larger than addition yet smaller than AES, providing a good mid-way stepping stone to the AES circuit in terms of number of gates. Additionally, as the number of outputs is larger and this should affect the time taken to run output determination for the HKE protocol.\\

				Furthermore, as the inputs sizes are the same for both parties the number of OTs is the same as in the Addition circuit, meaning we get to see how much importance the `depth' (size of circuit discounting inputs) of the circuit has with regards to performance. We expect to see the costs of OTs to remain the same and for the circuit building/checking times to increase.\\
				
				The multiplication circuit has around $30$ times more gates than the addition circuit so it will be on interest to compare how long it takes to build and to check correctness for the multiplication circuit compared to the Addition circuit.

			\subsection{AES encryption}

				AES encryption is a classic benchmark for Secure two part computations. We will be considering the version without The RTL circuit provided from \cite{NigelCircuits} for this computation has $\sim 39,000$ gates, 128 inputs for each party and 128 outputs. One party inputs a message, the other inputs a key.\\

				The Oblivious Transfers should increase in cost along with the increase in the number of inputs, however should also see a fairly large increase in the cost of the input consistency proofs.
				% We considered experimenting with the alternative circuit provided by \cite{NigelCircuits} which takes in an expanded key schedule reducing the circuit size in exchange for an increase in the number of inputs by a factor of $10$ for the Executor. However, while the reduction in circuit size would reduce building, checking and evaluation time this would be more than nullified by the increase in the number of inputs and the increase in the number of OTs involved.

		\section{Results}
			We now give results of using each of the Protocol on the test circuits with some comments on the results for each table, these comments will not focus overly much on the comparison between the protocols. Furthermore when summarising each circuit we will give a few notes detailing where we think our implementation has the most room for improvement.

			\FloatBarrier
			\subsection{Lindell-Pinkas 2010} \label{sub:LP_2010_Results_Analysis}

				\FloatBarrier
				\noindent \textbf{32-bit Addition}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $0.18$ & $0.02$ & $0$ & $0$ \\
						\hline
						Building circuits & $20.39$ & $2.69$ & $0$ & $0$ \\
						\hline
						OT- Sender & $82.75$ & $11.80$ & $1,214,877$ & $655,111$ \\
						\hline
						Sending circuits/commits & $0.63$ & $2.43$ & $6,125,691$ & $0$ \\
						\hline
						Open check circuits & $3.19$ & $3.20$ & $289,396$ & $2,214$ \\
						\hline
						Prove input consistency & $6.82$ & $7.27$ & $18,110$ & $79,784$ \\
						\thickhline
						Total & $113.96$ & $27.41$ & $7,648,074$ & $737,109$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Builder in the Lindell-Pinkas 2010 protocol evaluating the 32-bit addition circuit averaged over 100 trials. \label{table:LP_2010_Add_Builder}}
				\end{figure}
					
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT prep receiver & $17.60$ & $2.60$ & $0$ & $0$ \\
						\hline
						OT transfer receiver & $18.93$ & $14.18$ & $655,111$ & $1,214,877$ \\
						\hline
						Receive circuits/commits & $0.40$ & $0.05$ & $0$ & $6,125,691$ \\
						\hline
						Checking correctness & $11.57$ & $3.20$ & $2,214$ & $289,396$ \\
						\hline
						Verify input consistency & $6.87$ & $7.28$ & $79,784$ & $18,110$ \\
						\hline
						Evaluate circuits & $0.03$ & $0.03$ & $0$ & $0$ \\
						\thickhline
						Total & $55.90$ & $27.45$ & $737,109$ & $7,648,074$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the Lindell-Pinkas 2010 protocol evaluating the 32-bit addition circuit averaged over 100 trials.\label{table:LP_2010_Add_Executor}}
				\end{figure}
				\FloatBarrier

				As expected the Oblivious Transfers dominates the running time of the protocol on such a small circuit with relatively many input wires, especially for the Executing party as it does not bear the burden of building all the circuits.\\

				The communication costs are dominated by sending circuits. In future our implementation could be significantly improved by using the circuit hash trick for circuit correctness.\\


				\FloatBarrier
				\noindent \textbf{32-bit Multiplication}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $0.18$ & $0.02$ & $0$ & $0$ \\
						\hline
						Building circuits & $31.53$ & $4.21$ & $0$ & $0$ \\
						\hline
						OT- Sender & $82.70$ & $11.82$ & $1,214,877$ & $655,111$ \\
						\hline
						Sending circuits/commits & $1.01$ & $4.10$ & $202,012,291$ & $0$ \\
						\hline
						Open check circuits & $3.19$ & $3.22$ & $289,396$ & $2,214$ \\
						\hline
						Prove input consistency & $6.82$ & $7.27$ & $18,109$ & $79,784$ \\
						\thickhline
						Total & $125.43$ & $30.65$ & $203,534,673$ & $737,109$ \\
						\hline
					\end{tabular}

					\caption{The performance of the Builder in the Lindell-Pinkas 2010 protocol evaluating the 32-bit multiplication averaged over 100 trials. \label{table:LP_2010_Mul_Builder}}
				\end{figure}
				
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT prep receiver & $17.59$ & $2.60$ & $0$ & $0$ \\
						\hline
						OT transfer receiver & $18.69$ & $14.20$ & $655,111$ & $1,214,877$ \\
						\hline
						Receive circuits/commits & $1.65$ & $1.75$ & $0$ & $202,012,291$ \\
						\hline
						Checking correctness & $17.14$ & $3.19$ & $2,214$ & $289,396$ \\
						\hline
						Verify input consistency & $6.86$ & $7.28$ & $79,784$ & $18,109$ \\
						\hline
						Evaluate circuits & $0.84$ & $0.84$ & $0$ & $0$ \\
						\thickhline
						Total & $63.53$ & $31.50$ & $737,109$ & $203,534,673$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the Lindell-Pinkas 2010 protocol evaluating the 32-bit multiplication averaged over 100 trials. \label{table:LP_2010_Mul_Executor}}
				\end{figure}
				\FloatBarrier

				The Multiplication circuit takes only a little longer to run, and our prediction with regards to the Oblivious Transfer remaining steady are borne out. Most of the extra time is spent Building the significantly bigger circuits, but this increase is not linear with the increase in the circuit size. We shall see if this pattern continues with the AES circuit.\\

				The main difference overall is in the bandwidth usage. We send about $25$ times more than we did for the Addition circuit. This has little effect on run time though due to the low cost of communication in our testing environment.\\

				\FloatBarrier
				\noindent \textbf{AES Encryption}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $0.36$ & $0.05$ & $0$ & $0$ \\
						\hline
						Building circuits & $114.32$ & $15.39$ & $0$ & $0$ \\
						\hline
						OT- Sender & $323.83$ & $42.42$ & $4,859,037$ & $2,477,191$ \\
						\hline
						Sending circuits/commits & $1.37$ & $14.81$ & $663,253,047$ & $0$ \\
						\hline
						Open check circuits & $13.12$ & $13.17$ & $751,156$ & $2,214$ \\
						\hline
						Prove input consistency & $27.82$ & $29.15$ & $72,444$ & $319,112$ \\
						\thickhline
						Total & $480.82$ & $114.98$ & $668,935,684$ & $2,798,517$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Builder in the Lindell-Pinkas 2010 protocol evaluating the AES encryption circuit averaged over 100 trials. \label{table:LP_2010_AES_Builder}}
				\end{figure}

				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT prep receiver & $67.53$ & $9.03$ & $0$ & $0$ \\
						\hline
						OT transfer receiver & $70.98$ & $51.55$ & $2,477,191$ & $4,859,037$ \\
						\hline
						Receive circuits/commits & $3.16$ & $5.72$ & $0$ & $663,253,047$ \\
						\hline
						Checking correctness & $56.90$ & $13.15$ & $2,214$ & $751,156$ \\
						\hline
						Verify input consistency & $27.45$ & $29.14$ & $319,112$ & $72,444$ \\
						\hline
						Evaluate circuits & $1.15$ & $1.15$ & $0$ & $0$ \\
						\thickhline
						Total & $227.91$ & $116.15$ & $2,798,517$ & $668,935,684$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the Lindell-Pinkas 2010 protocol evaluating the AES encryption circuit averaged over 100 trials. \label{table:LP_2010_AES_Executor}}
				\end{figure}
				\FloatBarrier

				In the final circuit test for the Lindell-Pinkas Protocol we see the pattern of a fairly linear increase in the communications continue. Similarly we see a fairly linear increase in the cost of the Oblivious Transfers in line with the increase in the number of inputs.\\

			\noindent\textbf{Summary}\\

				Overall most components seem to grow linearly with their input sizes. It is worth noting that the computational costs are heavily imbalanced with the Builder  using around twice as much CPU time as the Executor in all three experiments.\\

				Most of this additional CPU time seems to be spent on the Oblivious Transfers. Communication costs are dominated by the circuits, and so is skewed heavily towards the Builder Sending. This could be greatly reduced using the Hashed circuits trick.\\

				Whilst further experimentation would be needed to check this, it appears the cost of the protocol is primarily linked to the number of Inputs. Further experiments could also test which input size (Builder's or Executor's) has the greatest impact, I suggest it will be the Builders due to the consistency proof.\\

				Lastly we make a side notes with an eye to improving our implementation. The main obvious area for improvement would be the consistency proving stage. At the moment it takes one input wire at a time and therefore does not make use of any extra cores available. This should not be overly taxing however time constraints have prevented us from attempting it. Preliminary investigation (comparing to the ZKPoK in the modified CnC OT) suggest this will speed up the consistency proof by a factor of 4.

			\subsection{Lindell 2013} \label{sub:L-2013_Results_Analysis}
				We do not provide a breakdown of the sub-computation here, this comes later when comparing the sub-computation performance for Lindell 2013 and our variant.\\

				\FloatBarrier
				\noindent \textbf{32-bit Addition}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $0.09$ & $0.01$ & $0$ & $0$ \\
						\hline
						Build circuits/commits & $6.49$ & $0.81$ & $0$ & $0$ \\
						\hline
						OT- Sender & $37.83$ & $8.98$ & $284,040$ & $135,781$ \\
						\hline
						Send circuits/commits & $0.00$ & $0.02$ & $1,889,281$ & $0$ \\
						\hline
						Partially open J-set & $0.99$ & $0.99$ & $88,982$ & $692$ \\
						\hline
						Sub-computation & $117.53$ & $21.85$ & $2,412,286$ & $746,955$ \\
						\hline
						Send B-Lists & $0.00$ & $0.00$ & $1,060$ & $0$ \\
						\hline
						Prove input consistency & $8.27$ & $9.37$ & $18,112$ & $96,764$ \\
						\thickhline
						Total & $171.21$ & $42.03$ & $4,693,761$ & $980,193$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Builder in the Lindell 2013 protocol evaluating the 32-bit addition averaged over 100 trials. \label{table:L_2013_Add_Builder}}
				\end{figure}

				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT - Receiver & $35.46$ & $9.79$ & $135,781$ & $284,040$ \\
						\hline
						Receive circuits/commits & $0.01$ & $0.03$ & $0$ & $1,889,281$ \\
						\hline
						Partially open J-set & $0.03$ & $0.99$ & $692$ & $88,982$ \\
						\hline
						Evaluate circuits & $0.01$ & $0.01$ & $0$ & $0$ \\
						\hline
						Sub-computation & $53.37$ & $21.85$ & $746,955$ & $2,412,286$ \\
						\hline
						Verify B-List & $0.00$ & $0.00$ & $0$ & $1,060$ \\
						\hline
						Checking correctness & $3.63$ & $0.58$ & $0$ & $0$ \\
						\hline
						Verify input consistency & $9.16$ & $8.79$ & $96,764$ & $18,112$ \\
						\thickhline
						Total & $101.69$ & $42.05$ & $980,193$ & $4,693,761$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the Lindell 2013 protocol evaluating the 32-bit addition averaged over 100 trials. \label{table:L_2013_Add_Executor}}
				\end{figure}
				\FloatBarrier

				As predicted the Sub-computation dominates the running time. We also that for such a small circuit the sub-computation is also the biggest single factor in the communication costs, this will not hold as the circuit size increases. The verification of the B-Lists against the Hashed B-list has a negligible cost and in future this measurement could be folded into the correctness check.\\

				We should now note that we expect the running time of the sub-computation to be about the same for the multiplication circuit as here, and only slightly increased for the AES circuit.\\

				\FloatBarrier
				\noindent \textbf{32-bit Multiplication}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $0.09$ & $0.01$ & $0$ & $0$ \\
						\hline
						Build circuits/commits & $9.76$ & $1.24$ & $0$ & $0$ \\
						\hline
						OT- Sender & $37.80$ & $8.99$ & $284,040$ & $135,780$ \\
						\hline
						Sending circuits/commits & $0.12$ & $0.52$ & $62,163,073$ & $0$ \\
						\hline
						Partially Open J-sets & $1.01$ & $1.04$ & $89,081$ & $681$ \\
						\hline
						Sub-computation & $117.91$ & $22.38$ & $2,412,286$ & $746,955$ \\
						\hline
						Send B-Lists & $0.00$ & $0.00$ & $2,052$ & $0$ \\
						\hline
						Prove Input Consistency & $8.31$ & $9.67$ & $18,111$ & $97,167$ \\
						\thickhline
						Total & $175.00$ & $43.86$ & $64,968,644$ & $980,583$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Builder in the Lindell 2013 protocol evaluating the 32-bit multiplication circuit averaged over 100 trials. \label{table:L_2013_Mul_Builder} }
				\end{figure}
				
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT - Receiver & $35.46$ & $10.23$ & $135,780$ & $284,040$ \\
						\hline
						Receiving circuits/commitments & $0.28$ & $0.56$ & $0$ & $62,163,073$ \\
						\hline
						Partially open J-set & $0.03$ & $1.01$ & $681$ & $89,081$ \\
						\hline
						Evaluate circuits & $0.26$ & $0.26$ & $0$ & $0$ \\
						\hline
						Sub-computation & $53.44$ & $22.13$ & $746,955$ & $2,412,286$ \\
						\hline
						Verify B-List & $0.00$ & $0.00$ & $0$ & $2,052$ \\
						\hline
						Checking correctness & $5.58$ & $0.85$ & $0$ & $0$ \\
						\hline
						Verify input consistency & $9.19$ & $8.82$ & $97,167$ & $18,111$ \\
						\thickhline
						Total & $104.28$ & $43.88$ & $980,583$ & $64,968,644$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the Lindell 2013 protocol evaluating the 32-bit multiplication circuit averaged over 100 trials.\label{table:L_2013_Mul_Executor} }
				\end{figure}
				\FloatBarrier

				Once again we see the cost of the Oblivious Transfers remaining steady when moving from the addition circuit to the multiplication circuit and a slight increase in the time taken to build the circuits. \\

				The costs of the sub-computation have not significantly changed when compared to the addition circuit, this was  as none of its input sizes have changed. In fact the overall running time has barely changed, this suggests that this protocol will be of most use when evaluating large circuit that have few inputs.\\

				This is hardly a big revelation though, this is more of a trend with Yao based protocols in general that we see with other protocols too.\\


				\FloatBarrier
				\noindent \textbf{AES Encryption}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $0.27$ & $0.03$ & $0$ & $0$ \\
						\hline
						Build circuits/commits & $36.24$ & $4.58$ & $0$ & $0$ \\
						\hline
						OT- Sender & $142.05$ & $33.20$ & $1,120,488$ & $476,292$ \\
						\hline
						Sending circuits/ommits & $0.33$ & $1.75$ & $204,095,057$ & $0$ \\
						\hline
						Partially open J-set & $4.01$ & $4.05$ & $227,146$ & $701$ \\
						\hline
						Sub-computation & $183.19$ & $37.52$ & $5,018,302$ & $746,955$ \\
						\hline
						Send B-Lists & $0.00$ & $0.00$ & $4,100$ & $0$ \\
						\hline
						Prove input consistency & $33.18$ & $38.11$ & $72,444$ & $385,743$ \\
						\thickhline
						Total & $399.27$ & $119.25$ & $210,537,538$ & $1,609,692$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Builder in the Lindell 2013 protocol evaluating the AES encryption circuit averaged over 100 trials. \label{table:L_2013_AES_Builder}}
				\end{figure}

				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT - Receiver & $138.36$ & $37.80$ & $476,292$ & $1,120,488$ \\
						\hline
						Receive circuits/commits & $0.77$ & $1.80$ & $0$ & $204,095,057$ \\
						\hline
						Partially open J-Set & $0.04$ & $4.02$ & $701$ & $227,146$ \\
						\hline
						Evaluate circuits & $0.35$ & $0.35$ & $0$ & $0$ \\
						\hline
						Sub-computation & $78.95$ & $37.20$ & $746,955$ & $5,018,302$ \\
						\hline
						Verify B-List & $0.00$ & $0.00$ & $0$ & $4,100$ \\
						\hline
						Checking correctness & $18.36$ & $3.13$ & $0$ & $0$ \\
						\hline
						Verify input consistency & $34.05$ & $34.96$ & $385,743$ & $72,444$ \\
						\thickhline
						Total & $270.99$ & $119.27$ & $1,609,692$ & $210,537,538$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the Lindell 2013 protocol evaluating the AES encryption circuit averaged over 100 trials. \label{table:L_2013_AES_Executor}}
				\end{figure}
				\FloatBarrier

				We now get to see how the sub-computation fares in a larger circuit. The cost of the sub-computation increases but by a much smaller factor than the rest of the computation, this is hopeful for applying this protocol to larger circuits.\\

				\noindent\textbf{Summary}\\

					It appears that Lindell's suggestion that this protocol is ill-suited to small circuits is entirely correct. As the circuits get bigger the relative cost of the sub-computation falls and this protocol becomes more useful.\\

					The sub-computation is very expensive (even on the AES circuit around $\frac{1}{3}$ of running time is spent in the sub-computation) so this is an area of the protocol ripe for optimisation.\\

					The obvious avenue for further optimisation will be exchanging the protocol used for the sub-computation, something we have attempted by using the HKE protocol for the sub-computation. This said this method can only take use so far, after all any protocol used for the sub-computation could simply be used for the main computation instead. A method of recovering the Builder's input without having to run a full Yao-Circuit computation would be preferable. \\

					As is usual in asymmetric Yao based protocols the computational load is heavier on the Builder and the Builder sends more data than the Executor. When originally thinking about circuits with differing inputs sizes for the two parties we expected we would be aiming to minimise the Executor's inputs to reduce the number of Oblivious Transfers.\\

					The opposite is true here, due to the expensive proofs for builder input consistency we should aim to minimise the number of inputs for the Builder.


			\subsection{Huang-Katz-Evans 2013} \label{sub:HKE_Results_Analysis}

				\FloatBarrier
				\noindent \textbf{32-bit Addition}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						 & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Circuits prep. & $2.81$ & $0.37$ & $77$ & $77$ \\
						\hline
						Building circuits & $0.14$ & $0.02$ & $0$ & $0$ \\
						\hline
						Exchanging Circuits & $0.31$ & $0.04$ & $2,162,460$ & $2,162,460$ \\
						\hline
						Exchange VSS schemes & $0.03$ & $0.00$ & $37,422$ & $37,405$ \\
						\hline
						Naor Pinkas OT & $12.37$ & $1.55$ & $156,904$ & $156,904$ \\
						\hline
						Make/Send commits & $12.59$ & $1.64$ & $430,126$ & $430,126$ \\
						\hline
						Coin flip for J-set & $0.08$ & $0.01$ & $2,532$ & $2,532$ \\
						\hline
						Initial J-set checks & $14.90$ & $2.41$ & $313,732$ & $313,732$ \\
						\hline
						Logarithm Checks & $1.08$ & $0.23$ & $26,500$ & $26,500$ \\
						\hline
						Output Determination & $1.16$ & $0.50$ & $13,630$ & $13,630$ \\
						\thickhline
						Total & $45.59$ & $6.77$ & $3,143,383$ & $3,143,366$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Huang-Katz-Evans 2013 protocol evaluating the 32-bit addition circuit averaged over 100 trials.\label{table:HKE_2013_Add}}
				\end{figure}

				The results for the Huang-Katz-Evans protocol are very promising. We have a very high CPU time to Wall time ratio (close to 7 with 8 cores available), indicating good parallelism. In particular the Naor-Pinkas OT step and the Commitment manufacturing step both seem to make good use of all available cores, though to be sure we'd need to run with differing numbers of cores.\\ 

				We also see the computational load is well balanced between the parties (as is communication traffic). In situations where the parties are equally capable this is a definite advantage, in cases where one party is more capable it could be a hindrance.\\

				There is no one step of the protocol that clearly dominates running time, though the initial J-set checks take the longest. Whilst I do not have direct data to back up this hypothesis I believe the opening of commitments is the primary cost in the J-set checks. In terms of communications the sending of circuits is the largest single factor as usual.\\

				\FloatBarrier
				\noindent \textbf{32-bit Multiplication}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						 & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Circuits prep. & $2.83$ & $0.38$ & $77$ & $77$ \\
						\hline
						Building circuits & $4.16$ & $0.55$ & $0$ & $0$ \\
						\hline
						Exchanging Circuits & $1.20$ & $1.25$ & $71,476,180$ & $71,476,180$ \\
						\hline
						Exchange VSS schemes & $0.00$ & $0.03$ & $72,529$ & $72,507$ \\
						\hline
						Naor Pinkas OT & $12.56$ & $1.62$ & $156,904$ & $156,904$ \\
						\hline
						Make/Send commits & $12.73$ & $1.67$ & $430,126$ & $430,126$ \\
						\hline
						Coin flip for J-set & $0.10$ & $0.01$ & $2,532$ & $2,532$ \\
						\hline
						Initial J-set checks & $17.36$ & $2.79$ & $342,252$ & $342,252$ \\
						\hline
						Logarithm Checks & $1.08$ & $0.22$ & $26,500$ & $26,500$ \\
						\hline
						Output Determination & $0.85$ & $0.87$ & $26,154$ & $26,154$ \\
						\thickhline
						Total & $54.00$ & $9.73$ & $72,533,254$ & $72,533,232$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Huang-Katz-Evans 2013 protocol evaluating the 32-bit multiplication circuit averaged over 100 trials.\label{table:HKE_2013_Mul}}
				\end{figure}

				The multiplication circuit results are particularly interesting for Huang-Katz-Evans. We predicted that we would see a significant increase in the cost of the output determination due the increase in the number of outputs. We do see a increase in running time though it is slightly below that which we expected, more interestingly there is a \emph{decrease} in CPU time used.\\

				We see the expected increase in cost for the circuit building and the expected lack of change in the cost of the OTs/Commitments/Log checks (all are dependant only on input size). Further we see some support for my hypothesis that the opening of commitments is the main cost in the J-set checks, as the cost goes up only marginally despite the large increase in circuit size (and so circuit correctness check costs).\\

				\FloatBarrier
				\noindent \textbf{AES Encryption}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						& \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Circuits prep. & $10.91$ & $1.47$ & $77$ & $77$ \\
						\hline
						Building circuits & $12.83$ & $1.72$ & $0$ & $0$ \\
						\hline
						Exchanging Circuits & $2.02$ & $4.11$ & $234,679,488$ & $234,679,488$ \\
						\hline
						Exchange VSS Schemes & $0.00$ & $0.05$ & $144,962$ & $144,967$ \\
						\hline
						Naor Pinkas OT & $49.33$ & $6.37$ & $627,592$ & $627,592$ \\
						\hline
						Make/Send commits & $49.63$ & $6.65$ & $1,719,598$ & $1,719,598$ \\
						\hline
						Coin flip for J-set & $0.07$ & $0.01$ & $2,532$ & $2,532$ \\
						\hline
						Initial J-set checks & $54.58$ & $9.62$ & $968,588$ & $968,588$ \\
						\hline
						Logarithm Checks & $3.17$ & $0.78$ & $105,988$ & $105,988$ \\
						\hline
						Output Determination & $1.70$ & $1.73$ & $52,010$ & $52,010$ \\
						\thickhline
						Total & $185.47$ & $32.95$ & $238,300,835$ & $238,300,840$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Huang-Katz-Evans 2013 protocol evaluating the AES encryption circuit averaged over 100 trials.\label{table:HKE_2013_AES}}
				\end{figure}

				When evaluating the AES circuit we see the expected increase in the time spent on input generation and circuit building. The increase in the cost of the OTs, Commitment construction and Logarithm checks is linear in terms of the growth in the number of inputs. We also see the the continuing trend of the circuit exchange dominating communications costs.\\

				\noindent\textbf{Summary}\\

				The Huang-Katz-Evans protocol shows great promise with good performance which does not seem overly affected by an increase in circuit size nor the number of outputs. Input size affects the running time of the Oblivious Transfer and Commitments, but the impact of increasing the input sizes on performance it seems to be fairly linear.\\

				In a few places our implementation could be improved, mainly the communications code, in several communication rounds we have taken the easy route of $P_1$ going first and having $P_2$ wait till it receives till serialising its own input. This should be changed so the parties serialise symmetrically then take turns to send.\\

				We suggest that further experimentation should be carried out, focusing on parties with unequal computational power but also on circuits with unequal input sizes. Further measurements should also be taken, breaking down the step `Initial J-set Checks'. Whilst we have inferred the most expensive component is likely the opening of commitments this claim needs to be supported by hard data.

			\subsection{L-HKE 2015} \label{sub:L-HKE_Results_Analysis}
				\FloatBarrier
				\noindent \textbf{32-bit Addition}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $2.34$ & $0.30$ & $77$ & $77$ \\
						\hline
						Circuit Building & $0.12$ & $0.02$ & $0$ & $0$ \\
						\hline
						OT- Sender & $37.65$ & $8.93$ & $284,040$ & $135,784$ \\
						\hline
						Sending circuits, queries and hashes & $0.02$ & $0.03$ & $1,883,800$ & $0$ \\
						\hline
						Make/Send commits & $10.83$ & $1.38$ & $374,062$ & $0$ \\
						\hline
						Partially Open J-Sets & $0.05$ & $0.01$ & $134,368$ & $683$ \\
						\hline
						Sub-computation & $94.77$ & $14.80$ & $3,294,892$ & $3,162,854$ \\
						\hline
						Send B-Lists & $0.00$ & $0.00$ & $1,060$ & $0$ \\
						\hline
						Prove Input Consistency & $0.00$ & $0.00$ & $23,067$ & $0$ \\
						\thickhline
						Total & $145.77$ & $25.47$ & $5,995,366$ & $3,299,399$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Builder in the L-HKE 2015 protocol evaluating the 32-bit addition circuit averaged over 100 trials. \label{table:L-HKE_2015_Add_Builder}}
				\end{figure}

				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT - Receiver & $35.29$ & $9.23$ & $135,861$ & $284,117$ \\
						\hline
						Receiving circuits and Hashed List & $0.01$ & $0.05$ & $0$ & $1,883,800$ \\
						\hline
						Receiving commits & $0.00$ & $1.39$ & $0$ & $374,062$ \\
						\hline
						Partially open J-set & $0.00$ & $0.00$ & $683$ & $134,368$ \\
						\hline
						Evaluate Circuits & $0.01$ & $0.01$ & $0$ & $0$ \\
						\hline
						Sub-computation & $94.53$ & $14.79$ & $3,162,854$ & $3,294,892$ \\
						\hline
						Verify B-List & $0.00$ & $0.00$ & $0$ & $1,060$ \\
						\hline
						Checking correctness & $1.74$ & $0.24$ & $0$ & $0$ \\
						\hline
						Verify input consistency & $0.93$ & $0.12$ & $0$ & $23,067$ \\
						\thickhline
						Total & $132.51$ & $25.83$ & $3,299,399$ & $5,995,366$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the L-HKE 2015 protocol evaluating the 32-bit addition circuit averaged over 100 trials. \label{table:L-HKE_2015_Add_Executor}}
				\end{figure}
				\FloatBarrier

				The sub-computation again dominates both running time and communications for a small circuit. The main computation circuits form the next biggest communication cost. We fully expect that as the circuit and input sizes increase the circuit sending we become the largest communication cost.\\

				The logarithm calculation stage for the builder has such a small cost in terms of CPU/Wall time our timing code does not register the time spent. This is not all that odd as for the Builder this is just computing a few subtractions.\\

				It is notable that the major computational costs here are dependant on the size of one the party's input. The Oblivious Transfers depend on the Executor's input size whilst the sub-computation depends on the Builder's input size, together these two components account for $>90\%$ of the running time on the addition circuit. If this trend holds then this protocol would be well suited to large circuits with small input sizes.\\

				Also noteworthy is that the computational costs of the protocol are fairly well balanced, with only a slight skewing towards the Builder. Similarly for the communications, however as already stated we expect the main computation circuits sending to unbalance this as the circuit sizes increase.\\

				\FloatBarrier
				\noindent \textbf{32-bit Multiplication}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $2.36$ & $0.30$ & $77$ & $77$ \\
						\hline
						Circuit Building & $3.53$ & $0.46$ & $0$ & $0$ \\
						\hline
						OT- Sender & $37.59$ & $8.94$ & $284,040$ & $135,783$ \\
						\hline
						Sending Circuits and Hash List & $0.14$ & $0.54$ & $62,157,592$ & $0$ \\
						\hline
						Make/Send commits & $10.83$ & $1.38$ & $374,062$ & $0$ \\
						\hline
						Partially Open J-set & $0.06$ & $0.01$ & $134,507$ & $685$ \\
						\hline
						Sub-computation & $95.10$ & $14.66$ & $3,294,887$ & $3,162,882$\\
						\hline
						Send B-Lists & $0.00$ & $0.00$ & $2,052$ & $0$ \\
						\hline
						Prove Input Consistency & $0.00$ & $0.00$ & $22,986$ & $0$ \\
						\thickhline
						Total & $149.61$ & $26.28$ & $66,270,204$ & $3,299,428$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Builder in the L-HKE 2015 protocol evaluating the 32-bit multiplication circuit averaged over 100 trials. \label{table:L-HKE_2015_Mul_Builder}}
				\end{figure}

				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT - Receiver & $35.29$ & $9.69$ & $135,860$ & $284,117$ \\
						\hline
						Receiving circuits and Hashed List & $0.28$ & $0.58$ & $0$ & $62,157,592$ \\
						\hline
						Receiving commits & $0.00$ & $1.35$ & $0$ & $374,062$ \\
						\hline
						Partially open J-set & $0.00$ & $0.00$ & $685$ & $134,507$ \\
						\hline
						Evaluate Circuits & $0.26$ & $0.27$ & $0$ & $0$ \\
						\hline
						Sub-computation & $94.49$ & $14.39$ & $3,162,882$ & $3,294,887$ \\
						\hline
						Verify B-List & $0.00$ & $0.00$ & $0$ & $2,052$ \\
						\hline
						Checking correctness & $3.79$ & $0.52$ & $0$ & $0$ \\
						\hline
						Verify input consistency & $0.93$ & $0.12$ & $0$ & $22,986$ \\
						\thickhline
						Total & $135.05$ & $26.92$ & $3,299,428$ & $66,270,204$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the L-HKE 2015 protocol evaluating the 32-bit multiplication circuit averaged over 100 trials. \label{table:L-HKE_2015_Mul_Executor}}
				\end{figure}
				\FloatBarrier

				These results give further evidence to support the claim that size of the circuit is a small factor in the running time compared to the input sizes. Despite an increase in the circuit size by a factor of $30$ the running time increase by about $5\%$.\\

				The communications costs are where the most change occurs. As we thought the communications costs of sending the circuits has risen to dominate the sub-computation

				\FloatBarrier
				\noindent \textbf{AES Encryption}
				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						Input generation & $9.39$ & $1.18$ & $77$ & $77$ \\
						\hline
						Building circuits & $11.18$ & $1.44$ & $0$ & $0$ \\
						\hline
						OT- Sender & $141.29$ & $33.36$ & $1,120,488$ & $476,293$ \\
						\hline
						Sending circuits and Hash List & $0.40$ & $1.82$ & $204,082,568$ & $0$ \\
						\hline
						Make/Send commits & $43.23$ & $5.44$ & $1,495,342$ & $0$ \\
						\hline
						Partially open J-set & $0.22$ & $0.03$ & $414,781$ & $684$ \\
						\hline
						Sub-computation & $212.13$ & $34.95$ & $7,516,036$ & $7,391,121$ \\
						\hline
						Send B-Lists & $0.00$ & $0.00$ & $4,100$ & $0$ \\
						\hline
						Prove input consistency & $0.00$ & $0.00$ & $92,025$ & $0$ \\
						\thickhline
						Total & $417.84$ & $78.22$ & $214,725,419$ & $7,868,176$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Builder in the L-HKE 2015 protocol evaluating the AES encryption circuit averaged over 100 trials. \label{table:L-HKE_2015_AES_Builder}}
				\end{figure}

				\begin{figure}[!ht]
					\begin{tabular}{| p{4.3cm} | c c c c |}
						\hline
						\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv} \\
						\thickhline
						OT - Receiver & $136.87$ & $35.96$ & $476,370$ & $1,120,565$ \\
						\hline
						Receiving circuits and Hashed List & $0.76$ & $1.88$ & $0$ & $204,082,568$ \\
						\hline
						Receiving commits & $0.02$ & $5.43$ & $0$ & $1,495,342$ \\
						\hline
						Partially open J-set & $0.01$ & $0.01$ & $684$ & $414,781$ \\
						\hline
						Evaluate circuits & $0.37$ & $0.37$ & $0$ & $0$ \\
						\hline
						Sub-computation & $211.41$ & $34.57$ & $7,391,121$ & $7,516,036$ \\
						\hline
						Verify B-List & $0.00$ & $0.00$ & $0$ & $4,100$ \\
						\hline
						Checking correctness & $11.14$ & $1.80$ & $0$ & $0$ \\
						\hline
						Verify input consistency & $2.89$ & $0.47$ & $0$ & $92,025$ \\
						\thickhline
						Total & $363.46$ & $80.49$ & $7,868,176$ & $214,725,419$ \\
						\hline
					\end{tabular}
					\caption{The performance of the Executor in the L-HKE 2015 protocol evaluating the AES encryption circuit averaged over 100 trials. \label{table:L-HKE_2015_AES_Executor}}
				\end{figure}
				\FloatBarrier

				Here we see fairly conclusive proof of the irrelevancy of circuit size compared to input size for the modified protocol. The Oblivious Transfer and Sub-computation continue to take the lion's share of the running time. The most interesting result though is the change in the balance between the Oblivious Transfer and sub-computation.\\

				We see the cost of the Oblivious Transfer has increased almost exactly linear with the Executor's input size. On the other hand while the running time of the Sub-computation has increased significantly, by a factor of $\sim 2.4$, this increase is less than the input size increase by a factor of $4$.\\


				\noindent \textbf{Summary}\\
					We have seen that for our modified version of the Lindell 2013 protocol that the most important factor is the size of the inputs. Furthermore we see that the size of the Executor's inputs has a greater impact on running time then the size of the Builder's inputs.\\

					The main area for improvement will be the sub-computation, particularly we feel that attempting to reconcile HKE with some of the Lindell optimisations we were forced to remove will yield the most improvement.

			\FloatBarrier
			\section{Comparison of protocols}
				\subsubsection{Overall} \label{sub:Overall_Comparisons}

					\noindent \textbf{Huang-Katz-Evans versus all} These results show a very large difference in performance between the Huang, Katz and Evans protocol and the rest. This is hardly surprising in the case of comparing Lindell-Pinkas 2010 to HKE as HKE requires (including the log factor) $92$ circuits to achieve a deterrent probability of $1 - 2^{-40}$. In comparison LP-2010 needs $130$ circuits (though with the improvements suggested in \cite{ShelatAndShen} this can be reduced to $126$.\\

					Conversely it is quite surprising, at least at a high level, to see HKE out perform Lindell-2013 by such a margin. To achieve the same level of security Lindell 2013 needs only $40$ circuits of the same size and $\sim 120$ very small sub-circuits. Yet even if we were to completely remove the sub-computation the Lindell 2013 protocol is still decisively out-performed by HKE.\\

					It is tempting to put this down to implementation quality, perhaps we have coded badly such that idle time is a significant factor in Lindell-2013. But this possibility does not seem to hold up when we look at the CPU times. HKE is not only taking less `wall clock' time to run, it also uses considerably less CPU time then all three other protocols.\\

					There are two key areas where HKE makes the improvements that yield this frankly astonishing performance. The first is in the proving of the consistency of the Builder's inputs and the second is the Oblivious Transfer.\\

					The modified CnC-OT takes just over $33$ seconds ($\sim 0.25$ seconds per input wire) on the AES circuit, whilst the OT step in the HKE protocol on the same circuit takes just under $7$ seconds ($\sim 0.05$ seconds per input wire). For significantly less CPU time and bandwidth to boot.\\

					The Extended DH tuple zero knowledge proof is a little more difficult to gauge as we have already noted we believe this could be implemented better. However at present proving the consistency of the Builder's inputs takes around $34$ seconds ($\sim 0.25$ seconds per input wire) on the AES circuit. In comparison the HKE approach using logarithms takes less than $2$ seconds.\\

					\noindent \textbf{Lindell 2013 over Lindell-Pinkas 2010} The performance of Lindell 2013 compared to Lindell-Pinkas 2010 is one of the more disappointing results. At a high level it sounds very good, after all we reduce the number of circuits needed by a factor of $\frac{1}{0.311}$.\\

					We believe there are two main reasons for L-2013 not outperforming LP-2010 at this level. First, we have not run big enough experiments. With a bigger circuit we will probably see L-2013 outperform LP-2010. In fact we think we are very close to the tipping point at which L-2013 will win as the running times are very nearly even and L-2013's running time grows at a slower rate.\\

					Secondly, one of the main costs apart from the OT and the sub-computation is the proof of the Builder's inputs consistency. The running time of this proof varies over two inputs, the number of Builder input wires and the number of circuits.\\

					One would hope then this would be significantly improved by reducing the number of circuits.
					Instead the L-2013 protocol actually increases the second as in addition to the main computation inputs it must prove the consistency of the sub-computation inputs. The increased cost is not very large but it is not a decrease is cost with is the main thing.\\

					Therefore the main saving is made in the Oblivious Transfers, which runs just less than  $60\%$ of the time the unmodified OT needs (with a smaller number of circuits but this is fair as the modifications allow the reduction in the number of circuit). It is roughly at the point where this saving exceeds the cost of the sub-computation the L-2013 protocol will outperform the old LP-2010 protocol.\\

					All the same it is tempting to be disappointed L-2013 did not perform better, however, in \cite{Lindell_CnC_2013} Lindell calculates theoretical measures of L-2013's performance versus those for LP-2010 and notes that his protocol exchanges more group exponentiations for less symmetric encryptions and less bandwidth. In our test environment AES-NI reduces the cost of the additional symmetric encryptions, whilst the network setup of the Diffie and Hellman de-emphasise communication costs. Further experiments should be run in an environment where communication costs are higher.\\ 

					\noindent \textbf{L-HKE - Modifying Lindell-2013} We now compare the overall performance of our modified version of the L-2013 protocol against the original protocol proposed by Lindell and against the Lindell-Pinkas protocol. The first thing to note is in terms of running times L-HKE outperforms both the other protocols on all three circuits.\\

					On the addition circuit L-HKE runs faster than LP-2010 by a very thin margin, only 2 seconds and at the cost of using significantly more CPU time and a minor increase in bandwidth used. When considering the multiplication circuit we see L-HKE very slightly increase its lead in running time. Furthermore we see the result of the main computation circuits taking dominance over bandwidth as L-HKE uses just over $\frac{1}{3}$ the bandwidth LP-2010 does. However, the CPU time used by L-HKE is still very high in comparison.\\

					As expected the AES circuit gives L-HKE its best relative performance. It runs $30$ seconds quicker than LP-2010, uses only $10\%$ more CPU time and again about $\frac{1}{3}$ the bandwidth. Here we can clearly see how as the circuit and input sizes get bigger the cost of the sub-computation is reduced relative to the other costs of the protocol.\\

					Another point to make is that the computational load is much more evenly balanced. This is neither an unambiguous positive or negative, in some settings one party having more computational work to do might be more practical (e.g. Mobile device paired with server).\ 

					The picture of L-HKE versus L-2013 is much more complex. L-HKE runs on the addition circuit considerably quicker (about $13$ seconds faster) and uses about the same amount of CPU time. In exchange requires $2,000,000$ additional bytes of communication.\\

					The performance gains are made only partly in the sub-computation. While it is true that the modified sub-computation is $6$ seconds faster, the main gain is in replacing the Extended DH tuple proof of consistency with the HKE logarithm based approach.\\

					Running the protocols on the multiplication circuit yields little change, CPU time usage remains about even, the Wall time difference increases very slightly. The only really interesting result is the absolute difference in bandwidth usage is steady.\\

					The AES circuit gives much more food for thought. L-HKE runs in $80$ seconds, about $40$ seconds faster than L-2013, however the difference in running times for the sub-computations is reduced to only a few seconds. This is as the cost of the modified sub-computation grows much faster than the original sub-computation due to the additional work involved with the `key' that hides the output from the Builder.\\

					As such almost the entirety of the improvement in running time is from the proof of the Builder's inputs consistency. It would be interesting to run further experiments to see if the additional sub-computation costs every outweigh the savings in the consistency proof.

				\subsection{Comparison of sub-computations}
					Lastly we turn our attention to comparing the two variants on the sub-computation of the Lindell 2013 protocol. We first give some comments on each sub-computation separately before comparing them directly.\\

					In the interest of saving space we have omitted the measurements from some steps where the measurements were so small as to be trivial. We have also removed the sub-computation on the multiplication circuit as it is no different from the sub-computation on the addition circuit.\\

					\noindent \textbf{L-2013 Sub-computation}\\
					\begin{figure}[!ht]
						\begin{tabular}{| p{4.3cm} | c c c c |}
							\hline
							\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv.} \\
							\thickhline
							Build sub-circuits & $18.98$ & $2.39$ & $0$ & $0$ \\
									   & $75.42$ & $9.48$ & $0$ & $0$ \\
							\hline
							Sub-OT-Sender & $94.94$ & $13.76$ & $1,401,757$ & $744,911$ \\
								      & $95.26$ & $13.46$ & $1,401,757$ & $744,911$ \\
							\hline
							Send circuits/commits & $0.07$ & $0.01$ & $741,341$ & $0$ \\
									      & $0.12$ & $0.02$ & $2,921,117$ & $0$ \\
							\hline
							Open J-set & $0.56$ & $2.71$ & $125,044$ & $2,044$ \\
								   & $0.59$ & $2.75$ & $125,044$ & $2,044$ \\
							\hline
							Send Builder Inputs & $2.94$ & $2.94$ & $142,092$ & $0$ \\
									    & $11.76$ & $11.77$ & $568,332$ & $0$ \\
							\thickhline
							Total & $117.53$ & $21.85$ & $2,412,286$ & $746,955$ \\
							      & $183.19$ & $37.52$ & $5,018,302$ & $746,955$ \\
							\hline
						\end{tabular}

						\vspace{0.5cm}

						\begin{tabular}{| p{4.3cm} | c c c c |}
							\hline
							\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv.} \\
							\thickhline
							Sub-OT prep & $20.09$ & $2.89$ & $0$ & $0$ \\
								    & $20.08$ & $2.91$ & $0$ & $0$ \\
							\hline
							Sub-OT transfer & $22.10$ & $16.01$ & $744,911$ & $1,401,757$ \\
									& $21.36$ & $16.21$ & $744,911$ & $1,401,757$ \\
							\hline
							Receive circuits/commits & $0.03$ & $0.00$ & $0$ & $741,341$ \\
										 & $0.12$ & $0.02$ & $0$ & $2,921,117$ \\
							\hline
							Open and check J-set & $10.39$ & $1.59$ & $2,044$ & $125,044$ \\
								   & $35.86$ & $5.72$ & $2,044$ & $125,044$ \\
							\hline
							Received builder inputs & $0.75$ & $1.36$ & $0$ & $142,092$ \\
										& $0.77$ & $6.06$ & $0$ & $568,332$ \\
							\hline
							Evaluate sub-circuits & $0.00$ & $0.00$ & $0$ & $0$ \\
									      & $0.01$ & $0.01$ & $0$ & $0$ \\
							\thickhline
							Total & $53.37$ & $21.85$ & $746,955$ & $2,412,286$ \\
							      & $78.95$ & $37.20$ & $746,955$ & $5,018,302$ \\
							\hline
						\end{tabular}
						\caption{The performance of the Builder and Executor in the original Lindell 2013 sub-computation. For each stage the first row is for the 32-bit addition circuit, second row is for the AES encryption circuit. \label{table:L_2013_Sub_Executor} }
					\end{figure}

					\FloatBarrier
					Here we have the breakdown of the sub-computation from Lindell's 2013 protocol. The Sub-OT takes a constant amount time regardless of input sizes, this is as expected. The sub-OT is affected only by the statistical security parameter as we only need to check the first $S$ many bits of $\delta$.\\

					One might initially be surprised by the difference in the cost of building the sub-circuits. However we should point out that this includes the cost of generating consistent inputs for the Builder's input wires a somewhat expensive operation that varies as the input size varies.\\

					The last point of note is the `Sending Builder's input' section. This result seems to suggest it is unparallelised despite being an obvious target for parallelism. Sure enough this is an oversight on our part during implementation, due to technical issues with Diffie and Hellman I am unable to rerun these tests. As such we take the results we have and make a note that both the LP-2010 and L-2013 protocols can probably be sped up by $5+$ seconds for the AES circuit.\\

					It is worth pointing out that the cost of evaluating the check circuits (once inputs obtained) is negligible. This is expected due to the small size of the circuits.\\

					\noindent \textbf{L-HKE Sub-computation}\\
					\FloatBarrier
					\begin{figure}[!ht]
						\begin{tabular}{| p{4.3cm} | c c c c |}
							\hline
							\textbf{Builder} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv.} \\
							\thickhline
							Build sub-circuits & $6.52$ & $0.84$ & $0$ & $0$ \\
									   & $15.27$ & $2.00$ & $0$ & $0$ \\
							\hline
							Send sub-circuits/$\delta$ keys & $0.23$ & $0.03$ & $1,315,834$ & $1,181,510$ \\
									  & $0.77$ & $0.51$ & $2,901,178$ & $2,766,854$ \\
							\hline
							Make/Send commits & $28.39$ & $4.00$ & $967,406$ & $967,406$ \\
									  & $64.25$ & $8.93$ & $2,256,878$ & $2,256,878$ \\
							\hline
							Sub-OT & $27.48$ & $3.69$ & $350,732$ & $353,024$ \\
							      & $63.94$ & $8.57$ & $814,412$ & $823,712$ \\
							\hline
							Initial J-set checks & $28.53$ & $4.96$ & $549,252$ & $549,252$ \\
									    & $60.88$ & $11.17$ & $1,205,028$ & $1,205,028$ \\
							\hline
							Evaluate sub-circuits & $0.00$ & $0.00$ & $0$ & $0$ \\
									      & $0.01$ & $0.01$ & $0$ & $0$ \\
							\hline
							Sub-circuit Log Checks 	& $2.00$ & $0.74$ & $59,620$ & $59,620$ \\
										& $3.91$ & $1.81$ & $139,108$ & $139,108$ \\
							\hline
							Output determination & $1.25$ & $0.48$ & $13,226$ & $13,226$ \\
									     & $2.51$ & $1.75$ & $52,010$ & $52,010$ \\
							\thickhline
							Total & $94.77$ & $14.80$ & $3,294,892$ & $3,162,854$ \\
							      & $212.13$ & $34.95$ & $7,516,036$ & $7,391,121$ \\
							\hline
						\end{tabular}

						\vspace{0.5cm}

						\begin{tabular}{| p{4.3cm} | c c c c |}
							\hline
							\textbf{Executor} & \textbf{CPU Time} & \textbf{Wall Time} & \textbf{Bytes Sent} & \textbf{Bytes Recv.} \\
							\thickhline
							Build sub-circuits & $6.30$ & $0.83$ & $0$ & $0$ \\
									   & $14.60$ & $2.09$ & $0$ & $0$ \\
							\hline
							Receive sub-circuits/$\delta$ keys & $0.31$ & $0.04$ & $1,181,510$ & $1,315,834$ \\
									  & $0.37$ & $0.05$ & $2,766,854$ & $2,901,178$ \\
							\hline
							Make/Send commits & $28.39$ & $4.00$ & $967,406$ & $967,406$ \\
									  & $64.76$ & $8.94$ & $2,256,878$ & $2,256,878$ \\
							\hline
							Sub-OT & $27.49$ & $3.72$ & $353,024$ & $350,732$ \\
							      & $63.85$ & $8.54$ & $823,712$ & $814,412$ \\
							\hline
							Initial J-set checks & $28.46$ & $4.99$ & $549,252$ & $549,252$ \\
									     & $61.31$ & $11.47$ & $1,205,028$ & $1,205,028$ \\
							\hline
							Evaluate sub-circuits & $0.00$ & $0.00$ & $0$ & $0$ \\
									      & $0.01$ & $0.01$ & $0$ & $0$ \\
							\hline
							Sub-circuit Log Checks 	& $2.03$ & $0.41$ & $59,620$ & $59,620$ \\
										& $3.98$ & $0.86$ & $139,108$ & $139,108$ \\
							\hline
							Output determination & $1.24$ & $0.77$ & $13,226$ & $13,226$ \\
									     & $2.52$ & $2.40$ & $52,010$ & $52,010$ \\
							\thickhline
							Total & $94.53$ & $14.79$ & $3,162,854$ & $3,294,892$ \\
							      & $211.41$ & $34.57$ & $7,391,121$ & $7,516,036$ \\
							\hline
						\end{tabular}

						\caption{The performance of the Builder and Executor in the modified L-HKE sub-computation. For each stage the first row is for the 32-bit addition circuit, second row is for the AES encryption circuit. \label{table:L-HKE_Sub_Executor} }
					\end{figure}

					We would expect to see the running time of the sub-computation using HKE to be fairly linear to the input sizes. This indeed is the case, with the cost of every component of the sub-computation increasing by a factor of less than four when moving from the addition to AES circuits.\\
					
					In fact every component increases by a factor of less than $3$, this is probably indicating some amount of constant overhead underneath each step.\\

					The majority of the sub-computation is spent in the commitment construction, OT and J-set checks. Recall from Subsection \ref{sub:HKE_Results_Analysis} that we believe the main cost of the J-set checks is opening the commitments to the Builder's inputs. If this is true then over half the sub-computation is spent making, sending or opening commitments\\

					We see a very balanced load for this sub-computation, both in terms of time (Wall and CPU) and in terms of bandwidth.\\

					\noindent \textbf{Comparison}\\

						Some uncertainty is added to our comparison by the discovery of the missing parallelism in the Builder input computation, however working on the assumption that the parallelism would have sped up this part of the protocol by a factor of $6$ (working on an eight core machine) we will continue with this caveat in mind.\\

						The first thing to notice is that the increase in the number of inputs from the addition circuit to the AES circuit has a much greater impact on the L-HKE sub-computation than on the L-2013 sub-computation. Indeed when running on the AES circuit the two sub-computations take almost the same amount of time to run.\\

						This might lead one to conclude that for circuits with more than 128 Builder inputs wires we are certainly better off with the L-2013 sub-computation. However, this overlooks two key points. The first point is the reason why the running time of the L-HKE sub-computation increases at such a greater rate than the L-2013 one.\\

						Due to the symmetric nature of the HKE protocol we were required to take extra steps to hide the output of the sub-computation. Recall we did this by having the Executor input a key chosen at random and changing the circuit to XOR this key with the output, effectively One Time Padding the output of the computation.\\ However, this key must be of the same length as the Builder's input, meaning the input size to the L-HKE sub-computation grows at double the rate the input size to the L-2013 sub-computation.\\

						We believe that if the requirement for this key can be removed then the L-HKE sub-computation will be competitive for much large input sizes.\\

						The second key point is the change to the \emph{main} computations proof of consistency. Recall that when modifying the sub-computation we changed the proof of consistency of the Builder's inputs to use the logarithm based approach used in HKE. This change reduces the cost of the consistency proof by a significant amount ($\sim 30$ seconds on the AES circuit).\\

						That said at present I can think of no reason this optimisation cannot be applied to the Lindell protocol directly. If this can be done then the key advantage of the L-HKE protocol over large input circuits is nullified.\\

						We conclude that the L-HKE sub-computation shows promise but it needs improvement before it can compete with the Lindell sub-computation on large circuits. It's primary problem is its sensitivity to variations in the Builder's input size.\\

						As such practical implementations built on the Lindell-2013 protocol could implement a check on the Builder's input size at the start of the computation and chose the sub-computation accordingly.


	\chapter{Conclusions}
		Our work provides the first practical implementation of two protocols, a new variant on one of those protocols and an implementation of a protocol for which only preliminary experiments have been performed. As such we provide the first practical comparison of these four protocols. We are also the first to be able to see how some of the new primitives suggested in \cite{LindellAndPinkas2011} and \cite{Lindell_CnC_2013} work in practise.\\

		All four protocols we have implemented compare very favourably to Lindell and Pinkas's previous protocol in \cite{LindellAndPinkas2007} (LP-2010), we base this statement on informal consideration of the results from the implementation of the latter given in \cite{LindellPinkasSmart2008}. The Lindell-Pinkas-Smart LP-2007 takes $135$ seconds to evaluate the function $x > y$ for 16-bit inputs. All of our implementation of protocol can evaluate an AES encryption in less time.\\

		Whilst some of this is no doubt due to differences in hardware the AES circuit is vastly more complex with 8 times more inputs and hundreds of times more gates.\\

		We also see that the number of input wires (both Builder and Executor) has a greater impact on the running time of a secure computation than the size of the circuit in terms of gates. This was expected, however more surprisingly we saw that in the asymmetric protocols the size of the \emph{Builder's} inputs had more impact then the size of the Executor's inputs.\\

		We see that HKE is by far and away the best protocol in terms of running time, however due to being symmetrical it will suffer performance degradation if the function outputs something to only $P_2$. In the cases where the Builder should not see $P_2$'s output and the input sizes are large it may be better to run the Lindell-2013 protocol.\\

		One of the most significant areas HKE is better than the other protocols is in proving the consistency of the Builder's inputs. Even when done in parallel the Extended Diffie-Hellman Tuple proof approach takes considerably longer then the logarithm approach.\\

		To the best of our knowledge we provide the first implementation of Cut and Choose Oblivious Transfer, both the original and modified versions. While CnC OT sounds good on paper, allowing us to fold the commitments to the input keys into the OT itself, in practise the Zero Knowledge proofs are very expensive and their cost outweigh the gains of removing the commitments.\\

		

		\section{Future Work}
			We have pointed the reader to several areas where we believe our implementation could be improved, notably the Zero Knowledge Proof of Builder's input consistency. But also optimisations such as the garbled row reduction, hashed circuit checks and the Free-XOR communication reduction.\\

			Additionally there are some corner cases our prototype implementation has not addressed, in particular the case where one party has input size zero. This is a somewhat dubious corner case though as if a party has no inputs to the computation there is little reason for a secure computation.\\

			There are also several further experiments we believe would be very helpful, a few particular ones are listed below,

			\begin{itemize}
				\item Unequal input sizes (e.g. Builder has many more input wires than Executor)
				\item Circuits with a very large number of inputs.
				\item Between parties with unequal computational resources.
				\item In an environment where communication costs are high.
			\end{itemize}
			
			Whilst we only had limited success with modifying the sub-computation of the Lindell-2013 protocol the results we obtained were promising.\\

			Further work could be done into the modified version of the Lindell-2013 protocol that we put forward, in particular into the problem of hiding the output of the sub-computation in a way that does not inflate the input size. This work would not just benefit our modified protocol, but also Symmetric Cut and Choose in general.\\

			Furthermore work should be done into modifying both the Lindell-Pinkas 2010 and Lindell 2013 protocols to use the logarithm based proof of Builder's consistency.

	\begin{thebibliography}{99}

		\bibitem{LindellAndPinkas2007}
			Y. Lindell and B. Pinkas. \emph{An Efficient Protocol for Secure Two-Party Computation in the Presence of Malicious Adversaries}.
			To appear in the Journal of Cryptology. (Extended abstract appeared in EUROCRYPT 2007, Springer (LNCS 4515), pages 5278, 2007.)

		\bibitem{LindellPinkasSmart2008}
			Y. Lindell, B. Pinkas and N. P. Smart.
			\emph{Implementing Two-Party Computation Efficiently with Security Against Malicious Adversaries}. Proceedings of the Sixth Conference on Security and Cryptography for Networks (SCN),
			2008.

		\bibitem{LindellAndPinkas2011}
			Y. Lindell and B. Pinkas. \emph{Secure Two-Party Computation via Cut-and-Choose Oblivious Transfer}.
			In TCC 2011,
			Springer (LNCS 6597), pages 329346,
			2011

		\bibitem{ShelatAndShen}
			A. Shelat, C.H. Shen. \emph{Two-Output Secure Computation with Malicious Adversaries},
			In EUROCRYPT 2011,
			Springer (LNCS 6632), pages 386405,
			2011.

		\bibitem{Lindell_CnC_2013}
			Y. Lindell.
			\emph{Fast cut-and-choose based protocols for malicious and covert adversaries}, R. Canetti, J.A. Garay, (eds.)
			CRYPTO 2013, Part II. LNCS, vol. 8043, pages 117.
			Springer, Heidelberg (2013).

		\bibitem{Katz_Symm_CnC_2013}
			Y. Huang, J. Katz, D. Evans.
			\emph{Efficient Secure Two-Party Computation Using Symmetric Cut-and-Choose}, In 33rd International Cryptology Conference (CRYPTO 2013),
			2013.

		\bibitem{SugarBeets}
			P. Bogetoft, D. Christensen, I. Damgrd et al.
			\emph{Secure Multiparty Computation Goes Live},
			In Financial Cryptography and Data Security 2009,
			Springer LNCS 5628, pages 325-343,
			2009.

		\bibitem{DYADIC_MPC_Primer}
			DYADIC,
			MPC Technical Primer,
			\url{https://www.dyadicsec.com/media/1093/mpc-primer.pdf}

		\bibitem{DARPAPROceed}
			DARPA.
			\emph{PROCEED Program webpage}.
			\url{http://www.darpa.mil/Our_Work/I2O/Programs/PROgramming_Computation_on_EncryptEd_Data_%28PROCEED%29.aspx}

			
		\bibitem{SMC_Is_Practical}
			B. Pinkas, T. Schneider, N. P. Smart and S. C. Williams.
			\emph{Secure Two-Party Computation is Practical},
			ASIACRYPT 2009, 2009.

		\bibitem{FreeXOR}
			V. Kolesnikov and T. Schneider.
			\emph{Improved garbled circuit: Free XOR gates and applications}.
			In Automata, Languages and Programming  ICALP 2008, Springer-Verlag (LNCS 5126),
			pages 486 - 498,
			2008.

		\bibitem{OnCommittedInputs}
			S. Jarecki and V. Shmatikov.
			\emph{Efficient Two-Party Secure Computation on Committed Inputs.}
			In EUROCRYPT 2007, Springer (LNCS 4515),
			pages 97 - 114,
			2007.

		\bibitem{LEGO_Paper}
			J. Nielsen and C. Orlandi. \emph{LEGO for Two-Party Secure Computation}. In TCC 2009, Springer (LNCS 5444), pages 368 - 386, 2009.

		\bibitem{MiniLEGO}
			T. Frederiksen, T. Jakobsen, J. Nielsen, et al. \emph{MiniLEGO: Efficient Secure Two-Party Computation from General Assumptions}, In Advances in Cryptology - EUROCRYPT 2013, Springer (LNCS 7881), pages 537 - 556, 2013.

		\bibitem{YaoOriginal}
			A. Yao. \emph{How to Generate and Exchange Secrets.} In 27th FOCS, pages 162167, 1986.

		\bibitem{ProofOfYaoSecurity}
			Y. Lindell, B. Pinkas. \emph{A proof of security of Yaos protocol for two-party computation}. Journal of Cryptology 22(2), pages 161 - 188 (2009).

		\bibitem{WhenGameTheoryMetSMC}
			I. Abraham, D. Dolev, R. Gonen and J. Halpern. \emph{Distributed Computing Meets Game Theory: Robust Mechanisms for Rational Secret Sharing and Multiparty Computation}, Proceedings of the Twenty-Fifth Annual ACM Symposium on Principles of Distributed Computing,  pages 53 - 62, 2006.

		\bibitem{Rabin81}
			M. Rabin. \emph{How to exchange secrets with oblivious transfer}. Technical Report, TR-81, Aiken Computation Lab, Harvard University, 1981.

		\bibitem{PinkasSlides2014}
			B. Pinkas. \emph{Secure Computation Lecture Series}, Lecture 5 - Oblivious Transfer, 2014.

		\bibitem{EvenEtAl85}
			S. Even, O. Goldreich and A. Lempel. \emph{A randomized protocol for signing contracts}, In Communications of the ACM, Vol. 28 Iss. 6, pages 637 - 647 (1985)

		\bibitem{PVW_OT_2008}
			C. Peikert, V. Vaikuntanathan and B. Waters. \emph{A framework for efficient and composable oblivious transfer}. In: Wagner, D. (ed.) CRYPTO 2008, Springer (LNCS 5157), pages 554571, 2008.

		\bibitem{NaorPinkasOT2001}
			Naor and B. Pinkas, \emph{Efficient Oblivious Transfer Protocols}, Proceedings of SODA 2001 (SIAM Symposium on Discrete Algorithms), 2001.

		\bibitem{HashCheckOpt}
			V. Goyal, P. Mohassel, and A. Smith.
			Efficient two party and multi party computation against covert adversaries.
			In Advances in Cryptology  Eurocrypt 2008, volume 4965 of LNCS,
			pages 289306. Springer,
			2008.

		\bibitem{PseudoRandomSynth}
			M. Naor and O. Reingold.
			\emph{Synthesizers and Their Application to the Parallel Construction of Psuedo-Random Functions.}
			In the 36th FOCS,
			pages 170181,
			1995.

		\bibitem{NigelCircuits}
			Bristol Cryptography Group,
			\emph{Circuits of Basic Functions Suitable For MPC and FHE}.  \url{http://www.cs.bris.ac.uk/Research/CryptographySecurity/MPC/}. 

		\bibitem{ECC_Primer}
			N. Sullivan,
			\emph{A (relatively easy to understand) primer on elliptic curve cryptography},
			October 2013,
			\url{http://arstechnica.com/security/2013/10/a-relatively-easy-to-understand-primer-on-elliptic-curve-cryptography/}.

		\bibitem{ECC_RFC_6090}
			D. McGrew, K. Igoe and M. Salter,
			\emph{Fundamental Elliptic Curve Cryptography Algorithms},
			RFC 6090,
			February 2011.

		\bibitem{BrainpoolSpecifications}
			ECC Brainpool, \emph{ECC Brainpool Standard Curves and Curve Generation},
			October 2005, \url{http://www.ecc-brainpool.org/
			download/Domain-parameters.pdf}.

		\bibitem{NSA_CaseForECC}
			NSA,
			\emph{The Case for Elliptic Curve Cryptography},
			January 2009,
			\url{https://www.nsa.gov/business/programs/elliptic_curve.shtml}.

		\bibitem{Wiki_ECC}
			Wikipedia (various authors),
			\emph{Elliptic curve point multiplication},
			\url{http://en.wikipedia.org/wiki/Elliptic_curve_point_multiplication}

		\bibitem{NigelCryptoBook}
			N. P. Smart,
			Cryptography, An Introduction : Third Edition,
			\url{https://www.cs.bris.ac.uk/~nigel/Crypto_Book/}
		
		\bibitem{ShamirSecretSharing}
			A. Shamir,
			\emph{How to Share a Secret}.
			In the Communications of the ACM,
			22(11):612613,
			1979.

		\bibitem{ISAAC_Implementation}
			Bob Jenkins. \emph{ISAAC: a fast cryptographic random number generator},
			\url{http://burtleburtle.net/bob/rand/isaacafa.html}.

	\end{thebibliography}


	\begin{appendices}

		\chapter{Implementation usage guide}
			This chapter deals with how to build and use the implementation provided. If you are the Bristol markers the implementation source code was submitted on SAFE in a zip file. Else you can download the source code from github. The project can be found at \url{https://github.com/nt1124/FourthYearProject}.\\
			
			Unless otherwise stated I assume you are in the root directory of the source code (FourthYearProject). I have tested the implementation on Ubuntu (both 14.04 and 12.04), I give no guarantees for other operating systems.

			\section{Building}
				\subsection{Dependencies}
					You will require the following to compile and run our code.

					\begin{itemize}
						\item \texttt{g++}, used to compile the code.
						\item GNU Multi-Precision Arithmetic Library, can be installed using the command \texttt{`sudo apt-get install libgmp-dev'}
						\item rt-library, used for wall clock timings.
						\item OpenMP, this is optional but its absence will have a serious impact on performance.
						\item AES-NI, again this is optional but preferred for performance.
					\end{itemize}

				\subsection{Compilation} \label{sub:CompilationInstructs}
					Compilation can be performed with the command
					\begin{center}
						\texttt{g++ circuitEvaluator.c -O3 -fopenmp -ffast-math -maes -lgmp -lrt}
					\end{center}

					This will produce an executable called \texttt{a.out}, the output file can be changed inthe usual manner. If you do not have OpenMP or AES-NI you can still compile by removing the \texttt{-fopen-mp} or \texttt{-maes} flags respectively.


			\section{Running}
				We assume you ran the command given in \ref{sub:CompilationInstructs} and the output file was \texttt{a.out}, if this is not the case then replace \texttt{a.out} with the relevant executable file. Then you can run our implementation with the following command,\\

				\texttt{./a.out [Circuit] [IP] [PortNum] [PartyInput] [ProtocolNum] [PartyID]}

				\begin{itemize}
					\item Circuit = Path to the file containing the raw binary circuit to be evaluated.
					\item IP = The IP of the other party.
					\item PortNum = The port on which the parties will communicate. Note this takes PortNum AND PortNum + 1.
					\item PartyInput = Path to file containing the party's input to the computation.
					\item Protocol Num = The protocol to run with where,
						\subitem 0 = Lindell-Pinkas 2010
						\subitem 1 = Lindell 2013
						\subitem 2 = Huang-Katz-Evans 2013
						\subitem 3 = L-HKE 2015
						\subitem $4+$ = Benchmarking.
					\item PartyID = 1 means the local party is $P_1$, 0 means the local party is $P_2$.
				\end{itemize}

		\chapter{Benchmarking components}
			Here I give some benchmarks of key components in my implementation such as communication, ECC encryption and circuit evaluation. I include these measurements so that others intending to implement these protocols with more efficient (e.g. library supplied) components can get a rough idea of what performance improvement they can expect.

			\section{Communications}

				We benchmark our communications between Diffie and Hellman. We focus on sending elements of the 256-bit ECC group and sending raw bytes in varying sizes and numbers of blocks.\\

				Communication benchmarks will probably will elicit the most interest from readers intending on implementing these protocols themselves as the nature of our test environment de-emphasise the communication costs due to the close proximity of the two test machines.\\

		% 				\begin{figure}
		% 					\begin{tabular}{ c | c | c }
		% 						Block Size & Time Taken (seconds) &  \\
		% 						\hline
		% 						$100,000$ & 0 &  \\
		% 						$10,000,000$ & 0 &  \\
		% 					\end{tabular}
		% 				\end{figure}

			\section{Elliptic Curve Group Operations}

				We benchmark point addition, point doubling, point multiplication and fixed point multiplication. The fixed point multiplication includes the pre-computation of the relevant windows.


			\section{Circuit Building}

				Circuit building can be an expensive operation, furthermore as we take the re-building approach to circuit correctness checking it is carried out for each check circuit. We do not include preliminary operations (e.g. generating consistent inputs for circuits).

			


		\chapter{Implementation Details} \label{sec:ImplementationDetails}
			The final implementation is quite large and as such it would be thoroughly to go through all of it in any great detail. Furthermore a blow by blow account of the implementation of how we implement such primitives as Yao Garbled Circuits would detract from the purpose of this thesis, namely a comparison of several recent protocols, not a rehash of how to implement primitives.\\

			However, this said we shall touch on some of the high points and some of the more interesting primitives. We also comment on the purpose of this implementation and suggest a few places where we feel the implementation could be improved.

			\section*{Purpose of Implementation}
				It should be made abundantly clear that the implementation provided is \emph{not} intended for real world use with actual confidentiality on the line, instead it is for the purposes of comparing the performance of the protocols under consideration.\\

				Whilst the protocols have been implemented faithfully some of the lower level details not relevant to a comparison of the protocols are ignored, for example we do not established a secure connection between the two parties.\\

				Where possible we have implemented everything myself and reused the same code across protocols, rather than using available libraries. This maintains a consistent quality of implementation, using libraries where appropriate would improve the quality of the implementation it would do so in an uneven manner as many areas cannot be done using a library. This could potentially give one protocol an unfair advantage over another leading to skewed results.

			\section{Yao Garbled Circuits implementation}

				Clearly we need to implement Yao garbled circuits, but before even that we have an ordinary binary circuit implementation and we need to understand the format of the circuit definition files given by \cite{NigelCircuits}.

				\subsection{Tillich-Smart Circuit Files}

					We are using the circuits provided by \cite{NigelCircuits}, these circuits have been crafted with Yao Garbled Circuits in mind, applying some of the optimisations suggested in \cite{SMC_Is_Practical} and trying to minimise the number of AND gates in order to take maximal advantage of the Free-XOR optimisation.\\

					Throughout we shall refer to the format of the files as RTL. The first line of each RTL file saying how many gates and how many wires are in the circuit, the second line tells us how many inputs party 1 and Party 2 give to the circuit and how many outputs there are. Note that without modification we can only provide output to either only the Executor or both parties.\\

					From then on each line refers to a single gate of the binary circuit. The first number (call this number $m$) of a gate definition says how many inputs wires go into the gate, the second number (call this $n$) how many output wire come from the gate. Then the next $m$ numbers are the input wire IDs, then the last $n$ number are the IDs of the output wires. Finally the gate type is indicated, either AND, XOR, or INV.\\

					So for example, `$2$ $1$ $0$ $32$ $406$ XOR' represents an XOR gate with ID $406$ that takes two input wires which have IDs $0$ and $32$.

				\subsection{Creating binary circuits}
					By creating a binary circuit from the RTL files and then using this binary circuit (here on in the Raw input circuit) as a template for the creation of Yao Circuits we gain three advantages over reading from the RTL file to create a Yao Garbled Circuit directly.\\

					Firstly this reducing the amount of file I/O, we only need read the file once. Secondly this means makes it easier for us to perform further optimisations on the circuits, for example wire switching the inversion gates to reduce the size of the circuits (note we have not actually done this). Thirdly we need to be able to execute the normal binary circuit in the course of the Lindell 2013 protocol.\\

					We then create a Garbled circuit in the usual way using the raw input circuit to define the relations between gate rather than the RTL file.

			\section{Elliptic Curve implementation}

				Throughout unless otherwise stated we have worked in Elliptic Curve groups, in particular on the curve \emph{brainpoolP256r1} specified in \cite{BrainpoolSpecifications}. This is a $256$-bit curve and as such provides $128$-bits of security. I suggest \cite{ECC_Primer} as a high-level primer on ECC and \cite{ECC_RFC_6090} for a more technically detailed introduction.\\

				For a quick reference on some of the algorithms we use for operations I warily suggest \cite{Wiki_ECC}, primarily for the virtue of clear pseudo-code. For obvious reasons do not rely to much on this source.\\

				Elliptic curves groups are preferable over Schnorr groups for cryptographic purposes. They require smaller keys for the same level of security reducing the required size of the group. reducing the size of the numbers we are dealing with making computations quicker without sacrificing security. This point is illustrated in the Figure \ref{fig:NSA_ECC_Table}.\\

				\begin{figure}[!htb]
					\begin{tabular}{| c | c | c |}
						\hline
						\textbf{Symmetric key size} & \textbf{RSA/Diffie-Hellman key size} & \textbf{Elliptic Curve key size} \\
						(bits) & (bits) & (bits) \\
						\hline
						\hline
						$80$ & $1024$ & $160$ \\
						\hline
						$112$ & $2048$ & $224$ \\
						\hline
						$128$ & $3072$ & $256$ \\
						\hline
						$192$ & $7680$ & $384$ \\
						\hline
						$256$ & $15360$ & $521$ \\
						\hline
					\end{tabular}

					\caption{A table showing the key sizes needed to achieve levels of security in both the traditional RSA/Diffie-Hellman groups and in Elliptic Curve groups. Taken from \cite{NSA_CaseForECC}. \label{fig:NSA_ECC_Table}}
				\end{figure}

				Elliptic Curve Groups are usually represented in Additive notation, differing from the usual Multiplicative notation used for groups in cryptography. This means when we add points together where we would usually multiple elements and apply scalar multiplication to a point where we would raise an element to the power of a scalar.\\

				We define a curve of the form $y^2 = x^3 + a\cdot x + b$ modulo some prime $q$, call this curve $C$. Say $n$ is the number of bits required to represent $q$, then we say this is an $n$-bit curve.\\

				We define the group by the set of elements and the group operation. The set of elements we give as,

				$$\{(x, y) \in \mathbb{Z}_p^2 : \textnormal{ where } y^2 = x^3 + a\cdot x + b\} $$

				We will use the most intuitive representation of points on elliptic curves, namely just the $(x, y)$ coordinates. We denote the identity in the group to be $(@, @)$ and the inverse of an element $(x, y)$ is simply $x, -y)$.\\

				This representation is sometimes called the \emph{Affine} representation, other representations exist and are used  when modular inversion are expensive as their operations reduce the number of inversions required for each group operation. Due to the speed of modular inversions in GMP we have opted to use Affine representation reducing bandwidth needed to send an element.\\


				\begin{mdframed}
					\begin{algorithm}[H]
						Take $P = (x_1, y_1)$ and $Q = (x_2, y_2)$, then $(x_3, y_3) = P + Q$. Then,\\[0.15cm]
						\eIf{($x_1 = x_2 \textnormal{ AND } y_1 \neq y_2$) OR
						    ($P = Q \textnormal{ AND } y_1 = 0$)}
						{
							$(x_3, y_3) = (@, @)$
						}
						{
							\eIf{($P \neq Q \textnormal{ AND } x_1 \neq x_2$)}
							{
								$x_3 = (\frac{y_2 - y_1}{x_2 - x_1})^2 - x_1 - x_2$\\
								$y_3 = (x_1 - x_3) * \frac{y_2 - y_1}{x_2 - x_1}$
							}
							{
								$x_3 = (\frac{3\cdot x_1^2 + a}{2 \cdot y_1}) ^ 2 - 2\cdot x_1$\\
								$y_3 = (x_1 - x_3) * \frac{3 \cdot x_1^2 + a}{2 \cdot y_1} - y_1$
							}
						}

						\caption{The group operation of the group of point on an Elliptic Curve defined by $y^2 = x^3 + a \cdot x + b$ in Affine Representation. \label{Algo:ECC_GroupOp}}
					\end{algorithm}
				\end{mdframed}

				\subsection{Elliptic Curve point scalar multiplication}
					As we noted above scalar multiplication of points is equivalent to Diffie-Hellman group exponentiations. As such we use scalar multiplication very often.\\

					Take a point $P$ and an integer $n$, consider $n \cdot P$, whilst we could compute this by $\sum_{i = 1}^{n}P$ this would require $n$ many additions. Where $n$ can be very big (say $256$-bits as in our group) this will require a stupendous number of group operations.\\

					Many of the same tricks that can be applied to integer exponentiation also work here. For example the square-multiply trick (though here it is double-add). Many of these tricks depend on taking advantage of thinking of the binary form of the exponent and using doubling.\\

					For standard point multiplication we have implemented the Windowed approach. Take a point $P$ and a scalar $n$. We pre-compute a set of multiplications of P, namely $\{w_i : w_i = i \cdot P\}_{i = 0}^{2^w - 1}$ where $w$ is the size of the windows in bits. We then consider the exponent in the form of $w$-sized windows, call the integer representation of the window $d_i$.

					\begin{mdframed}
						\begin{algorithm}[H]
							$Q = 0$;\\[0.25cm]
							\For{$i = m$ to $0$}
							{
								$Q := 2^w \cdot Q$ (using repeated point doubling);\\[0.25cm]
								\If{( $d_i > 0$ )}
								{
									Q := Q + $d_i \cdot P$;\\[0.25cm]
									// Compute $d_i \cdot P$ using pre-computed values.
								}
							}
							Return $Q$;\\[0.25cm]

							\caption{Windowed Scalar Elliptic Point Multiplication.}
						\end{algorithm}

					\end{mdframed}

					\subsubsection{Fixed Point Scalar Multiplication}
						What if there is some point which we shall be scalar multiplying very often? For example many cryptographic protocols repeatedly take scalar multiplications of the generator of the group.\\

						For such a point $P$ we can pre-compute the values $\{w_i := 2^i \cdot P\}_{i = 0}^{l}$ where $l$ is the size in bits of the order of the group. When computing some $k \cdot P$ we can output $k \cdot P = \sum_{i = 0}^{w} (k_i \cdot w_i)$ where $k_i$ is the value of the $i^{th}$ bit in $k$.\\

						This method of fixed point scalar multiplication is regularly cited as being three times faster than standard Windowed Scalar multiplications (see \cite{LindellPinkasSmart2008} for example).


			\section{Verifiable Secret Sharing and Multi-precision Polynomials}

				For the Zero Knowledge Proof of Knowledge specified in \cite{LindellAndPinkas2011} we need a Secret Sharing Scheme. For \cite{Katz_Symm_CnC_2013} we need to go one step further and have a Verifiable Secret Sharing Scheme.\\

				A Secret Sharing Scheme is a way of obscuring a secret whilst distributing shares to a set of parties such that only certain combinations of shares will be able to reconstruct the secret. So consider perhaps a bank vault which requires at least $3$ out of $10$ keys. Here the secret is the vault opening, the shares are the keys and the parties are the bank employees holding the keys. In general we speak of a $t$-out-of-$n$ scheme, where there are $n$ shares and $t$ of them are required to reveal the secret.\\

				For a fairly comprehensive overview of Secret Sharing I suggest pages 349-360 of \cite{NigelCryptoBook}.\\

				We have implemented Shamir's Secret Scheme (Shamir's) and its extension the Feldman's Scheme. Shamir's scheme is based on how many points are needed to uniquely define a polynomial curve.\\

				Consider a polynomial $K$ of degree $n$ over the finite field $\mathbb{F}_q$. Then we can denote this polynomial as $K = \sum_{i=0}^{n} a_i \cdot x ^ i$. Any such polynomial of degree $n$ can be uniquely defined given $n+1$ (or more) points on the curve, given $n$ or fewer points we gain no information about the polynomial.

				\subsection{Multi-precision polynomials}
					In order to use Shamir Secret Sharing we need an implementation of polynomials, furthermore in order to deal with the secrets of the the size we shall need to be dealing with we shall need Multi-precision polynomials.\\
					
					While several libraries exist with support for Multi-precision polynomials these are not commonly installed and given the ease of using GMP it was much simpler to implement Multi-Precision polynomials ourselves.\\

					We will not dwell on the details of this as this was quite trivial and is tangential. Suffice to say we have a structure for polynomials in a field, this structure contains a degree and a set of coefficients. We then coded functions to perform addition, multiplication and evaluation.

				\subsection{Shamir Secret Sharing}
					Shamir secret sharing was first proposed in \cite{ShamirSecretSharing} and gives a way to implement a Secret sharing scheme. The scheme consists of two algorithms, \texttt{Share} and \texttt{Recover}. We assume that each algorithm takes the field over which we work as an implicit input ($\mathbb{F}$).\\

					\texttt{Share} takes a secret $a \in \mathbb{F}$ and a pair of integers $t$ and $n$ such that $t \leq n$. It returns a set of $n$ shares (also elements in the field) such that $t + 1$ many are needed to recover the secret $a$. Note that the shares are indexed in the order they are output by \texttt{Share}.\\

					More concretely, to share a secret $a$ we generate a polynomial $F(X) = a + f_1 \cdot X + f_2 \cdot X^2 + ... +  + f_t \cdot X ^ t$. We then output $\{c_i = F(i)\}$ as the shares, note then that $F(0) = a$. The polynomial is \emph{not} known to the parties.\\

					\texttt{Recover} takes a set of $\tilde m$ shares $\{c_i\}$ where $i$ indicates the index of the share. \texttt{Recover} returns a $ \tilde a \in \mathbb{F}$. If $t \leq \tilde m$ and the $c_i$ are all valid shares then $\tilde a = a$.\\

					If we have $t + 1$ or more valid shares of the secret then we can reconstruct the polynomial $F$ by Lagrange interpolation. We will not dwell on the details of Lagrange interpolation.\\

				\subsection{Verifiable Secret Sharing}

					A Verifiable Secret Sharing (VSS) scheme is an extension to `vanilla' secret sharing schemes where any party can check whether an input is a valid share to a secret. This additional property is very important for the protocol described in \cite{Katz_Symm_CnC_2013}.\\

					We have implemented the Feldman VSS scheme which is an extension of the Shamir scheme. The basic concept is that the sharing step also publishes a public commitment to the shares to all parties. Then using the candidate share, the index of the  candidate share and the commitments any party can verify whether the candidate share is a valid share of the secret.

					Recall the polynomial used for the scheme is of the form $F(X) = a + f_1 \cdot X + f_2 \cdot X^2 + ... +  + f_t \cdot X ^ t$, and take $g$ to be a generator of the field. Then the public commitments to the shares of this polynomial are,
					$$p_0 = g^a, p_1 = g^{f_1}, p_2 = g^{f_2}, ..., p_t = g^{f_t}.$$
					
					As the name suggests these public commitments are sent to all parties. Then given a share $c$ and an index for the share $i$ any party can verify that $c$ is the valid $i^{th}$ share by computing $\prod_{j=0}^{t} p_0 ^ {i ^ j}$ and testing this equals $g ^ c$. If it does it is a valid share, else it is not.

	\end{appendices}

\end{document}


