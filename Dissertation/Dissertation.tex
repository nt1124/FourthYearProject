\documentclass[ % the name of the author
                    author={Nicholas Tutte},
                % the name of the supervisor
                supervisor={Prof. Nigel Smart},
                % the degree programme
                    degree={MEng},
                % the dissertation    title (which cannot be blank)
                     title={Secure Two Party Computation},
                % the dissertation subtitle (which can    be blank)
                  subtitle={A practical comparison of recent protocols},
                % the dissertation     type
                      type={Research - GG1K},
                % the year of submission
                      year={2015} ]{dissertation}

\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{graphicx}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{mdframed}


\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

	\maketitle
	% \frontmatter
	
	%\newpage
	\chapter*{Declaration}

		This dissertation is submitted to the University of Bristol in accordance 
		with the requirements of the degree of \textbf{GG1K} in the Faculty 
		of Engineering.  It has not been submitted for any other degree or diploma 
		of any examining body.  Except where specifically acknowledged, it is all 
		the work of the Author. 

		\vspace{6cm}

		\noindent{Nicholas Tutte}, \today


	\chapter*{Prelude}
		\section*{Executive Summary}
			\subsubsection*{Abstract}
			  We present implementations of several recently proposed Secure Two Party Computation protocols and perform experiments for the purpose of comparing their performance across a range of computations. Until now we have had only theoretical comparisons of these protocols, making it difficult to know which approach is the most promising.\\

			  In particular we have implemented the protocols described in \cite{LindellAndPinkas2011}, \cite{Lindell_CnC_2013} and \cite{Katz_Symm_CnC_2013} and additionally we experiment with modifying \cite{Lindell_CnC_2013} to use \cite{Katz_Symm_CnC_2013} instead of \cite{LindellAndPinkas2011} as a sub-protocol.\\

			\subsubsection*{Summary of Achievements}
				\begin{itemize}
					\item We implemented the protocols described in \cite{LindellAndPinkas2011, Lindell_CnC_2013}, to the best of my knowledge these are the first implementations of these protocols.
					\item We implemented the protocol described in \cite{Katz_Symm_CnC_2013}. Huang et al. have produced an implementation in Java this cannot be fairly compared to my C implementations of the other protocols. 
					\item We experimented with modifying the sub-protocol used for the Secure computation to detect cheating in \cite{Lindell_CnC_2013}, exchanging the use of \cite{LindellAndPinkas2011} for \cite{Katz_Symm_CnC_2013}.
					\item We have run practical comparisons of all the implemented protocols on a variety of circuits/computations and provided some analysis of the results.
				\end{itemize}

		\section*{Supporting Technologies}
			\begin{itemize}
					\item Unless otherwise stated all tests have been run upon the Bristol Cryptography Group's Diffie and Hellman machines. These machines are identical and have dedicated network cards for communications between each other.
					\item All code is in either C or C++, using the OpenMP library for parallelism in the shared memory paradigm. Furthermore AES-NI support is enabled.
					\item Extensive use has been made of the GNU Multi Precision Arithmetic Library.
					\item The net code was provided by my supervisor Prof. Nigel Smart.
					\item The AES implementation I use was mostly provided by my supervisor Prof. Nigel Smart (coded by Dr. Dan Page). Though I have extended this as it did not provide non-AES-NI decryption.
					\item The SHA-2 implementation used was taken from [INSERT CITATION HERE].
					\item For much of the random number generation we have used the implementation of ISAAC provided by [ISAAC IMPLEMENTATION CITATION HERE].
			\end{itemize}

		\section*{Notational Glossary}
			$\mathbb{G} = (G, g, q) \leftarrow \zeta(1^n)$ informally speaking this indicates choosing a group such that the `security' of the group is $n$ bits. We define the group as the tuple $(G, g, q)$ where $G$ is the set of all elements of the group, $g$ is a set that generates $G$ (we deal primarily in Cyclic groups so usually this will be a single element) and finally $q$ which is the order of the group.

	% \mainmatter
	% CONTENTS.
	\tableofcontents


	% NOTATION SECTION
	
	\chapter{Introduction}
		Secure multi-party computation(SMC) is a long standing problem in Cryptography. We have a set of parties who wish to cooperate to compute some function on inputs distributed across the parties. However, these parties distrust one another and do not wish their inputs to reveal their inputs to the other parties. Using SMC we can perform the desired computation without any party ever knowing the other's inputs.\\

		A commonly used example is the Millionaires problem. A group of rich persons wish to find out who among them is the richest, but do not wish to tell each other how much they are worth. Here the parties are the rich individuals, each party's inputs is their net worth and the function will return the identifier of the individual with the greatest input. Additionally, at the end of the computation no party should be able to divine anything about another party's inputs, apart from what can be inferred from their own input and the output.\\

		For many years Yao's protocol \cite{YaoOriginal} has been the most attractive avenue of theoretical research, mainly due to its conceptual simplicity and constant round nature. In particular recent work has endeavoured to produce variants of Yao's protocol that can provide security in the presence of malicious adversaries (\cite{LindellAndPinkas2007}, \cite{LindellAndPinkas2011}, \cite{Lindell_CnC_2013}, \cite{Katz_Symm_CnC_2013}, \cite{OnCommittedInputs}, \cite{LEGO_Paper}, \cite{MiniLEGO}) and to improve the efficiency of the original protocol itself (\cite{SMC_Is_Practical}, \cite{FreeXOR}).\\


		% Perhaps mention here the Lindell talk where he lists off the time taken to compute certain functions and how it's improved.

		Our contributions are as follows,

		\begin{itemize}
			\item To the best of our knowledge we provide the first implementations of the protocols of \cite{LindellAndPinkas2011} and \cite{Lindell_CnC_2013}.% and \cite{Katz_Symm_CnC_2013}.
			\item We put forward and implement a modification of \cite{Lindell_CnC_2013} using \cite{Katz_Symm_CnC_2013} for the sub-computation rather than \cite{LindellAndPinkas2011} as originally proposed.
			\item We measure the performance of each protocol on several of the classic SMC benchmark computations.
		\end{itemize}

		% In this paper we shall be producing implementations of several recently proposed protocols based on Yao's protocol and, several of which are as yet unimplemented, producing a practical comparison of them. The purpose being to explore which protocol suggests the most potential, allowing future research to be directed in the most promising direction.

		% \section{Paper Structure} Section \ref{sec:BG_toSMC} provides a more detailed overview of the problem of Secure Multiparty Computation and consider some of its applications for the purposes of motivation. Section \ref{sec:Yao_Circuits} introduces the basic ideas underlying Yao's protocol that are the cornerstone of the protocols we are comparing. Section \ref{sec:Protocols} delves into the specifics of each of the protocols we have implemented, touching on the main ideas and challenges of each. Section \ref{sec:ImplementationDetails} 


	\chapter{Background to Secure Multiparty Computation} \label{sec:BG_toSMC}
		\section{Security Properties} \label{sub:SecurityProperties}
			There are three main properties that we wish to achieve with any SMC protocol,
			\begin{itemize}
				\item Privacy, the only knowledge parties gain from participating is the output.
				\item Correctness, the output is indeed that of the intended function.
				\item Independence of inputs, no party can choose it's inputs as the function of other parties inputs.
			\end{itemize}

			In this sense we define the goal of an adversary to compromise any one of these properties.\\

			We compare any protocol to the \emph{ideal} execution, in which the parties submit their inputs to a universally trusted and incorruptible external party via secure channels. This trusted party then computes the value of the function and returns the output to the parties.\\

			Informally we say that the protocol is secure if no adversary can attack the protocol with more success than they can achieve than the ideal model. More formally a protocol is secure if it 

			It is worth noting that 

			% Alice-Bob-Trevor could go here.

		\section{Security levels}\label{sub:SecurityLevels}
			Having established the goals of the adversary and how we can measure if said adversary has a valid attack, we next deal with the capabilities of the adversary. We use three main models to describe the capability of the adversary.

			\subsection{Semi-honest Adversary}
				The Semi-honest adversary is the weakest adversary, with very limited capabilities. The Semi-honest adversary has also been referred to as ``honest but curious'', because in this case the adversary is not allowed to deviate from the established protocol (i.e. they are honest), but at the same time they will do their best to compromise one of the aforementioned security properties by examining the data they have legitimate access to. This is in some ways analogous to the classic ``passive'' adversary.

				\subsubsection{Example}

				\textcolor{red}{At first it can be difficult to think of applications where only Semi-Honest security is required, but such applications do exist. Mostly Semi-Honest security can be used in situations where it is not in the interest of either party to cheat.}\\

				\textcolor{red}{So take the example of parties who wish to decide whether they should cooperate on a particular project. More concretely maybe two drug companies are considering cooperating in a particular area of research, but first need to establish that they have the combined expertises required. To do this without unecessarily revealing information about their capabilities to the other company they might run a legally binding Secure Computation.}\\
				
				\textcolor{red}{In this case undetected cheating could lead to the parties committing to a project they do not have the expertises to complete, this is clearly not in the interests of the parties so it is likely that both parties will act honestly.}\\
				
				

			\subsection{Malicious Adversary}
				The Malicious adversary is allowed to employ any polynomial time strategy and is not bounded by the protocol (they can run arbitrary code instead), furthermore the Malicious adversary does not care if it is caught cheating so long as it achieves its goal in the process. This is in some ways analogous to the classic ``active'' adversary.

				\subsubsection{Example}
					\textcolor{red}{Security in the presence of malicious adversaries is much sought after, and is useful in many more scenarios. Suppose a pair of persons wish to compute the intersection of sets they each hold but only wish to reveal those elements in both sets, keeping the rest secret.}\\

					\textcolor{red}{A malicious adversary might wish to reveal all of the elements in the other party's set. If the adversary can rig the condition in the computation checking whether an element is in both sets they can get all elements returned. Clearly in this case the adversary has something to gain and so we cannot count on the adversary being honest.}\\


			\subsection{Covert Adversary}
				The Covert adversary model is very similar to the Malicious model, again bounded by polynomial time with freedom to ignore the protocol. However, in this case the adversary is adverse to being caught cheating and is therefore slightly weaker than the Malicious adversary. A Covert adversary will accept a certain probability of detection, this probability represents the point at which the expected benefit of cheating successfully outweighs the expected punishment for getting caught, effectively a game theory problem \cite{WhenGameTheoryMetSMC}.\\

				We call the probability that a Covert adversary will be caught the ``deterrent probability'', usually denoted using $\epsilon$. Often protocols providing security against Covert adversaries take a Security parameter which varies the probability of detecting cheating.

				\subsubsection{Example} 

				\textcolor{red}{ This model can be thought of as a compromise between practicality and malicious security and is usually appropriate when there are tangible consequences to a party being caught cheating. For example consider the case where a group of companies are required to report on certain business dealing }

		\section{Applications of SMC} \label{sub:Applications}
			Here we take time to motivate the study of SMC by giving several actual or proposed applications.

			\subsection{Secret Auctions - Danish Beets} \label{BeetsAuctionApplication}
				In Denmark a significant number of farmers are contracted to grow sugar beets for Danisco (a Danish bio-products company). Farmers can trade contracts amongst themselves (effectively sub-contracting the production of the beets), bidding for these sub-contracts is done via a ``double auction''.\\

				Farmers do not wish to expose their bids as this gives information about their financial state to Danisco and so refused to accept Danisco as a trusted auctioneer. Similarly all other parties (e.g. Farmer union) already involved are in some way disqualified. Rather than rely on a completely uninvolved party like an external auction house (an expensive option) the farmers use an SMC-based approached described in \cite{SugarBeets}. Since 2008 this auction has been ran multiple times \\

				As far as team behind this auction are aware this was the first large scale application of SMC to a real world problem, this application example in particular is important as it is a concrete practical example of SMC being used to solve a problem demonstrating this is not just a Cryptological gimmick.

			% SHOULD REALLY PROVIDE CITATION TO THEIR WEBSITE. AND TO RSA
			\subsection{Distributed secrets} \label{sub2:DistributedSecretApplication}
				Consider the growing use of physical tokens in user authentication, e.g. the RSA SecurID. When each SecurID token is activated the seed generated for that token is loaded to the relevant server (RSA Authentication Manager), then when authentication is needed both the server and the token compute `something' using the aforementioned seed. However, this means that in the event of the server being breached and the seed being compromised the physical tokens will need to be replaced. Clearly this is undesirable, being both expensive both in terms of up front clean up costs and reputation.\\

				In the above scenario we clearly need to store the secret(the seed) somewhere, but if we can split the seed across multiple servers and then get the servers to perform the computation as a SMC problem (where each server's input is their share of the secret, the output the value to compare to the token's input) then we can increase the cost to an attacker, as they will now have to compromise multiple servers. Such a service is in development by Dyadic Security (full disclosure, my supervisor Prof. Nigel Smart is a co-founder of Dyadic).

			\subsection{PROCEED - Computation on encrypted data} \label{sub2:PROCEED_DARPA}
				Recently US Defence Advanced Research Projects Agency (DARPA) ended a programme called PROCEED. The eventual goal being the ability to efficiently perform computations on encrypted data without knowledge of the data. This could be used by companies such as Google to continue to provide services requiring computation on personal data without intruding on the privacy on their users.

				 % MORE DETAILS! SEE IF WE CAN GET THE NAME OF THE SUCCESSOR PROGRAMME FROM NIGEL. ALSO CITE THEIR WEBSITE OR SOME PAPER SUMMING UP THE PROCEED PROGRAMME

	
	\chapter{Technical Background}
		\section{Oblivious Transfer} \label{sec:OT_Intro}
			Oblivious Transfers are vitally important for SMC and in particular Yao's Protocol that we shall be looking at later. Oblivious Transfers protocols allow for one party(called the receiver) to get exactly one out-of two (and can be extended to k-out-of-n for $k < n$) values from another party (called the Sender). The receiver is oblivious to the other value(s), and the Sender is oblivious to which value the receiver received.\\

			Oblivious Transfers were first suggested by Rabin in \cite{Rabin81}. We define the functionality of a 1-out-of-2 OT protocol in Figure \ref{fig:OTformalDef}. Oblivious Transfers are vital to Yao Garbled Circuits, used to give the circuit Executor data it needs to evaluate the circuit under their input without revealing to the circuit Builder what those inputs were.\\

			\begin{figure}[!htb]
				\centering
				\begin{minipage}{0.45\textwidth}
					\centering
					\textbf{Receiver}\\
					Inputs : $b \in \{0, 1\}$\\
					Outputs : $x_b$\\
				\end{minipage}
				\begin{minipage}{0.45\textwidth}
					\centering
					\textbf{Sender}\\
					Inputs : $x_0, x_1 \in \{0, 1\}^l$\\
					Outputs : $\emptyset$\\
				\end{minipage}

				\caption{ Formal definition of the functionality of a one-out-of-two OT protocol.\label{fig:OTformalDef}}
			\end{figure}

			The security of Oblivious Transfers is defined in a similar way to that of SMC, the focus is on Semi-honest(passive) and Malicious(active) adversaries. Security against these adversaries is usually either computational or statistical.\\

			A protocol is considered secure with regards to Semi-honest adversaries if neither a Semi-honest adversary in the sender role cannot learn anything about which value the receiver requested, nor can a Semi-honest adversary in the role of the Receiver learn anything about values other than the one it requested. The protocol being secure against Malicious adversaries is defined by the obvious extension of the Semi-honest case.\\

			We primarily use OTs based on the Peikert-Vaikuntanathan-Waters OT (PVW-OT) from \cite{PVW_OT_2008} or more precisely the modifications of the PVW-OT suggested in \cite{LindellAndPinkas2011} and expanded on in \cite{Lindell_CnC_2013}. However, we also use the Naor-Pinkas (NP-OT) from \cite{NaorPinkasOT2001} for the protocol in \cite{Katz_Symm_CnC_2013}.


			\subsection{Naor-Pinkas Oblivious Transfer} \label{sub:NaorPinkasOT}

				Here we describe the Naor-Pinkas Oblivious Transfer as put forward in \cite{Katz_Symm_CnC_2013} that is used in the Huang, Katz and Evans protocol later implemented, for a full description including proofs of security see \cite{NaorPinkasOT2001}.\\

				We assume that we have the usual OT inputs and parties. That is a Sender $S$ who holds two input bit strings denoted $x_0, x_1 \in \{0, 1\}^*$ and a Receiver who has a $b \in \{0, 1\}$ representing the  input that the Receiver wishes to uncover.\\

				On top of these inputs the parties share a group $\mathbb{G}$ as an auxiliary input. We denote the group by $(\mathbb{G}, g, q)$ where $<g> = \mathbb{G}$ and $q$ is the order of the group.\\ %($g$ generates $\mathbb{G}$)

				See Figure \ref{fig:NPOT_Functionality} for the functionality of the Naor-Pinkas OT.\\


				\begin{figure}[!htb]
					\centering
					
					\textbf{Shared Auxiliary Input}\\
					$\mathbb{G}$ a group for which the CDH assumption is believed to hold.\\
					\vspace{0.3cm}
					\begin{minipage}{0.45\textwidth}
						\centering
						\textbf{Receiver}\\
						Inputs : $b \in \{0, 1\}$\\
						Outputs : $x_b$\\
					\end{minipage}
					\begin{minipage}{0.45\textwidth}
						\centering
						\textbf{Sender}\\
						Inputs : $x_0, x_1 \in \{0, 1\}^l$\\
						Outputs : $\emptyset$\\
					\end{minipage}

					\caption{ Formal definition of the functionality of The Naor-Pinkas Oblivious Transfer.\label{fig:NPOT_Functionality}}
				\end{figure}

				The Naor-Pinkas OT is known to be simulatable against a malicious Sender assuming the CDH holds in the group $\mathbb{G}$. However, it is only known to provide \emph{privacy} against a malicious Receiver, the question of whether it is simulatable against such an adversary is as yet unanswered.

				\begin{figure}[!htb]
					\begin{mdframed}
						\centering
						\begin{tabular}{l c l}
							\textbf{Sender} & Group $\mathbb{G} = (G, g, q)$ & \textbf{Receiver}\\
							$x_0, x_1 \in \{0, 1\}^l$ & & $b \in \{0, 1\}$\\[0.6cm]

							$C \xleftarrow{\$} G$ & &\\

							& \commRightArrow{C} & \\

							& & $k \xleftarrow{\$} \mathbb{Z}_q$ \\
							& & $h_0 \leftarrow g^k$\\
							& & $h_1 \leftarrow C / g^k $\\

							& \commLeftArrow{h=h_b} & \\

							$r \xleftarrow{\$} \mathbb{Z}_q$ & &\\
							$a \leftarrow g ^ r$ & &\\
							$c_0 \leftarrow H(h^r) \oplus x_0$ & &\\
							$c_1 \leftarrow H( (C / h)^r) \oplus x_1$ & &\\

							& \commRightArrow{a, c_0, c_1} & \\

							& & $y \leftarrow a ^ k (= g^{r \cdot k})$ \\
							& & $x_b \leftarrow H( y ) \oplus c_b$ \\
							& & Output $x_b$\\
						\end{tabular}
					\end{mdframed}

					\caption{ The Naor-Pinkas Oblivious Transfer protocol. Note that the same $C$ can be used for multiple OTs.\label{fig:NPOT_Protocol}}
				\end{figure}



			% THIS NEED TIDYING UP
			\subsection{Peikert - Vaikuntanathan - Waters Oblivious Transfer} \label{sub:dualModeCryptoOT}
				\textcolor{red}{The basis of the Oblivious transfer protocol we shall be using comes from \cite{PVW_OT_2008}, in particular we shall be using the realisation of the dual-mode cryptosystem based on Decisional Diffie-Hellman problem. Whilst I shall not go into depth on this protocol we shall give a broad overview of the dual-mode cryptosystem.}\\

				\subsubsection{High level concepts}
					\textcolor{red}{The Peikert-Vaikuntanathan-Waters (PVW) OT has at its core the concept of a messy key. This is a key such that under encryption by this key all information about the plaintext is lost, moreover messy keys are indistinguishable from normal valid (\emph{neat}) keys that do not obliterate the plaintext. It does not take much to see how these could be useful for an Oblivious Transfer scheme.}\\

					\textcolor{red}{The PVW OT is constructed in such a way we can ensure one of the keys will be a messy key, whilst the other will be a neat key. Furthermore the Receiving party can control which key will be messy and which will be neat, allowing the Receiving party to choose which input to uncover.}

				\subsubsection{Dual-Mode Encryption}
					\textcolor{red}{Peikert-Vaikuntanathan and Water's describe a new abstraction, a Dual-mode cryptosystem. This system requires a setup phase in which the parties produce a public \emph{Common Reference String} and potentially a trapdoor. Peikert et al. state that this trapdoor information is only needed for the security proof as such we will mostly ignore these details.}\\

					\textcolor{red}{The setup also chooses one of two modes (\emph{messy} and \emph{decryption}).. Once this setup is complete this cryptosystem is very similar to a normal Public Key system, with one major difference, Peikert et al. introduce the concept of encryption branches.}\\
					
					\textcolor{red}{The key generation algorithm takes a parameter $\sigma \in \{0, 1\}$, and returns a public/secret key pair. Similarly when encrypting using the public key produced by the key generation one must also specify a $b \in \{0, 1\}$.}\\

					\textcolor{red}{Plaintexts can be decrypted if encrypted with $b = \sigma$ (the decryptable branch of $pk$), but plaintexts encrypted with $b \neq \sigma$ cannot be decrypted (we call this the messy branch of $pk$). Additionally when carrying out an encryption using a public key provided by the other party you cannot tell which branch is decryptable.}\\

					\textcolor{red}{Depending on which mode is selected during setup the trapdoor returned allows subversion of one of these properties. If the system is in messy mode the trapdoor allows the encrypting party to distinguish when the branch input to the key generation that produced a public key was. If the system is in decryptable mode the trapdoor allows the decryption of both branches.}\\

					\textcolor{red}{In Figure \ref{fig:PVW_Abstract_Functions} we more formally define the abstract system and in particular what functions are required.}\\

					\begin{figure}[!htb]
						\begin{mdframed}
							\centering
							\begin{itemize}
								\item \textbf{Setup}($1^n$, $\mu$) - This function takes a security parameter $1^n$ and a bit $\mu \in \{0, 1\}$ which defines which mode (messy or decryptable). The function should output the CRS and trapdoor information (crs, t). All other functions take this crs as an implicit parameter.\\[0.25cm]

								In order to ease notation later we define two separate functions depending on $\mu$. \textbf{SetupMessy}$(1^n) :=$ \textbf{Setup}$(1^n, 0)$ and \textbf{SetupDec}$(1^n) :=$ \textbf{Setup}$(1^n, 1)$.\\[0.25cm]


								\item \textbf{KeyGen}($\sigma$) - This function takes a single input of a bit $\sigma \in \{0, 1\}$ and outputs ($pk$, $sk$) where $pk$ is a public key for encryption and $sk$ is a secret key that allows decryption of plaintexts encrypted using $pk$ on the branch $\sigma$.

								\item \textbf{Enc}($m$, $pk$, $b$) - This function takes a message $m \in \{0, 1\}^l$, a public key $pk$ and a bit $b \in \{0, 1\}$. It returns the encryption of $m$ under $pk$ on branch $b$.

								\item \textbf{Dec}($c$, $sk$) - This function takes a ciphertext $c$ and a secret key $sk$. It outputs a message $m' \in \{0, 1\}^l$.

								\item \textbf{FindMessy}($pk$, $t$) - This function takes a public key $pk$ and a messy mode trapdoor $t$. The function then outputs a bit $b \in \{0, 1\}$ indicating which branch of $pk$ is messy.

								\item \textbf{TrapKeyGen}($t$) - This function takes decryptable mode trapdoor $t$ and is an alternative key generation. The function outputs $(pk, sk_0, sk_1)$, note that it outputs two secret keys, one for each branch. These secret keys allow the decryption of both branches of $pk$.
							\end{itemize}
						\end{mdframed}

						\caption{The abstract functions the define a Dual-mode cryptosystem. \label{fig:PVW_Abstract_Functions}}
					\end{figure}

				\subsubsection{Dual-mode encryption using DDH}

					Having described the abstract form of a Dual-mode cryptosystem we now give a concrete realisation. This realisation requires a group, as usual we define this group as $\mathbb{G} = (G, g, q)$ where $g$ generates $G$ and $|g| = q$. Further we require that the the group is chosen such that we believe the Decisional Diffie-Hellman problem be hard for this group.\\

					%Not sure if we should bother explaining the DDH problem.
					Before giving concrete definitions of the functions we need a few primitives relating to DDH cryptosystems.\\
					
					\paragraph{Randomisation} Take $G$ to be an arbitrary group, we shall use multiplicative notation, such that the group is of order $p$ where $p$ is prime. We then define $DLOG_G(x) = \{ (g, g^x) : g \in G\}$. Put another way $DLOG_G(x)$ is the set of all pairs of elements in $G$ such that the discrete log of the second over the first is $x$.\\
					
					We define a probabilistic algorithm \emph{Randomise} that takes generators $g,h \in G$ and elements $g', h' \in G$. The algorithm then outputs $(u, v) \in G^2$ such that the following properties hold,
					
					\begin{itemize}
						\item If $(g, g'), (h, h') \in DLOG_G(x)$ for some $x \in \mathbb{Z}_p$ then $(u, v)$ is chosen from $DLOG_G(x)$ uniformly at random.

						\item If $(g, g')\in DLOG_G(x)$ and $(h, h') \in DLOG_G(y)$ for some distinct $x, y \in \mathbb{Z}_p$ then $(u, v)$ is chosen uniformly at random from $G^2$.
					\end{itemize}
					In particular we define $Randomise(g, h, g', h')$ as follows, choose $s, t \xleftarrow{\$} \mathbb{Z}_p$ independently of one another, then let $u = g^s \cdot h^t$ and $v = (g')^s \cdot (h')^t$.\\
					A full proof that this instantiation of \emph{Randomise} is given in \cite{PVW_OT_2008}, suffice to say the main idea of the proof is to re-write $h$ as a power of $g$ which we can do as $g$ generates $G$.\\
					Having defined the function \emph{Randomise} Peikert et al. next defined a simple asymmetric cryptosystem based on it.

					\paragraph{DDH-Randomise Cryptosystem} As with all asymmetric cryptosystems we need to define three algorithms namely key generation, encryption and decryption.

					\begin{figure}[!htb]
						\begin{mdframed}
							\centering
							\begin{itemize}
								\item \textbf{DDH-KeyGen}($1^n$) - This function takes a security parameter and chooses a group $\mathbb{G} = (G, g, q) \leftarrow \gamma(1^n)$, this group $G$ is the message space. For our purposes this group will be an Elliptic curve group of size $\sim2^{2n}$.\\[0.25cm]

								Then choose another generator of the group $h \in G$ and an exponent $x \in \mathbb{Z}_p$. Then set $pk = (g, h, g^x, h^x)$ and $sk = x$. 

								\item \textbf{DDH-Enc}($pk$, $m$) - This function takes a message $m \in \{0, 1\}^l$, a public key $pk$. The public key should be parsed as $(g, h, g', h')$.\\[0.25cm]

								The function computes $(u, v) \leftarrow Randomise(g, h, g', h')$ and then outputs the ciphertext $(u, v \cdot m)$.

								\item \textbf{DDH-Dec}($sk$, $c$) - This function takes a ciphertext $c$ and a secret key $sk$, parse $c$ as $(c_0, c_1)$. Output a decryption $m' = c_1 / c_0^{sk}$.

							\end{itemize}
						\end{mdframed}

						\caption{A simple asymmetric cryptosystem based on \emph{Randomise} in a DDH group. It is important to note here that this system is messy if  \label{fig:DDH_Cryptosystem}}
					\end{figure}


					\paragraph{Dual-mode Cryptosystem based on Randomise} Finally Peikert et al. give instantiations of the functions specified in \ref{fig:PVW_Abstract_Functions}, using the DDH cryptosystem just defined. These instantiations can be seen in Figure \ref{fig:PVW_DDH_Concrete_Functions}\\

					
					\begin{figure}[!htb]
						\begin{mdframed}
							\centering
							\begin{itemize}
								\item \textbf{Setup}$(1^n, \mu)$ - Recall that for notational purposes we split this function depending on the value of $\mu$. However, both branches of this function begin by choosing a group $\mathbb{G} = (G, g, p) \leftarrow \zeta(1^n)$. Then the Decryption and Messy Setup functions diverge.

								\textbf{SetupDec}$(1^n)$ - Choose a random generator $g_0 \in G$, a random \emph{non-zero} exponent $y \in \mathbb{Z}_p$ and let $g_1 = g_0^y$. Then take another random \emph{non-zero} exponent $x \in \mathbb{Z}_p$ and let $h_b = g_b^x$ for $b \in \{0, 1\}$. The outputs are then $(crs, t) = ( (g_0, h_0, g_1, h_1), y )$.

								\textbf{SetupMessy}$(1^n)$ - Choose a pair of random generators $g_0, g_1 \in G$ and a pair of random \emph{distinct and non-zero} exponents $x_0, x_1 \in \mathbb{Z}_p$. Let $h_b = g_b^{x_b}$ for $b \in \{0, 1\}$.  The outputs are then $(crs, t) = ( (g_0, h_0, g_1, h_1), (x_0, x_1) )$.

								\item \textbf{KeyGen}($\sigma$) - Firstly choose $r \xleftarrow{\$} \mathbb{Z}_p$. Then set $g = g_{\sigma}^r$ and  $h = h_{\sigma}^r$. Finally set $pk = (g, h)$ and $sk = r$ and output $(pk, sk)$.

								\item \textbf{Enc}($m$, $pk$, $b$) - Parse $pk$ as $(g, h)$. Let $pk_b = (g_b, h_b, g, h)$ where $g_b, h_b$ are taken from the crs. Then output \textbf{DDH-ENC}$(pk_b, m)$

								\item \textbf{Dec}($sk$, $c$) - This function just outputs \textbf{DDH-Dec}$(sk, c)$.

								\item \textbf{FindMessy}($pk$, $t$) - Parse $pk$ as $(g, h)$ and a messy mode trapdoor $t$ as $x_0, x_1$. If $h \neq g^{x_0}$ then output 0 (as the $pk$ provided is for branch 1, so branch 0 is the messy branch). Else output 1.

								\item \textbf{TrapKeyGen}($t$) - Parse $t$ as $y \in \mathbb{Z}_p$, check that $y$ is indeed non-zero and a member of $\mathbb{Z}_p$. Pick a random $r \xleftarrow{\$} \mathbb{Z}_p$, compute $pk = (g_0^r, h_0^r)$ and output $(pk, r, r / y)$
							\end{itemize}
						\end{mdframed}

						\caption{The realisation of the Dual-mode cryptosystem based on the DDH cryptosystem defined. \label{fig:PVW_DDH_Concrete_Functions}}
					\end{figure}

					\paragraph{Trusted Setup} - Peikert et al. state that the OT they provide requires a trusted setup. They claim this is a reasonable assumption and can be achieved using shared randomness, they suggest sunspots. To understand what the problem and why trusted setup is required consider the following case.\\

					Suppose the Receiving party performs the setup, recall however, that the Sender will not be able to tell if the $crs$ they are given by the Receiver is a Messy $crs$ or a Decryptable $crs$. Therefore it is then childs play for the Receiver to produce a Decryptable $crs$ and to keep the trapdoor, allowing the Receiver to decrypt on both branches giving access to all of the Senders inputs.\\
					
					One might hope letting the Sending party perform setup might be better, in fact it is much worse. Clearly the clear logical reverse of the Receiver case is possible, where the Sender performs a Messy setup and as such can then, using the resulting trapdoor values, uncover what values the Receiver is requesting.\\%One obvious possible solution might be to require a Zero Knowledge Proof of Knowledge that the 

					In short, both parties could potentially craft a malicious $crs$ during setup allowing them to subvert the properties of the Dual-mode system, so the solution is to divide the work between the two parties so each provide some of the $crs$ in such a way that neither has enough information to create the trapdoor that is worth anything to them .


	\section{Yao's Protocol} \label{sec:Yao_Circuits}

		\subsection{Overview} \label{sub:Yao_Overview}
			Yao garbled circuits are one of the primary avenues of research into Secure multi-party computation. Yao first proposed garbled circuits in \cite{YaoOriginal}. The two parties are designated the Builder and the Executor. The Builder then constructs a circuit representing the function the parties wish to compute, this circuit is ``garbled'' in such a way that it can still be executed.\\

			This garbled circuit, hardcoded with the Builder's input data, is sent to the Executing party who then obtains the data representing its input from the Builder via Oblivious Transfer (for details on OT see Section  \ref{sec:OT_Intro}). The Executor then evaluates the circuit and obtains the output of the function.


		\subsection{Yao Garbled Circuits} \label{sub:Yao_Details}
			As noted above we first represent the function to compute as a binary circuit. Denote the two parties as $P_1$ and $P_2$, we will denote the party building the circuit by $P_1$ and the executing party by $P_2$.\\
			
			Take a single gate of this circuit with two input wires and a single output wire. Denote the gate a $G_1$ and the input wires as $w_1$ and $w_2$ and let $w_3$ be the output wire. Let $b_i \in \{0, 1\}$ be the value of $w_i$. Here we will take the case where $w_i$ is an input wire for which $P_i$ provides the value. Define the output value of the gate to be $G(b_1, b_2) \in \{0, 1\}$. We now garble this gate in order to obscure the inputs and outputs.\\

			$P_1$ garbles each wire by selecting two random keys of length $l$, for the wire $w_i$ call these keys $k_i^0$ and $k_i^1$. The length of these keys ($l$) can be considered a security parameter, and should correspond to the length of the key needed for the symmetric encryption scheme we'll be using later. Further $P_1$ also generates a random permutation $\pi_i \in \{0, 1\}$ for each $w_i$. We define $c_i = \pi_i(b_i)$. The garbled value of the $i^{th}$ wire is then $k_i^{b_i} \Vert c_i$, we then represent our garbled truth table for the gate with the table indexed by the values for the $c_1$ and $c_2$.

			$$ c_1, c_2 : E_{k_1^{b_1}, k_2^{b_2}} (k_3^{ G(b_1, b_2) } \Vert c_3) $$

			Where $E_{k_i, k_j}(m)$ is some encryption function taking the keys $k_i$ and $k_j$ and the plaintext $m$. Since the advent of AES-NI and the cheapness of using AES we will use AES with 128 bit keys to make this function. Suppose that $AES_k(m)$ denotes the AES encryption of the plaintext $m$ under the 128 bit key $k$ and $AES^{-1}_k(c)$ denotes the decryption of ciphertext $c$ under key $k$. We define $E_K$ (and it's inverse $D_K$) as follows,

			$$ E_K(m) = AES_{k_1}( AES_{k_2}( ...AES_{k_n}(m) ...) ) \textnormal{, where } K = \{k_1, ..., k_n\}$$ 
			$$ D_K(m) = AES^{-1}_{k_n}( AES^{-1}_{k_{n-1}}( ...AES^{-1}_{k_1}(m) ...) ) \textnormal{, where } K = \{k_1, ..., k_n\}$$ 

			This is the intuitive extension of AES to multiple keys, chaining the encryption under all of the keys in a set order.\\

			Then $P_1$ (the builder of the circuit) sends this garbled version of the circuit to $P_2$ (the executor of the circuit). $P_1$ should send the garbling key for it's input bit ($k_1^{b_1}$), the full encrypted truth table and $c_1 = \pi(b_1)$. Then $P_2$ needs to get $k_2^{b_2} \Vert c_2$ from $P_2$ without revealing the value of $b_2$. This is done by an Oblivious Transfer (see Section\ref{sec:OT_Intro}) where $P_1$ inputs $k_2^0$ and $k_2^1$ and $P_2$ inputs $b_2$. $P_2$ receives the output $k_2^{b_2} \Vert c_2$ from the OT and learns nothing about $k_2^{(1 - b_2)} $, $P_1$ gets no output and learns nothing about the value of $b_2$.\\

			$P_2$ can then look up the entry in the encrypted truth table indexed by $c_1$ and $c_2$ and decrypt it using $D_{k_1^{b_1}, k_2^{b_2}}(\cdot)$. This will give $P_2$ a value for $k_3^{G(b_1, b_2)} \Vert c_3$. Then by using $\pi_3^{-1}$, $P_2$ can extract a value for $G(b_1, b_2)$.\\

			This can be extended to a full circuit, the input wires belonging to the circuits builder are hard coded and their garble keys and permuted values are sent to the executor. The values for the input wires belonging to the executor are obtained by the executor via Oblivious transfer with the builder. The executor is only given the permutations for the output wires, and therefore the intermediate wire bit values are protected.

		\subsection{Security of Yao Garbled Circuits} \label{sub:YaoSecurity}
			A naive implementation of a protocol using Yao Garbled Circuits provides only Semi-honest security. For a formal proof of Semi-honest security see \cite{ProofOfYaoSecurity}, we shall briefly give an intuitive explanation of why naive Yao Garbled Circuits are not secure in the presence of Malicious or Covert adversaries.\\

			Consider the case where $P_1$ is Malicious, at no point does a naive $P_2$ verify that the garbled circuit provided by the Builder actually computes the function the builder claims it does. Whilst the Executor can check that the garbled circuit has the correct ``shape'' (number of gates, wires between gates etc.) the Executor cannot verified that each gate has the correct output. \textcolor{red}{This clearly breaks the Correctness requirement and depending on the function being computed and the structure of the circuit corresponding to it, the Builder can craft a garbled circuit to undermine the Privacy or Independence of Input properties.}\\

			\textcolor{red}{Additionally, the Executor has no way to check that the key it received from the OTs actually corresponds to the request key in the circuit, the Builder could use the same key for both $X_0$ and $X_1$ and thus alter the key used by the Executor for a given input wire.}


		\subsection{Cut and Choose - Security against Malicious and Covert Adversaries} \label{sub:YaoMalicious}
			\subsubsection{Concept}
				Several extensions of Yao's original protocol have been proposed in order to achieve security against Malicious and Covert adversaries. Mostly depending on an approach dubbed ``cut and choose'' which provides statistical security (detects cheating with a certain probability).\\

				This relates to the old solution to dividing a cake fairly, one party cuts the cake in two, then the other party chooses a slice. In our case the Builder builds $s$ many garbled circuits and sends them to the Executor. A subset of these circuits are chosen to be opened for the purpose of checking if they are correct. The remaining circuits are then referred to as Evaluation circuits.\\

				If all check-circuits pass then the Executor evaluates the remaining circuits as usual. If the Executor receives differing outputs from the Evaluation Circuits this indicates cheating, furthermore if any check circuits fail during correctness testing this is also taken to indicate cheating.\\

				The number of garbled circuits built ($s$) acts as a security parameter and the probability of detecting cheating is expressed in terms of $s$. For example cheating in the protocol proposed in \cite{Lindell_CnC_2013} goes undetected with probability $2^{-s}$.\\

			\subsubsection{Issues}
				This Cut and Choose seems very simple conceptually, but creates several subtle new problems to be solved.\\

				\textcolor{red}{Firstly whilst evaluating the many circuits we must now also ensure that both parties' inputs are consistent (same inputs to each circuit) else they might be able learn many outputs, each revealing something they should not have been able to discover.}\\

				In \cite{LindellAndPinkas2007} the example is given of computing the inner product of two binary strings, in this situation the Executing party could give many different inputs each with a single bit set to $1$. The output of the circuit would then give the Executor the value of the Builder's input bit corresponding to the high bit in the Executor's input.\\

				\textcolor{red}{Secondly, in order to open the check circuits the Executor needs obtain both keys for each of its input wires for the check circuits without revealing which circuits have been chosen.}\\

				\textcolor{red}{Having obtained its input keys the Executor then prove to the Builder what subset of the circuits it opened as check circuits so that the Builder can provide both keys for each of its input wires allowing for the opening of the whole circuit.}\\

				\textcolor{red}{Thirdly, given all keys for the inputs wires how do we check the correctness of a circuit? The obvious method would be to fully decrypt each gate, checking to make sure it is the correct gate type(e.g. AND gate)}\\

				\textcolor{red}{A simpler alternative though would be for the Builder to seed the random generator differently for each circuit and then sending the seed for each circuit identified as a check circuit. The Executor can then re-build each Check Circuit using this seed and the full inputs sets and check that the resulting circuit is equal to the Check circuit.}\\

				\textcolor{red}{Fourthly, how should the Executor react to differing outputs from the evaluation circuits. Whilst it is tempting to simply abort immediately this opens the Executor up to a \emph{selective failure} attack. This is an attack where the Builder crafts one of the circuits to fail in some way if the Executors input fulfils some condition (e.g. if the first bit is 1). Then the Executor aborting due to differing outputs from Evaluation Circuits leaks information.}\\

				In the classic protocol the Executor returns the majority output on each output wire. Suppose that we have $s$ many circuits, $t$ of which are selected as check circuits. Then clearly the output will only be corrupted if half of the Evaluation circuits are corrupted. This means that the Builder needs to submit at least $\frac{s - t}{2}$ many corrupted circuits else the bad circuits will certainly be outvoted when it comes to decided the majority output. However, the Builder also requires that none of the corrupted circuits are selected as Check circuits, else their cheating will be detected.



	\chapter{Protocols} \label{sec:Protocols}
		\section{Lindell and Pinkas 2011}
			\subsection*{Overview}
				The protocol proposed in \cite{LindellAndPinkas2011} is a significant improvement on their previous proposal \cite{LindellAndPinkas2007}. Firstly his protocol gives an improved deterrent probability of $\epsilon = 1 - 2^{-0.311s}$, further the work in \cite{ShelatAndShen} showed how to achieve a slightly improve deterrent probability of $\epsilon = 1 - 2^{-0.32s}$. Secondly it removes the need for the very large number of commitments entails in \cite{LindellAndPinkas2007} and thirdly it does not require the preprocessing of the circuit that inflates the number of input wires for the Executor and thus the number of Oblivious transfers needed.\\

				The main new idea in this protocol is a modification of the PVW-OT from \cite{PVW_OT_2008}. We refer to this new OT as the ``Cut and Choose OT''(CnC OT), the Receiver generates a random $J \subset [1, ..., s]$ during the setup such that $\vert J \vert = \frac{s}{2}$, this set represents a subset of the $s$ circuits to be opened.\\

				This set $J$ is then used to generate $s$ many CRSs, each CRS to be used for a different circuit that the Builder sent. For the $j^{th}$ CRS if $j \in J$ then an OT using this CRS will reveal both values input by the sender rather than the usual 1-out-of-2 values, otherwise the usual OT functionality holds.\\

				When running the OT to get its garbled inputs the parties use the $j^{th}$ CRS for all OTs concerning the $j^{th}$ circuit. Clearly this requires that the Executing party be able to prove that only $\frac{s}{2}$ many of the CRSs allow the recovery of both inputs. This is achieved via a Zero Knowledge Proof detailed in Appendix B of \cite{LindellAndPinkas2011}.

		\section{Lindell 2013}
			\subsection*{Overview}

				In \cite{Lindell_CnC_2013} Lindell proposed further improvements on his work with Pinkas in \cite{LindellAndPinkas2011}. There are two

				Lindell proposes using a Secure Computation to determine the output that will produce the correct output if only one of the evaluation circuits produces the correct output. Lindell suggest this Secure Computation be carried out using the protocol he authored with Pinkas in \cite{LindellAndPinkas2011} using a small circuit he provides. The hope is that, especially for large circuits, this small secure computation will be relatively cheap.\\

				This means that to successfully cheat a malicious builder will need guess \emph{exactly} which circuits will be selected as check circuits and will have to fully commit to this guess by corrupting every circuit it does not think will be selected as a check circuit. If this malicious builders guess is wrong by even one circuit the cheating will either be detected (if it corrupts a check circuit) or mitigated (if it fails to corrupt every evaluation circuit).\\

				In order to take full advantage of this improved output determination Lindell modifies the Cut and Choose Oblivious Transfer in \cite{LindellAndPinkas2011}. This modification removes the requirement that exactly half the circuits are selected as check circuits, instead each circuit is selected with probability $\frac{1}{2}$. This is modification of the OT requires a series of Zero knowledge proofs. However, as we shall see it also allows a significant reduction in the number of circuits needed and so the number of OTs needed.\\

				As each circuit is chosen to be a check-circuit with probability $\frac{1}{2}$ this is effectively requiring a malicious adversary to guess at a random element in the set $\{0, 1\}^s$ in order to cheat successfully. Therefore such a builder can only successfully cheat with probability $2^{-s}$.\\

				\subsubsection{}

		\section{Huang, Katz and Evans 2013}
			\subsection*{Overview}

				Concurrently to Lindell's work in \cite{Lindell_CnC_2013} Huang, Katz and Evans produced a protocol also based along the same cut and choose paradigm, however in their approach the parties symmetrically generate a set of circuits and then evaluate each others circuits.\\

				They then both open half of each others circuits to check for correctness before evaluating the unopened circuits.\\

				The probability of a malicious adversary successfully cheating is $2^{-s + log(s)}$ where $s$ is the number of circuits created by \emph{each} party. Note this means that we actually need to create $2s$ many circuit so this protocol requires a factor of $3/2$ less circuits for the same security level as \cite{LindellAndPinkas2011}.\\
				
				Moreover, as the protocol is symmetrical, both parties will be working symmetrically reducing wall clock delays caused by one party having more work to do leaving the other party idle, so depending on how this works in practise this could mean an improvement in wall clock time of around $3$ times quicker.\\

	\chapter{Implementation Details} \label{sec:ImplementationDetails}
		\section*{Purpose of Implementation}
			It should be made abundantly clear that the implementation provided is not intended for real world use with actual confidentiality on the line, instead it is for the purposes of comparing the performance of the protocols under consideration.\\

			Whilst the protocols have been implemented faithfully some of the lower level details not relevant to a comparison of the protocols are ignored, for example we do not established a secure connection between the two parties.\\

			Where possible we have implemented everything myself and reused the same code across protocols, rather than using available libraries. This maintains a consistent quality of implementation, using libraries where appropriate would improve the quality of the implementation it would do so in an uneven manner as many areas cannot be done using a library. This could potentially give one protocol an unfair advantage over another leading to skewed results.

		\section{Yao Garbled Circuits implementation}

			% Stuff goes here
			Clearly we need to implement Yao garbled circuits, but before even that we have an ordinary binary circuit implementation and we need to understand the format of the circuit definition files given by \cite{NigelCircuits}.

			\subsection{Tillich-Smart Circuit Files}

				We are using the circuits provided by \cite{NigelCircuits}, these circuits have been crafted with Yao Garbled Circuits in mind, applying some of the optimisations suggested in \cite{SMC_Is_Practical} and trying to minimise the number of AND gates in order to take maximal advantage of the Free-XOR optimisation.\\

				Throughout we shall refer to the format of the files as RTL. The first line of each RTL file saying how many gates and how many wires are in the circuit, the second line tells us how many inputs party 1 and party 2 give to the circuit and how many outputs there are. Note that without modification we can only provide output to either only the Executor or both parties.\\

				From then on each line refers to a single gate of the binary circuit. The first number (call this number $m$) of a gate definition says how many inputs wires go into the gate, the second number (call this $n$) how many outputs. Then the next $m$ numbers are the input wire IDs, then the last $n$ number are the IDs of the output wires. Finally the gate type is indicated, either AND, XOR, or INV.\\

			\subsection{Creating binary circuits}
				By creating a binary circuit from the RTL files and then using this binary circuit as a template for the creation of Yao Circuits we gain three advantages over reading from the RTL file to create a Yao Garbled Circuit directly.\\

				Firstly this reducing the amount of file I/O, we only need read the file once. Secondly this means makes it easier for us to perform further optimisations on the circuits, for example wire switching the inversion gates to reduce the size of the circuits. Thirdly we need to be able to execute the normal binary circuit in the course of the Lindell 2013 protocol.

				The actual creation of 

		\section{Elliptic Curve implementation}

			\textcolor{red}{Throughout unless otherwise stated we have worked in Elliptic Curve groups, in particular on the curve \emph{brainpoolP256r1} specified in \cite{BrainpoolSpecifications}. This is a $256$-bit curve and as such provides $128$-bits of security. I suggest [REFERENCE THE PRIMER ON ECC] as a high-level primer on ECC and \cite{ECC_RFC_6090} for a more technical introduction.}\\

			\textcolor{red}{Elliptic curves groups are preferable over Schnorr groups for cryptographic puposes, they require smaller keys for the same level of security reducing the required size of the group. This is particularly desirable as it reduces the size of the number we are dealing with. This point is illustrated in the Figure [INSERT FIGURE REFERENCE HERE (AND FIGURE)].}\\

			\textcolor{red}{Elliptic Curve Groups are usually represented in Additive notation, differing from the usual Multiplicative notation used for groups in cryptography. We define a curve of the form $y^2 = x^3 + a\cdot x + b$ modulo some prime $q$, call this curve $C$. Say $n$ is the number of bits required to represent $q$, then we say this is an $n$-bit curve.}\\
			
			\textcolor{red}{We then need to define the group by the set of elements and the group operation. The set of elements is simply defined as,}

			$$\{(x, y) \in \mathbb{Z}_p^2 : \textnormal{ where } y^2 = x^3 + a\cdot x + b\} $$

			\textcolor{red}{The group operation is more complex, suffice to }

		\section{Verifiable Secret Sharing and Multi-precision Polynomials}

			\textcolor{red}{For the Zero Knowledge Proof of Knowledge specified in \cite{LindellAndPinkas2011} we need a Secret Sharing Scheme. For \cite{Katz_Symm_CnC_2013} we need to go one step further and have a Verifiable Secret Sharing Scheme.}\\

			\textcolor{red}{A Secret Sharing Scheme is a way of obscuring a secret whilst distributing shares to a set of parties such that only certain combinations of shares will be able to reconstruct the secret. So consider perhaps a bank vault which requires at least $3$ out of $10$ keys. Here the secret is the vault opening, the shares are the keys and the parties are the bank employees holding the keys. In general we speak of a $t$-out-of-$n$ scheme, where there are $n$ shares and $t$ of them are required to reveal the secret.}\\

			\textcolor{red}{We have implemented Shamir's Secret Scheme (Shamir's) and its extension the Feldman's Scheme. Shamir's scheme is based on how many points are needed to uniquely define a polynomial curve. }\\

			\textcolor{red}{Consider a polynomial $K$ of degree $n$ over the finite field $\mathbb{F}_q$. Then we can denote this polynomial as $K = \sum_{i=0}^{n} a_i \cdot x ^ i$. Any such polynomial of degree $n$ can be uniquely defined given $n+1$ (or more) points on the curve, given $n$ or fewer points we gain no information about the polynomial.}

		\section{Peikert, Vaikuntanathan and Waters OT}

			.

		\subsection{Other - AES, SHA-2}

			.


	\chapter{Experiments} \label{sec:Results}
		We shall be using the circuits provided in \cite{NigelCircuits} for our experiments with varying randomised inputs, in particular we shall consider
		
		\begin{itemize}
			\item AES,
			\item 32-bit Addition,
			\item 32-bit Multiplication,
			\item SHA-256 hashing.
		\end{itemize}


		\section{Measurement metrics}
			We shall be focusing on three main metrics for measuring performance of the protocols for both parties, namely CPU time used, wall clock time used and data sent.\\

			We shall break these metrics down further so that we can see measure the performance of each part of the protocol for the purpose of identifying the bottlenecks for each protocol.

		\section{Testing Environment}
			All tests were carried out between two test machines each with an i7-3770S CPU clocked at $3.10$ GHz with $8096$ KB of cache and $32$ GB of RAM. These machines both possess dedicated network cards for communications with the other member of the pair. Compilation was performed with g$++$ version 4.4.7. 

		\section{Benchmarks}
			Here I give some benchmarks of key components in my implementation such as communication, ECC encryption and circuit evaluation. I include these measurements so that others intending to implement these protocols with more efficient (e.g. library supplied) components can get a rough idea of what performance improvement they can expect.

			\subsection{Communications}

% 				\begin{figure}
% 					\begin{tabular}{ c | c | c }
% 						Block Size & Time Taken (seconds) &  \\
% 						\hline
% 						$100,000$ & 0 &  \\
% 						$10,000,000$ & 0 &  \\
% 					\end{tabular}
% 				\end{figure}
	\chapter{Conclusions}

		

	\begin{thebibliography}{5}
	
		\bibitem{LindellAndPinkas2007}
			Y. Lindell and B. Pinkas. \emph{An Efficient Protocol for Secure Two-Party Computation in the Presence of Malicious Adversaries}. To appear in the Journal of Cryptology. (Extended abstract appeared in EUROCRYPT 2007, Springer (LNCS 4515), pages 52–78, 2007.)

		\bibitem{LindellAndPinkas2011}
			Y. Lindell and B. Pinkas. \emph{Secure Two-Party Computation via Cut-and-Choose Oblivious Transfer}. In TCC 2011, Springer (LNCS 6597), pages 329–346, 2011

		\bibitem{ShelatAndShen}
			A. Shelat, C.H. Shen. Two-Output Secure Computation with Malicious Adversaries. In EUROCRYPT 2011, Springer (LNCS 6632), pages 386–405, 2011.

		\bibitem{Lindell_CnC_2013}
			Y. Lindell.
			\emph{Fast cut-and-choose based protocols for malicious and covert adversaries}, R. Canetti, J.A. Garay, (eds.) CRYPTO 2013, Part II. LNCS, vol. 8043, pp. 1–17. Springer, Heidelberg (2013).

		\bibitem{Katz_Symm_CnC_2013}
			Y. Huang, J. Katz, D. Evans. \emph{Efficient Secure Two-Party Computation Using Symmetric Cut-and-Choose}, In 33rd International Cryptology Conference (CRYPTO 2013), 2013.

		\bibitem{SugarBeets}
			P. Bogetoft, D. Christensen, I. Damgård et al. \emph{Secure Multiparty Computation Goes Live}, In Financial Cryptography and Data Security 2009, Springer LNCS 5628, pages 325-343, 2009.

		\bibitem{SMC_Is_Practical}
			Benny Pinkas, Thomas Schneider, Nigel P. Smart and Stephen C. Williams. \emph{Secure Two-Party Computation is Practical}, ASIACRYPT 2009, December 6-10, 2009.

		\bibitem{FreeXOR}
			V. Kolesnikov and T. Schneider. \emph{Improved garbled circuit: Free XOR gates and applications}. In Automata, Languages and Programming – ICALP 2008, Springer-Verlag (LNCS 5126), pages 486 - 498, 2008.

		\bibitem{OnCommittedInputs}
			S. Jarecki and V. Shmatikov. \emph{Efficient Two-Party Secure Computation on Committed Inputs.} In EUROCRYPT 2007, Springer (LNCS 4515), pages 97 - 114, 2007.

		\bibitem{LEGO_Paper}
			J. Nielsen and C. Orlandi. \emph{LEGO for Two-Party Secure Computation}. In TCC 2009, Springer (LNCS 5444), pages 368 - 386, 2009.

		\bibitem{MiniLEGO}
			T. Frederiksen, T. Jakobsen, J. Nielsen, et al. \emph{MiniLEGO: Efficient Secure Two-Party Computation from General Assumptions}, In Advances in Cryptology - EUROCRYPT 2013, Springer (LNCS 7881), pages 537 - 556, 2013.

		\bibitem{YaoOriginal}
			A. Yao. \emph{How to Generate and Exchange Secrets.} In 27th FOCS, pages 162–167, 1986.

		\bibitem{ProofOfYaoSecurity}
			Y. Lindell, B. Pinkas. \emph{A proof of security of Yao’s protocol for two-party computation}. Journal of Cryptology 22(2), pages 161 - 188 (2009).

		\bibitem{WhenGameTheoryMetSMC}
			I. Abraham, D. Dolev, R. Gonen and J. Halpern. \emph{Distributed Computing Meets Game Theory: Robust Mechanisms for Rational Secret Sharing and Multiparty Computation}, Proceedings of the Twenty-Fifth Annual ACM Symposium on Principles of Distributed Computing,  pages 53 - 62, 2006.

		\bibitem{Rabin81}
			M. Rabin. \emph{How to exchange secrets with oblivious transfer}. Technical Report, TR-81, Aiken Computation Lab, Harvard University, 1981.

		\bibitem{PinkasSlides2014}
			B. Pinkas. \emph{Secure Computation Lecture Series}, Lecture 5 - Oblivious Transfer, 2014.

		\bibitem{EvenEtAl85}
			S. Even, O. Goldreich and A. Lempel. \emph{A randomized protocol for signing contracts}, In Communications of the ACM, Vol. 28 Iss. 6, pages 637 - 647 (1985)

		\bibitem{PVW_OT_2008}
			C. Peikert, V. Vaikuntanathan and B. Waters. \emph{A framework for efficient and composable oblivious transfer}. In: Wagner, D. (ed.) CRYPTO 2008, Springer (LNCS 5157), pages 554–571, 2008.

		\bibitem{NaorPinkasOT2001}
			Naor and B. Pinkas, \emph{Efficient Oblivious Transfer Protocols}, Proceedings of SODA 2001 (SIAM Symposium on Discrete Algorithms), 2001.

		\bibitem{NigelCircuits}
			Bristol Cryptography Group. \emph{Circuits of Basic Functions Suitable For MPC and FHE}.  \url{http://www.cs.bris.ac.uk/Research/CryptographySecurity/MPC/}. 

		\bibitem{ECC_RFC_6090}
			D. McGrew, K. Igoe and M. Salter,\emph{ Fundamental Elliptic Curve Cryptography Algorithms}, RFC 6090, February 2011.

		\bibitem{BrainpoolSpecifications}
			ECC Brainpool, "ECC Brainpool Standard Curves and Curve
			Generation", October 2005, \url{http://www.ecc-brainpool.org/
			download/Domain-parameters.pdf}.

	\end{thebibliography}


\end{document}


